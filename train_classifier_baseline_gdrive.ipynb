{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAhYhRtWd-U3",
        "outputId": "0679dbe2-cc97-4db1-9e09-3ca5412fea7f"
      },
      "id": "rAhYhRtWd-U3",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m92.2/101.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b64c1de4",
      "metadata": {
        "id": "b64c1de4"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import yaml\n",
        "import json\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import numpy as np\n",
        "import math\n",
        "import shutil\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "37c4bcdb",
      "metadata": {
        "id": "37c4bcdb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from tensorboardX import SummaryWriter\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torch.optim import SGD, Adam\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "KyJp5ywnclHe"
      },
      "id": "KyJp5ywnclHe",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ROOT = r'/content/gdrive/'\n",
        "\n",
        "drive.mount(ROOT)\n",
        "dir = r'My Drive'\n",
        "HOME_DIRECTORY = ROOT + dir\n",
        "\n",
        "SOURCE_DIRECTORY = f\"{HOME_DIRECTORY}/tudelft/msc/quarter3/deep-learning/reproducibility-project\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13Kkb3Bzcpve",
        "outputId": "25013c5f-5670-4b2e-b8de-efa0a1a1d82d"
      },
      "id": "13Kkb3Bzcpve",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "_log_path = None\n",
        "\n",
        "def set_log_path(path):\n",
        "    global _log_path\n",
        "    _log_path = path\n",
        "\n",
        "def log(obj, filename='log.txt'):\n",
        "    print(obj)\n",
        "    if _log_path is not None:\n",
        "        with open(os.path.join(_log_path, filename), 'a') as f:\n",
        "            print(obj, file=f)\n",
        "\n",
        "\n",
        "class Averager():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.n = 0.0\n",
        "        self.v = 0.0\n",
        "\n",
        "    def add(self, v, n=1.0):\n",
        "        self.v = (self.v * self.n + v * n) / (self.n + n)\n",
        "        self.n += n\n",
        "\n",
        "    def item(self):\n",
        "        return self.v\n",
        "\n",
        "\n",
        "class Timer():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.v = time.time()\n",
        "\n",
        "    def s(self):\n",
        "        self.v = time.time()\n",
        "\n",
        "    def t(self):\n",
        "        return time.time() - self.v\n",
        "\n",
        "\n",
        "def set_gpu(gpu):\n",
        "    print('set gpu:', gpu)\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n",
        "\n",
        "\n",
        "def ensure_path(path, remove=True):\n",
        "    basename = os.path.basename(path.rstrip('/'))\n",
        "    if os.path.exists(path):\n",
        "        if remove and (basename.startswith('_')\n",
        "                or input('{} exists, remove? ([y]/n): '.format(path)) != 'n'):\n",
        "            shutil.rmtree(path)\n",
        "            os.makedirs(path)\n",
        "    else:\n",
        "        os.makedirs(path)\n",
        "\n",
        "\n",
        "def time_str(t):\n",
        "    if t >= 3600:\n",
        "        return '{:.1f}h'.format(t / 3600)\n",
        "    if t >= 60:\n",
        "        return '{:.1f}m'.format(t / 60)\n",
        "    return '{:.1f}s'.format(t)\n",
        "\n",
        "\n",
        "def compute_logits(feat, proto, metric='dot', temp=1.0):\n",
        "    assert feat.dim() == proto.dim()\n",
        "\n",
        "    if feat.dim() == 2:\n",
        "        if metric == 'dot':\n",
        "            logits = torch.mm(feat, proto.t())\n",
        "        elif metric == 'cos':\n",
        "            logits = torch.mm(F.normalize(feat, dim=-1),\n",
        "                              F.normalize(proto, dim=-1).t())\n",
        "        elif metric == 'sqr':\n",
        "            logits = -(feat.unsqueeze(1) -\n",
        "                       proto.unsqueeze(0)).pow(2).sum(dim=-1)\n",
        "\n",
        "    elif feat.dim() == 3:\n",
        "        if metric == 'dot':\n",
        "            logits = torch.bmm(feat, proto.permute(0, 2, 1))\n",
        "        elif metric == 'cos':\n",
        "            logits = torch.bmm(F.normalize(feat, dim=-1),\n",
        "                               F.normalize(proto, dim=-1).permute(0, 2, 1))\n",
        "        elif metric == 'sqr':\n",
        "            logits = -(feat.unsqueeze(2) -\n",
        "                       proto.unsqueeze(1)).pow(2).sum(dim=-1)\n",
        "\n",
        "    return logits * temp\n",
        "\n",
        "\n",
        "def compute_acc(logits, label, reduction='mean'):\n",
        "    ret = (torch.argmax(logits, dim=1) == label).float()\n",
        "    if reduction == 'none':\n",
        "        return ret.detach()\n",
        "    elif reduction == 'mean':\n",
        "        return ret.mean().item()\n",
        "\n",
        "\n",
        "def compute_n_params(model, return_str=True):\n",
        "    tot = 0\n",
        "    for p in model.parameters():\n",
        "        w = 1\n",
        "        for x in p.shape:\n",
        "            w *= x\n",
        "        tot += w\n",
        "    if return_str:\n",
        "        if tot >= 1e6:\n",
        "            return '{:.1f}M'.format(tot / 1e6)\n",
        "        else:\n",
        "            return '{:.1f}K'.format(tot / 1e3)\n",
        "    else:\n",
        "        return tot\n",
        "\n",
        "\n",
        "def make_optimizer(params, name, lr, weight_decay=None, milestones=None):\n",
        "    if weight_decay is None:\n",
        "        weight_decay = 0.\n",
        "    if name == 'sgd':\n",
        "        optimizer = SGD(params, lr, momentum=0.9, weight_decay=weight_decay)\n",
        "    elif name == 'adam':\n",
        "        optimizer = Adam(params, lr, weight_decay=weight_decay)\n",
        "    if milestones:\n",
        "        lr_scheduler = MultiStepLR(optimizer, milestones)\n",
        "    else:\n",
        "        lr_scheduler = None\n",
        "    return optimizer, lr_scheduler\n",
        "\n",
        "\n",
        "def visualize_dataset(dataset, name, writer, n_samples=16):\n",
        "    demo = []\n",
        "    for i in np.random.choice(len(dataset), n_samples):\n",
        "        demo.append(dataset.convert_raw(dataset[i][0]))\n",
        "    writer.add_images('visualize_' + name, torch.stack(demo))\n",
        "    writer.flush()\n",
        "\n",
        "\n",
        "def freeze_bn(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            m.eval()\n",
        "\n"
      ],
      "metadata": {
        "id": "zquFYmn6dAk7"
      },
      "id": "zquFYmn6dAk7",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_ROOT = SOURCE_DIRECTORY + \"/dataset-MiniImageNet\"\n",
        "\n",
        "\n",
        "datasets = {}\n",
        "def datasets_register(name):\n",
        "    def decorator(cls):\n",
        "        datasets[name] = cls\n",
        "        return cls\n",
        "    return decorator\n",
        "\n",
        "\n",
        "def datasets_make(name, **kwargs):\n",
        "    if kwargs.get('root_path') is None:\n",
        "        kwargs['root_path'] = os.path.join(DEFAULT_ROOT, name)\n",
        "    dataset = datasets[name](**kwargs)\n",
        "    return dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "zxr_LloTdAVM"
      },
      "id": "zxr_LloTdAVM",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@datasets_register('image-folder')\n",
        "class ImageFolder(Dataset):\n",
        "\n",
        "    def __init__(self, root_path, image_size=224, box_size=256, **kwargs):\n",
        "        if box_size is None:\n",
        "            box_size = image_size\n",
        "\n",
        "        self.filepaths = []\n",
        "        self.label = []\n",
        "        classes = sorted(os.listdir(root_path))\n",
        "\n",
        "        if kwargs.get('split'):\n",
        "            path = kwargs.get('split_file')\n",
        "            if path is None:\n",
        "                path = os.path.join(\n",
        "                        os.path.dirname(root_path.rstrip('/')), 'split.json')\n",
        "            split = json.load(open(path, 'r'))\n",
        "            classes = sorted(split[kwargs['split']])\n",
        "\n",
        "        for i, c in enumerate(classes):\n",
        "            for filename in sorted(os.listdir(os.path.join(root_path, c))):\n",
        "                self.filepaths.append(os.path.join(root_path, c, filename))\n",
        "                self.label.append(i)\n",
        "        self.n_classes = max(self.label) + 1\n",
        "\n",
        "        norm_params = {'mean': [0.485, 0.456, 0.406],\n",
        "                       'std': [0.229, 0.224, 0.225]}\n",
        "        normalize = transforms.Normalize(**norm_params)\n",
        "        if kwargs.get('augment'):\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(image_size),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize(box_size),\n",
        "                transforms.CenterCrop(image_size),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "\n",
        "        def convert_raw(x):\n",
        "            mean = torch.tensor(norm_params['mean']).view(3, 1, 1).type_as(x)\n",
        "            std = torch.tensor(norm_params['std']).view(3, 1, 1).type_as(x)\n",
        "            return x * std + mean\n",
        "        self.convert_raw = convert_raw\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filepaths)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        img = Image.open(self.filepaths[i]).convert('RGB')\n",
        "        return self.transform(img), self.label[i]\n",
        "\n"
      ],
      "metadata": {
        "id": "QOFXfUfkdAQG"
      },
      "id": "QOFXfUfkdAQG",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@datasets_register('mini-imagenet')\n",
        "class MiniImageNet(Dataset):\n",
        "\n",
        "    def __init__(self, root_path, split='train', **kwargs):\n",
        "        split_tag = split\n",
        "        if split == 'train':\n",
        "            split_tag = 'train_phase_train'\n",
        "        split_file = 'miniImageNet_category_split_{}.pickle'.format(split_tag)\n",
        "        with open(os.path.join(root_path, split_file), 'rb') as f:\n",
        "            pack = pickle.load(f, encoding='latin1')\n",
        "        data = pack['data']\n",
        "        label = pack['labels']\n",
        "\n",
        "        image_size = 80\n",
        "        data = [Image.fromarray(x) for x in data]\n",
        "\n",
        "        min_label = min(label)\n",
        "        label = [x - min_label for x in label]\n",
        "\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "        self.n_classes = max(self.label) + 1\n",
        "\n",
        "        norm_params = {'mean': [0.485, 0.456, 0.406],\n",
        "                       'std': [0.229, 0.224, 0.225]}\n",
        "        normalize = transforms.Normalize(**norm_params)\n",
        "        self.default_transform = transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "        augment = kwargs.get('augment')\n",
        "        if augment == 'resize':\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.RandomResizedCrop(image_size),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "        elif augment == 'crop':\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize(image_size),\n",
        "                transforms.RandomCrop(image_size, padding=8),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "        elif augment is None:\n",
        "            self.transform = self.default_transform\n",
        "\n",
        "        def convert_raw(x):\n",
        "            mean = torch.tensor(norm_params['mean']).view(3, 1, 1).type_as(x)\n",
        "            std = torch.tensor(norm_params['std']).view(3, 1, 1).type_as(x)\n",
        "            return x * std + mean\n",
        "        self.convert_raw = convert_raw\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.transform(self.data[i]), self.label[i]\n",
        "\n"
      ],
      "metadata": {
        "id": "k0noCslgdASp"
      },
      "id": "k0noCslgdASp",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CategoriesSampler():\n",
        "\n",
        "    def __init__(self, label, n_batch, n_cls, n_per, ep_per_batch=1):\n",
        "        self.n_batch = n_batch\n",
        "        self.n_cls = n_cls\n",
        "        self.n_per = n_per\n",
        "        self.ep_per_batch = ep_per_batch\n",
        "\n",
        "        label = np.array(label)\n",
        "        self.catlocs = []\n",
        "        for c in range(max(label) + 1):\n",
        "            self.catlocs.append(np.argwhere(label == c).reshape(-1))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_batch\n",
        "\n",
        "    def __iter__(self):\n",
        "        for i_batch in range(self.n_batch):\n",
        "            batch = []\n",
        "            for i_ep in range(self.ep_per_batch):\n",
        "                episode = []\n",
        "                classes = np.random.choice(len(self.catlocs), self.n_cls,\n",
        "                                           replace=False)\n",
        "                for c in classes:\n",
        "                    l = np.random.choice(self.catlocs[c], self.n_per,\n",
        "                                         replace=False)\n",
        "                    episode.append(torch.from_numpy(l))\n",
        "                episode = torch.stack(episode)\n",
        "                batch.append(episode)\n",
        "            batch = torch.stack(batch) # bs * n_cls * n_per\n",
        "            yield batch.view(-1)\n",
        "\n"
      ],
      "metadata": {
        "id": "VuoXX_6adAXy"
      },
      "id": "VuoXX_6adAXy",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "models = {}\n",
        "def models_register(name):\n",
        "    def decorator(cls):\n",
        "        models[name] = cls\n",
        "        return cls\n",
        "    return decorator\n",
        "\n",
        "\n",
        "def models_make(name, **kwargs):\n",
        "    if name is None:\n",
        "        return None\n",
        "    model = models[name](**kwargs)\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "    return model\n",
        "\n",
        "\n",
        "def load(model_sv, name=None):\n",
        "    if name is None:\n",
        "        name = 'model'\n",
        "    model = make(model_sv[name], **model_sv[name + '_args'])\n",
        "    model.load_state_dict(model_sv[name + '_sd'])\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "TBNv3xjsiorL"
      },
      "id": "TBNv3xjsiorL",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@models_register('classifier')\n",
        "class Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, encoder_args,\n",
        "                 classifier, classifier_args):\n",
        "        super().__init__()\n",
        "        self.encoder = models_make(encoder, **encoder_args)\n",
        "        classifier_args['in_dim'] = self.encoder.out_dim\n",
        "        self.classifier = models_make(classifier, **classifier_args)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "@models_register('linear-classifier')\n",
        "class LinearClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, in_dim, n_classes):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(in_dim, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "\n",
        "@models_register('nn-classifier')\n",
        "class NNClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, in_dim, n_classes, metric='cos', temp=None):\n",
        "        super().__init__()\n",
        "        self.proto = nn.Parameter(torch.empty(n_classes, in_dim))\n",
        "        nn.init.kaiming_uniform_(self.proto, a=math.sqrt(5))\n",
        "        if temp is None:\n",
        "            if metric == 'cos':\n",
        "                temp = nn.Parameter(torch.tensor(10.))\n",
        "            else:\n",
        "                temp = 1.0\n",
        "        self.metric = metric\n",
        "        self.temp = temp\n",
        "\n",
        "    def forward(self, x):\n",
        "        return utils.compute_logits(x, self.proto, self.metric, self.temp)\n",
        "\n",
        "\n",
        "def conv_block(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "\n",
        "\n",
        "@models_register('convnet4')\n",
        "class ConvNet4(nn.Module):\n",
        "\n",
        "    def __init__(self, x_dim=3, hid_dim=64, z_dim=64):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            conv_block(x_dim, hid_dim),\n",
        "            conv_block(hid_dim, hid_dim),\n",
        "            conv_block(hid_dim, hid_dim),\n",
        "            conv_block(hid_dim, z_dim),\n",
        "        )\n",
        "        self.out_dim = 1600\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return x.view(x.shape[0], -1)\n"
      ],
      "metadata": {
        "id": "qgF5hpSudAdA"
      },
      "id": "qgF5hpSudAdA",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@models_register('meta-baseline')\n",
        "class MetaBaseline(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, encoder_args={}, method='cos',\n",
        "                 temp=10., temp_learnable=True):\n",
        "        super().__init__()\n",
        "        self.encoder = models_make(encoder, **encoder_args)\n",
        "        self.method = method\n",
        "\n",
        "        if temp_learnable:\n",
        "            self.temp = nn.Parameter(torch.tensor(temp))\n",
        "        else:\n",
        "            self.temp = temp\n",
        "\n",
        "    def forward(self, x_shot, x_query):\n",
        "        shot_shape = x_shot.shape[:-3]\n",
        "        query_shape = x_query.shape[:-3]\n",
        "        img_shape = x_shot.shape[-3:]\n",
        "\n",
        "        x_shot = x_shot.view(-1, *img_shape)\n",
        "        x_query = x_query.view(-1, *img_shape)\n",
        "        x_tot = self.encoder(torch.cat([x_shot, x_query], dim=0))\n",
        "        x_shot, x_query = x_tot[:len(x_shot)], x_tot[-len(x_query):]\n",
        "        x_shot = x_shot.view(*shot_shape, -1)\n",
        "        x_query = x_query.view(*query_shape, -1)\n",
        "\n",
        "        if self.method == 'cos':\n",
        "            x_shot = x_shot.mean(dim=-2)\n",
        "            x_shot = F.normalize(x_shot, dim=-1)\n",
        "            x_query = F.normalize(x_query, dim=-1)\n",
        "            metric = 'dot'\n",
        "        elif self.method == 'sqr':\n",
        "            x_shot = x_shot.mean(dim=-2)\n",
        "            metric = 'sqr'\n",
        "\n",
        "        logits = compute_logits(\n",
        "                x_query, x_shot, metric=metric, temp=self.temp)\n",
        "        return logits\n",
        "\n"
      ],
      "metadata": {
        "id": "ZSZg1spbj8jJ"
      },
      "id": "ZSZg1spbj8jJ",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n",
        "           'wide_resnet50_2', 'wide_resnet101_2']\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    __constants__ = ['downsample']\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    __constants__ = ['downsample']\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.out_dim = 512 * block.expansion\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "@models_register('resnet18')\n",
        "def resnet18(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "def resnet34(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-34 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "@models_register('resnet50')\n",
        "def resnet50(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-50 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "def resnet101(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-101 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, progress,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "def resnet152(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-152 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "def resnext50_32x4d(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNeXt-50 32x4d model from\n",
        "    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    kwargs['groups'] = 32\n",
        "    kwargs['width_per_group'] = 4\n",
        "    return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3],\n",
        "                   pretrained, progress, **kwargs)\n",
        "\n",
        "\n",
        "def resnext101_32x8d(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNeXt-101 32x8d model from\n",
        "    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    kwargs['groups'] = 32\n",
        "    kwargs['width_per_group'] = 8\n",
        "    return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\n",
        "                   pretrained, progress, **kwargs)\n",
        "\n",
        "\n",
        "def wide_resnet50_2(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"Wide ResNet-50-2 model from\n",
        "    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n",
        "\n",
        "    The model is the same as ResNet except for the bottleneck number of channels\n",
        "    which is twice larger in every block. The number of channels in outer 1x1\n",
        "    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n",
        "    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    kwargs['width_per_group'] = 64 * 2\n",
        "    return _resnet('wide_resnet50_2', Bottleneck, [3, 4, 6, 3],\n",
        "                   pretrained, progress, **kwargs)\n",
        "\n",
        "\n",
        "def wide_resnet101_2(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"Wide ResNet-101-2 model from\n",
        "    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n",
        "\n",
        "    The model is the same as ResNet except for the bottleneck number of channels\n",
        "    which is twice larger in every block. The number of channels in outer 1x1\n",
        "    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n",
        "    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    kwargs['width_per_group'] = 64 * 2\n",
        "    return _resnet('wide_resnet101_2', Bottleneck, [3, 4, 23, 3],\n",
        "                   pretrained, progress, **kwargs)\n"
      ],
      "metadata": {
        "id": "Fiv27JoYdAfm"
      },
      "id": "Fiv27JoYdAfm",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def conv3x3(in_planes, out_planes):\n",
        "    return nn.Conv2d(in_planes, out_planes, 3, padding=1, bias=False)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes):\n",
        "    return nn.Conv2d(in_planes, out_planes, 1, bias=False)\n",
        "\n",
        "\n",
        "def norm_layer(planes):\n",
        "    return nn.BatchNorm2d(planes)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, planes, downsample):\n",
        "        super().__init__()\n",
        "\n",
        "        self.relu = nn.LeakyReLU(0.1)\n",
        "\n",
        "        self.conv1 = conv3x3(inplanes, planes)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.conv3 = conv3x3(planes, planes)\n",
        "        self.bn3 = norm_layer(planes)\n",
        "\n",
        "        self.downsample = downsample\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.maxpool(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet12(nn.Module):\n",
        "\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.inplanes = 3\n",
        "\n",
        "        self.layer1 = self._make_layer(channels[0])\n",
        "        self.layer2 = self._make_layer(channels[1])\n",
        "        self.layer3 = self._make_layer(channels[2])\n",
        "        self.layer4 = self._make_layer(channels[3])\n",
        "\n",
        "        self.out_dim = channels[3]\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out',\n",
        "                                        nonlinearity='leaky_relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, planes):\n",
        "        downsample = nn.Sequential(\n",
        "            conv1x1(self.inplanes, planes),\n",
        "            norm_layer(planes),\n",
        "        )\n",
        "        block = Block(self.inplanes, planes, downsample)\n",
        "        self.inplanes = planes\n",
        "        return block\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = x.view(x.shape[0], x.shape[1], -1).mean(dim=2)\n",
        "        return x\n",
        "\n",
        "\n",
        "@models_register('resnet12')\n",
        "def resnet12():\n",
        "    return ResNet12([64, 128, 256, 512])\n",
        "\n",
        "\n",
        "@models_register('resnet12-wide')\n",
        "def resnet12_wide():\n",
        "    return ResNet12([64, 160, 320, 640])\n",
        "\n"
      ],
      "metadata": {
        "id": "Vj0MBInqdAiX"
      },
      "id": "Vj0MBInqdAiX",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def split_shot_query(data, way, shot, query, ep_per_batch=1):\n",
        "    img_shape = data.shape[1:]\n",
        "    data = data.view(ep_per_batch, way, shot + query, *img_shape)\n",
        "    x_shot, x_query = data.split([shot, query], dim=2)\n",
        "    x_shot = x_shot.contiguous()\n",
        "    x_query = x_query.contiguous().view(ep_per_batch, way * query, *img_shape)\n",
        "    return x_shot, x_query\n",
        "\n",
        "\n",
        "def make_nk_label(n, k, ep_per_batch=1):\n",
        "    label = torch.arange(n).unsqueeze(1).expand(n, k).reshape(-1)\n",
        "    label = label.repeat(ep_per_batch)\n",
        "    return label\n",
        "\n"
      ],
      "metadata": {
        "id": "DATVlOexdAnf"
      },
      "id": "DATVlOexdAnf",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ybaXsioodAqR"
      },
      "id": "ybaXsioodAqR",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U9UFrsNodAtD"
      },
      "id": "U9UFrsNodAtD",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sByAWjK6dAvn"
      },
      "id": "sByAWjK6dAvn",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b23e2e2e",
      "metadata": {
        "id": "b23e2e2e"
      },
      "outputs": [],
      "source": [
        "def main(config):\n",
        "    svname = None\n",
        "    if svname is None:\n",
        "        svname = 'classifier_{}'.format(config['train_dataset'])\n",
        "        svname += '_' + config['model_args']['encoder']\n",
        "        clsfr = config['model_args']['classifier']\n",
        "        if clsfr != 'linear-classifier':\n",
        "            svname += '-' + clsfr\n",
        "    # if args.tag is not None:\n",
        "    #     svname += '_' + args.tag\n",
        "    save_path = os.path.join(SOURCE_DIRECTORY + './save', svname)\n",
        "    ensure_path(save_path)\n",
        "    set_log_path(save_path)\n",
        "    writer = SummaryWriter(os.path.join(save_path, 'tensorboard'))\n",
        "\n",
        "    yaml.dump(config, open(os.path.join(save_path, 'config.yaml'), 'w'))\n",
        "\n",
        "    #### Dataset ####\n",
        "\n",
        "    # train\n",
        "    train_dataset = datasets_make(config['train_dataset'],\n",
        "                                  **config['train_dataset_args'])\n",
        "    train_loader = DataLoader(train_dataset, config['batch_size'], shuffle=True,\n",
        "                              num_workers=8, pin_memory=True)\n",
        "    log('train dataset: {} (x{}), {}'.format(\n",
        "            train_dataset[0][0].shape, len(train_dataset),\n",
        "            train_dataset.n_classes))\n",
        "    if config.get('visualize_datasets'):\n",
        "        visualize_dataset(train_dataset, 'train_dataset', writer)\n",
        "\n",
        "    # val\n",
        "    if config.get('val_dataset'):\n",
        "        eval_val = True\n",
        "        val_dataset = datasets_make(config['val_dataset'],\n",
        "                                    **config['val_dataset_args'])\n",
        "        val_loader = DataLoader(val_dataset, config['batch_size'],\n",
        "                                num_workers=8, pin_memory=True)\n",
        "        log('val dataset: {} (x{}), {}'.format(\n",
        "                val_dataset[0][0].shape, len(val_dataset),\n",
        "                val_dataset.n_classes))\n",
        "        if config.get('visualize_datasets'):\n",
        "            visualize_dataset(val_dataset, 'val_dataset', writer)\n",
        "    else:\n",
        "        eval_val = False\n",
        "\n",
        "    # few-shot eval\n",
        "    if config.get('fs_dataset'):\n",
        "        ef_epoch = config.get('eval_fs_epoch')\n",
        "        if ef_epoch is None:\n",
        "            ef_epoch = 5\n",
        "        eval_fs = True\n",
        "\n",
        "        fs_dataset = datasets_make(config['fs_dataset'],\n",
        "                                   **config['fs_dataset_args'])\n",
        "        log('fs dataset: {} (x{}), {}'.format(\n",
        "                fs_dataset[0][0].shape, len(fs_dataset),\n",
        "                fs_dataset.n_classes))\n",
        "        if config.get('visualize_datasets'):\n",
        "            visualize_dataset(fs_dataset, 'fs_dataset', writer)\n",
        "\n",
        "        n_way = 5\n",
        "        n_query = 15\n",
        "        n_shots = [1, 5]\n",
        "        fs_loaders = []\n",
        "        for n_shot in n_shots:\n",
        "            fs_sampler = CategoriesSampler(\n",
        "                    fs_dataset.label, 200,\n",
        "                    n_way, n_shot + n_query, ep_per_batch=4)\n",
        "            fs_loader = DataLoader(fs_dataset, batch_sampler=fs_sampler,\n",
        "                                   num_workers=8, pin_memory=True)\n",
        "            fs_loaders.append(fs_loader)\n",
        "    else:\n",
        "        eval_fs = False\n",
        "\n",
        "    ########\n",
        "\n",
        "    #### Model and Optimizer ####\n",
        "\n",
        "    if config.get('load'):\n",
        "        model_sv = torch.load(config['load'])\n",
        "        model = models_load(model_sv)\n",
        "    else:\n",
        "        model = models_make(config['model'], **config['model_args'])\n",
        "\n",
        "    if eval_fs:\n",
        "        fs_model = models_make('meta-baseline', encoder=None)\n",
        "        fs_model.encoder = model.encoder\n",
        "\n",
        "    if config.get('_parallel'):\n",
        "        model = nn.DataParallel(model)\n",
        "        if eval_fs:\n",
        "            fs_model = nn.DataParallel(fs_model)\n",
        "\n",
        "    log('num params: {}'.format(compute_n_params(model)))\n",
        "\n",
        "    optimizer, lr_scheduler = make_optimizer(\n",
        "            model.parameters(),\n",
        "            config['optimizer'], **config['optimizer_args'])\n",
        "\n",
        "    ########\n",
        "\n",
        "    max_epoch = config['max_epoch']\n",
        "    save_epoch = config.get('save_epoch')\n",
        "    max_va = 0.\n",
        "    timer_used = Timer()\n",
        "    timer_epoch = Timer()\n",
        "\n",
        "    for epoch in range(1, max_epoch + 1 + 1):\n",
        "        if epoch == max_epoch + 1:\n",
        "            if not config.get('epoch_ex'):\n",
        "                break\n",
        "            train_dataset.transform = train_dataset.default_transform\n",
        "            train_loader = DataLoader(\n",
        "                    train_dataset, config['batch_size'], shuffle=True,\n",
        "                    num_workers=8, pin_memory=True)\n",
        "\n",
        "        timer_epoch.s()\n",
        "        aves_keys = ['tl', 'ta', 'vl', 'va']\n",
        "        if eval_fs:\n",
        "            for n_shot in n_shots:\n",
        "                aves_keys += ['fsa-' + str(n_shot)]\n",
        "        aves = {k: Averager() for k in aves_keys}\n",
        "\n",
        "        # train\n",
        "        model.train()\n",
        "        writer.add_scalar('lr', optimizer.param_groups[0]['lr'], epoch)\n",
        "\n",
        "        for data, label in tqdm(train_loader, desc='train', leave=False):\n",
        "            data, label = data.cuda(), label.cuda()\n",
        "            logits = model(data)\n",
        "            loss = F.cross_entropy(logits, label)\n",
        "            acc = compute_acc(logits, label)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            aves['tl'].add(loss.item())\n",
        "            aves['ta'].add(acc)\n",
        "\n",
        "            logits = None; loss = None\n",
        "\n",
        "        # eval\n",
        "        if eval_val:\n",
        "            model.eval()\n",
        "            for data, label in tqdm(val_loader, desc='val', leave=False):\n",
        "                data, label = data.cuda(), label.cuda()\n",
        "                with torch.no_grad():\n",
        "                    logits = model(data)\n",
        "                    loss = F.cross_entropy(logits, label)\n",
        "                    acc = compute_acc(logits, label)\n",
        "\n",
        "                aves['vl'].add(loss.item())\n",
        "                aves['va'].add(acc)\n",
        "\n",
        "        if eval_fs and (epoch % ef_epoch == 0 or epoch == max_epoch + 1):\n",
        "            fs_model.eval()\n",
        "            for i, n_shot in enumerate(n_shots):\n",
        "                np.random.seed(0)\n",
        "                for data, _ in tqdm(fs_loaders[i],\n",
        "                                    desc='fs-' + str(n_shot), leave=False):\n",
        "                    x_shot, x_query = split_shot_query(\n",
        "                            data.cuda(), n_way, n_shot, n_query, ep_per_batch=4)\n",
        "                    label = make_nk_label(\n",
        "                            n_way, n_query, ep_per_batch=4).cuda()\n",
        "                    with torch.no_grad():\n",
        "                        logits = fs_model(x_shot, x_query).view(-1, n_way)\n",
        "                        acc = compute_acc(logits, label)\n",
        "                    aves['fsa-' + str(n_shot)].add(acc)\n",
        "\n",
        "        # post\n",
        "        if lr_scheduler is not None:\n",
        "            lr_scheduler.step()\n",
        "\n",
        "        for k, v in aves.items():\n",
        "            aves[k] = v.item()\n",
        "\n",
        "        t_epoch = time_str(timer_epoch.t())\n",
        "        t_used = time_str(timer_used.t())\n",
        "        t_estimate = time_str(timer_used.t() / epoch * max_epoch)\n",
        "\n",
        "        if epoch <= max_epoch:\n",
        "            epoch_str = str(epoch)\n",
        "        else:\n",
        "            epoch_str = 'ex'\n",
        "        log_str = 'epoch {}, train {:.4f}|{:.4f}'.format(\n",
        "                epoch_str, aves['tl'], aves['ta'])\n",
        "        writer.add_scalars('loss', {'train': aves['tl']}, epoch)\n",
        "        writer.add_scalars('acc', {'train': aves['ta']}, epoch)\n",
        "\n",
        "        if eval_val:\n",
        "            log_str += ', val {:.4f}|{:.4f}'.format(aves['vl'], aves['va'])\n",
        "            writer.add_scalars('loss', {'val': aves['vl']}, epoch)\n",
        "            writer.add_scalars('acc', {'val': aves['va']}, epoch)\n",
        "\n",
        "        if eval_fs and (epoch % ef_epoch == 0 or epoch == max_epoch + 1):\n",
        "            log_str += ', fs'\n",
        "            for n_shot in n_shots:\n",
        "                key = 'fsa-' + str(n_shot)\n",
        "                log_str += ' {}: {:.4f}'.format(n_shot, aves[key])\n",
        "                writer.add_scalars('acc', {key: aves[key]}, epoch)\n",
        "\n",
        "        if epoch <= max_epoch:\n",
        "            log_str += ', {} {}/{}'.format(t_epoch, t_used, t_estimate)\n",
        "        else:\n",
        "            log_str += ', {}'.format(t_epoch)\n",
        "        log(log_str)\n",
        "\n",
        "        if config.get('_parallel'):\n",
        "            model_ = model.module\n",
        "        else:\n",
        "            model_ = model\n",
        "\n",
        "        training = {\n",
        "            'epoch': epoch,\n",
        "            'optimizer': config['optimizer'],\n",
        "            'optimizer_args': config['optimizer_args'],\n",
        "            'optimizer_sd': optimizer.state_dict(),\n",
        "        }\n",
        "        save_obj = {\n",
        "            'file': __file__,\n",
        "            'config': config,\n",
        "\n",
        "            'model': config['model'],\n",
        "            'model_args': config['model_args'],\n",
        "            'model_sd': model_.state_dict(),\n",
        "\n",
        "            'training': training,\n",
        "        }\n",
        "        if epoch <= max_epoch:\n",
        "            torch.save(save_obj, os.path.join(save_path, 'epoch-last.pth'))\n",
        "\n",
        "            if (save_epoch is not None) and epoch % save_epoch == 0:\n",
        "                torch.save(save_obj, os.path.join(\n",
        "                    save_path, 'epoch-{}.pth'.format(epoch)))\n",
        "\n",
        "            if aves['va'] > max_va:\n",
        "                max_va = aves['va']\n",
        "                torch.save(save_obj, os.path.join(save_path, 'max-va.pth'))\n",
        "        else:\n",
        "            torch.save(save_obj, os.path.join(save_path, 'epoch-ex.pth'))\n",
        "\n",
        "        writer.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "212c3a37",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "212c3a37",
        "outputId": "bdc03a97-276a-4307-84f4-e1748a08247f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set gpu: 4\n",
            "/content/gdrive/My Drive/tudelft/msc/quarter3/deep-learning/reproducibility-project./save/classifier_mini-imagenet_resnet12 exists, remove? ([y]/n): y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train dataset: torch.Size([3, 80, 80]) (x38400), 64\n",
            "val dataset: torch.Size([3, 80, 80]) (x18748), 64\n",
            "fs dataset: torch.Size([3, 80, 80]) (x12000), 20\n",
            "num params: 8.0M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "No CUDA GPUs are available",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d7b2c9b44186>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mset_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-3fb20028a2b7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    # parser = argparse.ArgumentParser()\n",
        "    # parser.add_argument('--config')\n",
        "    # parser.add_argument('--name', default=None)\n",
        "    # parser.add_argument('--tag', default=None)\n",
        "    # parser.add_argument('--gpu', default='0')\n",
        "    # args = parser.parse_args()\n",
        "\n",
        "    # config = yaml.load(open(args.config, 'r'), Loader=yaml.FullLoader)\n",
        "    # if len(args.gpu.split(',')) > 1:\n",
        "    #     config['_parallel'] = True\n",
        "    #     config['_gpu'] = args.gpu\n",
        "\n",
        "    config = {  'train_dataset': 'mini-imagenet',\n",
        "            'train_dataset_args': {\n",
        "                'split': 'train',\n",
        "                'augment': 'resize'\n",
        "                },\n",
        "                'val_dataset': 'mini-imagenet',\n",
        "                'val_dataset_args': {\n",
        "                    'split': 'train_phase_val'\n",
        "                    },\n",
        "                'fs_dataset': 'mini-imagenet',\n",
        "                'fs_dataset_args': {\n",
        "                    'split': 'test'\n",
        "                    },\n",
        "                'eval_fs_epoch': 5,\n",
        "                'model': 'classifier',\n",
        "                'model_args': {\n",
        "                    'encoder': 'resnet12',\n",
        "                    'encoder_args': {},\n",
        "                    'classifier': 'linear-classifier',\n",
        "                    'classifier_args': {\n",
        "                        'n_classes': 64\n",
        "                        }\n",
        "                    },\n",
        "                'batch_size': 128,\n",
        "                'max_epoch': 100,\n",
        "                'optimizer': 'sgd',\n",
        "                'optimizer_args': {\n",
        "                    'lr': 0.1,\n",
        "                    'weight_decay': 0.0005,\n",
        "                    'milestones': [90]\n",
        "                    },\n",
        "                'save_epoch': 5,\n",
        "                'visualize_datasets': True\n",
        "                }\n",
        "\n",
        "    set_gpu(\"4\")\n",
        "    main(config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ARBRZATYe6TS"
      },
      "id": "ARBRZATYe6TS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}