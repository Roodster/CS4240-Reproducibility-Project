{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7883994,"sourceType":"datasetVersion","datasetId":4627769},{"sourceId":17991,"sourceType":"modelInstanceVersion","modelInstanceId":14984},{"sourceId":19254,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":15974}],"dockerImageVersionId":30674,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorboardX","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11064,"status":"ok","timestamp":1710833268810,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"rAhYhRtWd-U3","outputId":"237d63b8-9b42-4dd1-c0f6-e52d7e26b45a","execution":{"iopub.status.busy":"2024-03-23T11:22:56.694952Z","iopub.execute_input":"2024-03-23T11:22:56.695660Z","iopub.status.idle":"2024-03-23T11:23:09.506489Z","shell.execute_reply.started":"2024-03-23T11:22:56.695629Z","shell.execute_reply":"2024-03-23T11:23:09.505382Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorboardX in /opt/conda/lib/python3.10/site-packages (2.6.2.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorboardX) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorboardX) (21.3)\nRequirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.10/site-packages (from tensorboardX) (3.20.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorboardX) (3.1.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import argparse\nimport os\nimport yaml\nimport json\nfrom PIL import Image\nimport pickle\nimport numpy as np\nimport math\nimport shutil\nimport time","metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1710833268811,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"b64c1de4","execution":{"iopub.status.busy":"2024-03-23T11:23:09.508267Z","iopub.execute_input":"2024-03-23T11:23:09.508583Z","iopub.status.idle":"2024-03-23T11:23:09.513874Z","shell.execute_reply.started":"2024-03-23T11:23:09.508552Z","shell.execute_reply":"2024-03-23T11:23:09.512822Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom tensorboardX import SummaryWriter\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom torch.optim import SGD, Adam\nfrom torch.optim.lr_scheduler import MultiStepLR\n","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1710833268811,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"37c4bcdb","execution":{"iopub.status.busy":"2024-03-23T11:23:09.515176Z","iopub.execute_input":"2024-03-23T11:23:09.515499Z","iopub.status.idle":"2024-03-23T11:23:09.525688Z","shell.execute_reply.started":"2024-03-23T11:23:09.515452Z","shell.execute_reply":"2024-03-23T11:23:09.524831Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"assert torch.cuda.is_available() == True","metadata":{"execution":{"iopub.status.busy":"2024-03-23T11:23:09.528145Z","iopub.execute_input":"2024-03-23T11:23:09.528722Z","iopub.status.idle":"2024-03-23T11:23:09.535606Z","shell.execute_reply.started":"2024-03-23T11:23:09.528682Z","shell.execute_reply":"2024-03-23T11:23:09.534589Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\n_log_path = None\n\ndef set_log_path(path):\n    global _log_path\n    _log_path = path\n\ndef log(obj, filename='log.txt'):\n    print(obj)\n    if _log_path is not None:\n        with open(os.path.join(_log_path, filename), 'a') as f:\n            print(obj, file=f)\n\n\nclass Averager():\n\n    def __init__(self):\n        self.n = 0.0\n        self.v = 0.0\n\n    def add(self, v, n=1.0):\n        self.v = (self.v * self.n + v * n) / (self.n + n)\n        self.n += n\n\n    def item(self):\n        return self.v\n\n\nclass Timer():\n\n    def __init__(self):\n        self.v = time.time()\n\n    def s(self):\n        self.v = time.time()\n\n    def t(self):\n        return time.time() - self.v\n\n\ndef set_gpu(gpu):\n    print('set gpu:', gpu)\n    os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n\n\ndef ensure_path(path, remove=True):\n    basename = os.path.basename(path.rstrip('/'))\n    if os.path.exists(path):\n        if remove and (basename.startswith('_')\n                or input('{} exists, remove? ([y]/n): '.format(path)) != 'n'):\n            shutil.rmtree(path)\n            os.makedirs(path)\n    else:\n        os.makedirs(path)\n\n\ndef time_str(t):\n    if t >= 3600:\n        return '{:.1f}h'.format(t / 3600)\n    if t >= 60:\n        return '{:.1f}m'.format(t / 60)\n    return '{:.1f}s'.format(t)\n\n\ndef compute_logits(feat, proto, metric='dot', temp=1.0):\n    assert feat.dim() == proto.dim()\n\n    if feat.dim() == 2:\n        if metric == 'dot':\n            logits = torch.mm(feat, proto.t())\n        elif metric == 'cos':\n            logits = torch.mm(F.normalize(feat, dim=-1),\n                              F.normalize(proto, dim=-1).t())\n        elif metric == 'sqr':\n            logits = -(feat.unsqueeze(1) -\n                       proto.unsqueeze(0)).pow(2).sum(dim=-1)\n\n    elif feat.dim() == 3:\n        if metric == 'dot':\n            logits = torch.bmm(feat, proto.permute(0, 2, 1))\n        elif metric == 'cos':\n            logits = torch.bmm(F.normalize(feat, dim=-1),\n                               F.normalize(proto, dim=-1).permute(0, 2, 1))\n        elif metric == 'sqr':\n            logits = -(feat.unsqueeze(2) -\n                       proto.unsqueeze(1)).pow(2).sum(dim=-1)\n\n    return logits * temp\n\n\ndef compute_acc(logits, label, reduction='mean'):\n    ret = (torch.argmax(logits, dim=1) == label).float()\n    if reduction == 'none':\n        return ret.detach()\n    elif reduction == 'mean':\n        return ret.mean().item()\n\n\ndef compute_n_params(model, return_str=True):\n    tot = 0\n    for p in model.parameters():\n        w = 1\n        for x in p.shape:\n            w *= x\n        tot += w\n    if return_str:\n        if tot >= 1e6:\n            return '{:.1f}M'.format(tot / 1e6)\n        else:\n            return '{:.1f}K'.format(tot / 1e3)\n    else:\n        return tot\n\n\ndef make_optimizer(params, name, lr, weight_decay=None, milestones=None):\n    if weight_decay is None:\n        weight_decay = 0.\n    if name == 'sgd':\n        optimizer = SGD(params, lr, momentum=0.9, weight_decay=weight_decay)\n    elif name == 'adam':\n        optimizer = Adam(params, lr, weight_decay=weight_decay)\n    if milestones:\n        lr_scheduler = MultiStepLR(optimizer, milestones)\n    else:\n        lr_scheduler = None\n    return optimizer, lr_scheduler\n\n\ndef visualize_dataset(dataset, name, writer, n_samples=16):\n    demo = []\n    for i in np.random.choice(len(dataset), n_samples):\n        demo.append(dataset.convert_raw(dataset[i][0]))\n    writer.add_images('visualize_' + name, torch.stack(demo))\n    writer.flush()\n\n\ndef freeze_bn(model):\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d):\n            m.eval()\n\n","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"zquFYmn6dAk7","execution":{"iopub.status.busy":"2024-03-23T11:26:40.066032Z","iopub.execute_input":"2024-03-23T11:26:40.066802Z","iopub.status.idle":"2024-03-23T11:26:40.092635Z","shell.execute_reply.started":"2024-03-23T11:26:40.066760Z","shell.execute_reply":"2024-03-23T11:26:40.091665Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"DEFAULT_ROOT = \"/kaggle/input/\"\ndatasets = {}\ndef datasets_register(name):\n    def decorator(cls):\n        datasets[name] = cls\n        return cls\n    return decorator\n\n\ndef datasets_make(name, **kwargs):\n    if kwargs.get('root_path') is None:\n        kwargs['root_path'] = os.path.join(DEFAULT_ROOT, name)\n    dataset = datasets[name](**kwargs)\n    return dataset\n\n","metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"zxr_LloTdAVM","execution":{"iopub.status.busy":"2024-03-23T11:26:40.503901Z","iopub.execute_input":"2024-03-23T11:26:40.504503Z","iopub.status.idle":"2024-03-23T11:26:40.510354Z","shell.execute_reply.started":"2024-03-23T11:26:40.504470Z","shell.execute_reply":"2024-03-23T11:26:40.509351Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"\n@datasets_register('image-folder')\nclass ImageFolder(Dataset):\n\n    def __init__(self, root_path, image_size=224, box_size=256, **kwargs):\n        if box_size is None:\n            box_size = image_size\n\n        self.filepaths = []\n        self.label = []\n        classes = sorted(os.listdir(root_path))\n\n        if kwargs.get('split'):\n            path = kwargs.get('split_file')\n            if path is None:\n                path = os.path.join(\n                        os.path.dirname(root_path.rstrip('/')), 'split.json')\n            split = json.load(open(path, 'r'))\n            classes = sorted(split[kwargs['split']])\n\n        for i, c in enumerate(classes):\n            for filename in sorted(os.listdir(os.path.join(root_path, c))):\n                self.filepaths.append(os.path.join(root_path, c, filename))\n                self.label.append(i)\n        self.n_classes = max(self.label) + 1\n\n        norm_params = {'mean': [0.485, 0.456, 0.406],\n                       'std': [0.229, 0.224, 0.225]}\n        normalize = transforms.Normalize(**norm_params)\n        if kwargs.get('augment'):\n            self.transform = transforms.Compose([\n                transforms.RandomResizedCrop(image_size),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                normalize,\n            ])\n        else:\n            self.transform = transforms.Compose([\n                transforms.Resize(box_size),\n                transforms.CenterCrop(image_size),\n                transforms.ToTensor(),\n                normalize,\n            ])\n\n        def convert_raw(x):\n            mean = torch.tensor(norm_params['mean']).view(3, 1, 1).type_as(x)\n            std = torch.tensor(norm_params['std']).view(3, 1, 1).type_as(x)\n            return x * std + mean\n        self.convert_raw = convert_raw\n\n    def __len__(self):\n        return len(self.filepaths)\n\n    def __getitem__(self, i):\n        img = Image.open(self.filepaths[i]).convert('RGB')\n        return self.transform(img), self.label[i]\n\n","metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"QOFXfUfkdAQG","execution":{"iopub.status.busy":"2024-03-23T11:26:40.647500Z","iopub.execute_input":"2024-03-23T11:26:40.647849Z","iopub.status.idle":"2024-03-23T11:26:40.664017Z","shell.execute_reply.started":"2024-03-23T11:26:40.647822Z","shell.execute_reply":"2024-03-23T11:26:40.662973Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"@datasets_register('mini-imagenet')\nclass MiniImageNet(Dataset):\n\n    def __init__(self, root_path, split='train', **kwargs):\n        split_tag = split\n        if split == 'train':\n            split_tag = 'train_phase_train'\n        split_file = 'miniImageNet_category_split_{}.pickle'.format(split_tag)\n        with open(os.path.join(root_path, split_file), 'rb') as f:\n            pack = pickle.load(f, encoding='latin1')\n        data = pack['data']\n        label = pack['labels']\n\n        image_size = 80\n        data = [Image.fromarray(x) for x in data]\n\n        min_label = min(label)\n        label = [x - min_label for x in label]\n\n        self.data = data\n        self.label = label\n        self.n_classes = max(self.label) + 1\n\n        norm_params = {'mean': [0.485, 0.456, 0.406],\n                       'std': [0.229, 0.224, 0.225]}\n        normalize = transforms.Normalize(**norm_params)\n        self.default_transform = transforms.Compose([\n            transforms.Resize(image_size),\n            transforms.ToTensor(),\n            normalize,\n        ])\n        augment = kwargs.get('augment')\n        if augment == 'resize':\n            self.transform = transforms.Compose([\n                transforms.RandomResizedCrop(image_size),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                normalize,\n            ])\n        elif augment == 'crop':\n            self.transform = transforms.Compose([\n                transforms.Resize(image_size),\n                transforms.RandomCrop(image_size, padding=8),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                normalize,\n            ])\n        elif augment is None:\n            self.transform = self.default_transform\n\n        def convert_raw(x):\n            mean = torch.tensor(norm_params['mean']).view(3, 1, 1).type_as(x)\n            std = torch.tensor(norm_params['std']).view(3, 1, 1).type_as(x)\n            return x * std + mean\n        self.convert_raw = convert_raw\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, i):\n        return self.transform(self.data[i]), self.label[i]\n\n","metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"k0noCslgdASp","execution":{"iopub.status.busy":"2024-03-23T11:26:40.774435Z","iopub.execute_input":"2024-03-23T11:26:40.774749Z","iopub.status.idle":"2024-03-23T11:26:40.788356Z","shell.execute_reply.started":"2024-03-23T11:26:40.774725Z","shell.execute_reply":"2024-03-23T11:26:40.787303Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"\nclass CategoriesSampler():\n\n    def __init__(self, label, n_batch, n_cls, n_per, ep_per_batch=1):\n        self.n_batch = n_batch\n        self.n_cls = n_cls\n        self.n_per = n_per\n        self.ep_per_batch = ep_per_batch\n\n        label = np.array(label)\n        self.catlocs = []\n        for c in range(max(label) + 1):\n            self.catlocs.append(np.argwhere(label == c).reshape(-1))\n\n    def __len__(self):\n        return self.n_batch\n\n    def __iter__(self):\n        for i_batch in range(self.n_batch):\n            batch = []\n            for i_ep in range(self.ep_per_batch):\n                episode = []\n                classes = np.random.choice(len(self.catlocs), self.n_cls,\n                                           replace=False)\n                for c in classes:\n                    l = np.random.choice(self.catlocs[c], self.n_per,\n                                         replace=False)\n                    episode.append(torch.from_numpy(l))\n                episode = torch.stack(episode)\n                batch.append(episode)\n            batch = torch.stack(batch) # bs * n_cls * n_per\n            yield batch.view(-1)\n\n","metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"VuoXX_6adAXy","execution":{"iopub.status.busy":"2024-03-23T11:26:40.934256Z","iopub.execute_input":"2024-03-23T11:26:40.934636Z","iopub.status.idle":"2024-03-23T11:26:40.943867Z","shell.execute_reply.started":"2024-03-23T11:26:40.934607Z","shell.execute_reply":"2024-03-23T11:26:40.942938Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"\n\nmodels = {}\ndef models_register(name):\n    def decorator(cls):\n        models[name] = cls\n        return cls\n    return decorator\n\n\ndef models_make(name, **kwargs):\n    if name is None:\n        return None\n    model = models[name](**kwargs)\n    if torch.cuda.is_available():\n        model.cuda()\n    return model\n\n\ndef models_load(model_sv, name=None):\n    if name is None:\n        name = 'model'\n    model = models_make(model_sv[name], **model_sv[name + '_args'])\n    model.load_state_dict(model_sv[name + '_sd'])\n    return model\n\n","metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1710833271164,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"TBNv3xjsiorL","execution":{"iopub.status.busy":"2024-03-23T11:26:41.118031Z","iopub.execute_input":"2024-03-23T11:26:41.118388Z","iopub.status.idle":"2024-03-23T11:26:41.125245Z","shell.execute_reply.started":"2024-03-23T11:26:41.118359Z","shell.execute_reply":"2024-03-23T11:26:41.124238Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"@models_register('classifier')\nclass Classifier(nn.Module):\n\n    def __init__(self, encoder, encoder_args,\n                 classifier, classifier_args):\n        super().__init__()\n        self.encoder = models_make(encoder, **encoder_args)\n        classifier_args['in_dim'] = self.encoder.out_dim\n        self.classifier = models_make(classifier, **classifier_args)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.classifier(x)\n        return x\n\n\n@models_register('linear-classifier')\nclass LinearClassifier(nn.Module):\n\n    def __init__(self, in_dim, n_classes):\n        super().__init__()\n        self.linear = nn.Linear(in_dim, n_classes)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\n@models_register('nn-classifier')\nclass NNClassifier(nn.Module):\n\n    def __init__(self, in_dim, n_classes, metric='cos', temp=None):\n        super().__init__()\n        self.proto = nn.Parameter(torch.empty(n_classes, in_dim))\n        nn.init.kaiming_uniform_(self.proto, a=math.sqrt(5))\n        if temp is None:\n            if metric == 'cos':\n                temp = nn.Parameter(torch.tensor(10.))\n            else:\n                temp = 1.0\n        self.metric = metric\n        self.temp = temp\n\n    def forward(self, x):\n        return utils.compute_logits(x, self.proto, self.metric, self.temp)\n\n\ndef conv_block(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n    )\n\n@models_register('convnet4-fs')\nclass ConvNet4FS(nn.Module):\n\n    def __init__(self, encoder, encoder_args,\n                 classifier, classifier_args):\n        super().__init__()\n        self.encoder = models_make(encoder, **encoder_args)\n        classifier_args['in_dim'] = self.encoder.out_dim\n        self.classifier = models_make(classifier, **classifier_args)\n\n    def forward(self, x_shot, x_query):\n        x_shot, x_query = self.encoder(x_shot, x_query)\n        x_shot, x_query = self.classifier(x_shot, x_query)\n        return x\n\n    \n    def forward(self, x_shot, x_query):\n        x_shot, x_query = self.encoder(x_shot, x_query)\n        logits = self.classifier(x_shot, x_query)\n        return logits\n\n\n@models_register('convnet4-classifier')\nclass ConvNet4Classifier(nn.Module):\n\n    def __init__(self, in_dim, n_classes, metric='cos'):\n        super().__init__()\n        self.method = metric\n    \n    def forward(self, x_shot, x_query):\n        if self.method == 'cos':\n            x_shot = x_shot.mean(dim=-2)\n            x_shot = F.normalize(x_shot, dim=-1)\n            x_query = F.normalize(x_query, dim=-1)\n            metric = 'dot'\n        elif self.method == 'sqr':\n            x_shot = x_shot.mean(dim=-2)\n            metric = 'sqr'\n\n        logits = compute_logits(\n                x_query, x_shot, metric=metric)\n        return logits\n\n@models_register('convnet4')\nclass ConvNet4(nn.Module):\n\n    def __init__(self, x_dim=3, hid_dim=64, z_dim=64):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            conv_block(x_dim, hid_dim),\n            conv_block(hid_dim, hid_dim),\n            conv_block(hid_dim, hid_dim),\n            conv_block(hid_dim, z_dim),\n        )\n        self.out_dim = 1600\n\n    def forward(self, x_shot, x_query):\n        shot_shape = x_shot.shape[:-3]\n        query_shape = x_query.shape[:-3]\n        img_shape = x_shot.shape[-3:]\n\n        x_shot = x_shot.view(-1, *img_shape)\n        x_query = x_query.view(-1, *img_shape)\n        x_tot = self.encoder(torch.cat([x_shot, x_query], dim=0))\n        x_shot, x_query = x_tot[:len(x_shot)], x_tot[-len(x_query):]\n        x_shot = x_shot.view(*shot_shape, -1)\n        x_query = x_query.view(*query_shape, -1)\n        \n        return x_shot, x_query\n","metadata":{"executionInfo":{"elapsed":456,"status":"ok","timestamp":1710833271612,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"qgF5hpSudAdA","execution":{"iopub.status.busy":"2024-03-23T11:26:41.274817Z","iopub.execute_input":"2024-03-23T11:26:41.275176Z","iopub.status.idle":"2024-03-23T11:26:41.298234Z","shell.execute_reply.started":"2024-03-23T11:26:41.275148Z","shell.execute_reply":"2024-03-23T11:26:41.297251Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"\n@models_register('meta-baseline')\nclass MetaBaseline(nn.Module):\n\n    def __init__(self, encoder, encoder_args={}, method='cos',\n                 temp=10., temp_learnable=True):\n        super().__init__()\n        self.encoder = models_make(encoder, **encoder_args)\n        self.method = method\n\n        if temp_learnable:\n            self.temp = nn.Parameter(torch.tensor(temp))\n        else:\n            self.temp = temp\n\n    def forward(self, x_shot, x_query):\n        shot_shape = x_shot.shape[:-3]\n        query_shape = x_query.shape[:-3]\n        img_shape = x_shot.shape[-3:]\n\n        x_shot = x_shot.view(-1, *img_shape)\n        x_query = x_query.view(-1, *img_shape)\n        x_tot = self.encoder(torch.cat([x_shot, x_query], dim=0))\n        x_shot, x_query = x_tot[:len(x_shot)], x_tot[-len(x_query):]\n        x_shot = x_shot.view(*shot_shape, -1)\n        x_query = x_query.view(*query_shape, -1)\n\n        if self.method == 'cos':\n            x_shot = x_shot.mean(dim=-2)\n            x_shot = F.normalize(x_shot, dim=-1)\n            x_query = F.normalize(x_query, dim=-1)\n            metric = 'dot'\n        elif self.method == 'sqr':\n            x_shot = x_shot.mean(dim=-2)\n            metric = 'sqr'\n\n        logits = compute_logits(\n                x_query, x_shot, metric=metric, temp=self.temp)\n        return logits\n\n","metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1710833271612,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"ZSZg1spbj8jJ","execution":{"iopub.status.busy":"2024-03-23T11:26:41.393656Z","iopub.execute_input":"2024-03-23T11:26:41.394498Z","iopub.status.idle":"2024-03-23T11:26:41.405016Z","shell.execute_reply.started":"2024-03-23T11:26:41.394464Z","shell.execute_reply":"2024-03-23T11:26:41.404039Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"\n__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n           'wide_resnet50_2', 'wide_resnet101_2']\n\n\ndef conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n\n\ndef conv1x1(in_planes, out_planes, stride=1):\n    \"\"\"1x1 convolution\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n    __constants__ = ['downsample']\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n                 base_width=64, dilation=1, norm_layer=None):\n        super(BasicBlock, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        if groups != 1 or base_width != 64:\n            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n        if dilation > 1:\n            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = norm_layer(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = norm_layer(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n    __constants__ = ['downsample']\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n                 base_width=64, dilation=1, norm_layer=None):\n        super(Bottleneck, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        width = int(planes * (base_width / 64.)) * groups\n        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n        self.conv1 = conv1x1(inplanes, width)\n        self.bn1 = norm_layer(width)\n        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n        self.bn2 = norm_layer(width)\n        self.conv3 = conv1x1(width, planes * self.expansion)\n        self.bn3 = norm_layer(planes * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, zero_init_residual=False,\n                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n                 norm_layer=None):\n        super(ResNet, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        self._norm_layer = norm_layer\n\n        self.inplanes = 64\n        self.dilation = 1\n        if replace_stride_with_dilation is None:\n            # each element in the tuple indicates if we should replace\n            # the 2x2 stride with a dilated convolution instead\n            replace_stride_with_dilation = [False, False, False]\n        if len(replace_stride_with_dilation) != 3:\n            raise ValueError(\"replace_stride_with_dilation should be None \"\n                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n        self.groups = groups\n        self.base_width = width_per_group\n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = norm_layer(self.inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n                                       dilate=replace_stride_with_dilation[0])\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n                                       dilate=replace_stride_with_dilation[1])\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n                                       dilate=replace_stride_with_dilation[2])\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.out_dim = 512 * block.expansion\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n        # Zero-initialize the last BN in each residual branch,\n        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n        if zero_init_residual:\n            for m in self.modules():\n                if isinstance(m, Bottleneck):\n                    nn.init.constant_(m.bn3.weight, 0)\n                elif isinstance(m, BasicBlock):\n                    nn.init.constant_(m.bn2.weight, 0)\n\n    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n        norm_layer = self._norm_layer\n        downsample = None\n        previous_dilation = self.dilation\n        if dilate:\n            self.dilation *= stride\n            stride = 1\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv1x1(self.inplanes, planes * block.expansion, stride),\n                norm_layer(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n                            self.base_width, previous_dilation, norm_layer))\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes, groups=self.groups,\n                                base_width=self.base_width, dilation=self.dilation,\n                                norm_layer=norm_layer))\n\n        return nn.Sequential(*layers)\n\n    def _forward_impl(self, x):\n        # See note [TorchScript super()]\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n\n        return x\n\n    def forward(self, x):\n        return self._forward_impl(x)\n\n\ndef _resnet(arch, block, layers, pretrained, progress, **kwargs):\n    model = ResNet(block, layers, **kwargs)\n    return model\n\n","metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1710833271613,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"Fiv27JoYdAfm","execution":{"iopub.status.busy":"2024-03-23T11:26:41.556542Z","iopub.execute_input":"2024-03-23T11:26:41.556873Z","iopub.status.idle":"2024-03-23T11:26:41.594129Z","shell.execute_reply.started":"2024-03-23T11:26:41.556845Z","shell.execute_reply":"2024-03-23T11:26:41.593125Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"\ndef conv3x3(in_planes, out_planes):\n    return nn.Conv2d(in_planes, out_planes, 3, padding=1, bias=False)\n\n\ndef conv1x1(in_planes, out_planes):\n    return nn.Conv2d(in_planes, out_planes, 1, bias=False)\n\n\ndef norm_layer(planes):\n    return nn.BatchNorm2d(planes)\n\n\nclass Block(nn.Module):\n\n    def __init__(self, inplanes, planes, downsample):\n        super().__init__()\n\n        self.relu = nn.LeakyReLU(0.1)\n\n        self.conv1 = conv3x3(inplanes, planes)\n        self.bn1 = norm_layer(planes)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = norm_layer(planes)\n        self.conv3 = conv3x3(planes, planes)\n        self.bn3 = norm_layer(planes)\n\n        self.downsample = downsample\n\n        self.maxpool = nn.MaxPool2d(2)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        out = self.maxpool(out)\n\n        return out\n\n\nclass ResNet12(nn.Module):\n\n    def __init__(self, channels):\n        super().__init__()\n\n        self.inplanes = 3\n\n        self.layer1 = self._make_layer(channels[0])\n        self.layer2 = self._make_layer(channels[1])\n        self.layer3 = self._make_layer(channels[2])\n        self.layer4 = self._make_layer(channels[3])\n\n        self.out_dim = channels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out',\n                                        nonlinearity='leaky_relu')\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def _make_layer(self, planes):\n        downsample = nn.Sequential(\n            conv1x1(self.inplanes, planes),\n            norm_layer(planes),\n        )\n        block = Block(self.inplanes, planes, downsample)\n        self.inplanes = planes\n        return block\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = x.view(x.shape[0], x.shape[1], -1).mean(dim=2)\n        return x\n\n\n@models_register('resnet12')\ndef resnet12():\n    return ResNet12([64, 128, 256, 512])\n\n\n@models_register('resnet12-wide')\ndef resnet12_wide():\n    return ResNet12([64, 160, 320, 640])\n\n","metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1710833271613,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"Vj0MBInqdAiX","execution":{"iopub.status.busy":"2024-03-23T11:26:41.755167Z","iopub.execute_input":"2024-03-23T11:26:41.755776Z","iopub.status.idle":"2024-03-23T11:26:41.773623Z","shell.execute_reply.started":"2024-03-23T11:26:41.755743Z","shell.execute_reply":"2024-03-23T11:26:41.772634Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"\n\ndef split_shot_query(data, way, shot, query, ep_per_batch=1):\n    img_shape = data.shape[1:]\n    data = data.view(ep_per_batch, way, shot + query, *img_shape)\n    x_shot, x_query = data.split([shot, query], dim=2)\n    x_shot = x_shot.contiguous()\n    x_query = x_query.contiguous().view(ep_per_batch, way * query, *img_shape)\n    return x_shot, x_query\n\n\ndef make_nk_label(n, k, ep_per_batch=1):\n    label = torch.arange(n).unsqueeze(1).expand(n, k).reshape(-1)\n    label = label.repeat(ep_per_batch)\n    return label\n\n","metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1710833271613,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"DATVlOexdAnf","execution":{"iopub.status.busy":"2024-03-23T11:26:41.916869Z","iopub.execute_input":"2024-03-23T11:26:41.917223Z","iopub.status.idle":"2024-03-23T11:26:41.924605Z","shell.execute_reply.started":"2024-03-23T11:26:41.917190Z","shell.execute_reply":"2024-03-23T11:26:41.923478Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"\n# OUR LOSS FUNCTION\ndef kd_loss(student_outputs, labels, teacher_outputs, temperature, alpha):\n    KD_loss = nn.KLDivLoss()(F.log_softmax(student_outputs/temperature, dim=1), F.softmax(teacher_outputs/temperature,dim=1)) *  (alpha * temperature * temperature) + F.cross_entropy(student_outputs, labels) * (1. - alpha)\n    return KD_loss","metadata":{"execution":{"iopub.status.busy":"2024-03-23T11:26:42.360723Z","iopub.execute_input":"2024-03-23T11:26:42.361101Z","iopub.status.idle":"2024-03-23T11:26:42.367134Z","shell.execute_reply.started":"2024-03-23T11:26:42.361070Z","shell.execute_reply":"2024-03-23T11:26:42.366126Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"\ndef main(config):\n    svname = config.get('name')\n    if svname is None:\n        svname = 'conv4_{}-{}shot'.format(\n                config['train_dataset'], config['k_shot'])\n        svname += '_' + config['student_model'] + '-' + config['student_model_args']['encoder']\n    if config.get('tag') is not None:\n        svname += '_' + config.get('tag')\n    save_path = os.path.join('/kaggle/working/output/save', svname)\n    ensure_path(save_path)\n    set_log_path(save_path)\n    writer = SummaryWriter(os.path.join(save_path, 'tensorboard'))\n\n    yaml.dump(config, open(os.path.join(save_path, 'config.yaml'), 'w'))\n\n    #### Dataset ####\n\n    n_way, k_shot = config['n_way'], config['k_shot']\n    n_query = config['n_query']\n\n    if config.get('n_train_way') is not None:\n        n_train_way = config['n_train_way']\n    else:\n        n_train_way = n_way\n    if config.get('n_train_shot') is not None:\n        n_train_shot = config['n_train_shot']\n    else:\n        n_train_shot = k_shot\n    if config.get('ep_per_batch') is not None:\n        ep_per_batch = config['ep_per_batch']\n    else:\n        ep_per_batch = 1\n\n    # train\n    train_dataset = datasets_make(config['train_dataset'],\n                                  **config['train_dataset_args'])\n    log('train dataset: {} (x{}), {}'.format(\n            train_dataset[0][0].shape, len(train_dataset),\n            train_dataset.n_classes))\n    if config.get('visualize_datasets'):\n        visualize_dataset(train_dataset, 'train_dataset', writer)\n    train_sampler = CategoriesSampler(\n            train_dataset.label, config['train_batches'],\n            n_train_way, n_train_shot + n_query,\n            ep_per_batch=ep_per_batch)\n    train_loader = DataLoader(train_dataset, batch_sampler=train_sampler,\n                              num_workers=4, pin_memory=True)\n\n    # tval\n    if config.get('tval_dataset'):\n        tval_dataset = datasets_make(config['tval_dataset'],\n                                     **config['tval_dataset_args'])\n        log('tval dataset: {} (x{}), {}'.format(\n                tval_dataset[0][0].shape, len(tval_dataset),\n                tval_dataset.n_classes))\n        if config.get('visualize_datasets'):\n            visualize_dataset(tval_dataset, 'tval_dataset', writer)\n        tval_sampler = CategoriesSampler(\n                tval_dataset.label, 200,\n                n_way, k_shot + n_query,\n                ep_per_batch=4)\n        tval_loader = DataLoader(tval_dataset, batch_sampler=tval_sampler,\n                                 num_workers=4, pin_memory=True)\n    else:\n        tval_loader = None\n\n    # val\n    val_dataset = datasets_make(config['val_dataset'],\n                                **config['val_dataset_args'])\n    log('val dataset: {} (x{}), {}'.format(\n            val_dataset[0][0].shape, len(val_dataset),\n            val_dataset.n_classes))\n    if config.get('visualize_datasets'):\n        visualize_dataset(val_dataset, 'val_dataset', writer)\n    val_sampler = CategoriesSampler(\n            val_dataset.label, 200,\n            n_way, k_shot + n_query,\n            ep_per_batch=4)\n    val_loader = DataLoader(val_dataset, batch_sampler=val_sampler,\n                            num_workers=4, pin_memory=True)\n\n    ########\n\n    #### Model and optimizer ####\n\n    # LOAD STUDENT MODEL\n    \n    if config.get('student_load'):\n        student_model_sv = torch.load(config['student_load'])\n        student_model = models_load(student_model_sv)\n    else:\n        student_model = models_make(config['student_model'], **config['student_model_args'])\n    \n    # LOAD TEACHER MODEL\n    # model\n    if config.get('teacher_load') is None:\n        teacher_model = models_make('meta-baseline', encoder=None)\n    else:\n        teacher_model = models_load(torch.load(config['teacher_load']))\n    \n    \n    # Freeze all layers\n    for param in teacher_model.parameters():\n        param.requires_grad = False\n\n    if config.get('_parallel'):\n        student_model = nn.DataParallel(student_model)\n\n    log('num params: {}'.format(compute_n_params(student_model)))\n\n    optimizer, lr_scheduler = make_optimizer(\n            student_model.parameters(),\n            config['optimizer'], **config['optimizer_args'])\n\n    ########\n    \n    \n    # HYPER PARAMETERS\n    temperature = config['temperature']\n    alpha = config['alpha']\n    \n    max_epoch = config['max_epoch']\n    save_epoch = config.get('save_epoch')\n    max_va = 0.\n    timer_used = Timer()\n    timer_epoch = Timer()\n\n    aves_keys = ['tl', 'ta', 'tvl', 'tva', 'vl', 'va']\n    trlog = dict()\n    for k in aves_keys:\n        trlog[k] = []\n\n    for epoch in range(1, max_epoch + 1):\n        timer_epoch.s()\n        aves = {k: Averager() for k in aves_keys}\n\n        # train\n        student_model.train()\n        if config.get('freeze_bn'):\n            freeze_bn(model) \n        writer.add_scalar('lr', optimizer.param_groups[0]['lr'], epoch)\n\n        np.random.seed(epoch)\n        for data, _ in tqdm(train_loader, desc='train', leave=False):\n            x_shot, x_query = split_shot_query(\n                    data.cuda(), n_train_way, n_train_shot, n_query,\n                    ep_per_batch=ep_per_batch)\n            labels = make_nk_label(n_train_way, n_query,\n                    ep_per_batch=ep_per_batch).cuda()\n\n            teacher_output = teacher_model(x_shot, x_query).view(-1, n_train_way)    \n            student_outputs = student_model(x_shot, x_query).view(-1, n_train_way)\n            loss = F.cross_entropy(student_outputs, labels)\n            loss = kd_loss(student_outputs,labels,teacher_output,temperature,\n                        alpha)\n            \n            acc = compute_acc(student_outputs, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            aves['tl'].add(loss.item())\n            aves['ta'].add(acc)\n\n            student_output = None; teacher_output = None; loss = None \n\n        # eval\n        student_model.eval()\n\n        for name, loader, name_l, name_a in [\n                ('tval', tval_loader, 'tvl', 'tva'),\n                ('val', val_loader, 'vl', 'va')]:\n\n            if (config.get('tval_dataset') is None) and name == 'tval':\n                continue\n\n            np.random.seed(0)\n            for data, _ in tqdm(loader, desc=name, leave=False):\n                x_shot, x_query = split_shot_query(\n                        data.cuda(), n_way, k_shot, n_query,\n                        ep_per_batch=4)\n                \n                labels = make_nk_label(n_way, n_query,\n                        ep_per_batch=4).cuda()\n\n                with torch.no_grad():\n                    teacher_outputs = teacher_model(x_shot, x_query).view(-1, n_way)\n                    student_outputs = student_model(x_shot, x_query).view(-1, n_way)\n                    \n                    loss = F.cross_entropy(student_outputs, labels)\n                    loss = kd_loss(student_outputs,labels,teacher_outputs,temperature,\n                        alpha)\n                    acc = compute_acc(student_outputs, labels)\n                \n                aves[name_l].add(loss.item())\n                aves[name_a].add(acc)\n\n        _sig = int(_[-1])\n\n        # post\n        if lr_scheduler is not None:\n            lr_scheduler.step()\n\n        for k, v in aves.items():\n            aves[k] = v.item()\n            trlog[k].append(aves[k])\n\n        t_epoch = time_str(timer_epoch.t())\n        t_used = time_str(timer_used.t())\n        t_estimate = time_str(timer_used.t() / epoch * max_epoch)\n        log('epoch {}, train {:.4f}|{:.4f}, tval {:.4f}|{:.4f}, '\n                'val {:.4f}|{:.4f}, {} {}/{} (@{})'.format(\n                epoch, aves['tl'], aves['ta'], aves['tvl'], aves['tva'],\n                aves['vl'], aves['va'], t_epoch, t_used, t_estimate, _sig))\n\n        writer.add_scalars('loss', {\n            'train': aves['tl'],\n            'tval': aves['tvl'],\n            'val': aves['vl'],\n        }, epoch)\n        writer.add_scalars('acc', {\n            'train': aves['ta'],\n            'tval': aves['tva'],\n            'val': aves['va'],\n        }, epoch)\n\n        if config.get('_parallel'):\n            student_model_ = student_model.module\n        else:\n            student_model_ = student_model\n\n        training = {\n            'epoch': epoch,\n            'optimizer': config['optimizer'],\n            'optimizer_args': config['optimizer_args'],\n            'optimizer_sd': optimizer.state_dict(),\n        }\n        save_obj = {\n            'file': './train_kd_kaggle.ipynb',\n            'config': config,\n\n            'model': config['student_model'],\n            'model_args': config['student_model_args'],\n            'model_sd': student_model_.state_dict(),\n\n            'training': training,\n        }\n        torch.save(save_obj, os.path.join(save_path, 'epoch-last.pth'))\n        torch.save(trlog, os.path.join(save_path, 'trlog.pth'))\n\n        if (save_epoch is not None) and epoch % save_epoch == 0:\n            torch.save(save_obj,\n                    os.path.join(save_path, 'epoch-{}.pth'.format(epoch)))\n\n        if aves['va'] > max_va:\n            max_va = aves['va']\n            torch.save(save_obj, os.path.join(save_path, 'max-va.pth'))\n\n        writer.flush()\n\n","metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1710833271614,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"b23e2e2e","execution":{"iopub.status.busy":"2024-03-23T12:40:03.692067Z","iopub.execute_input":"2024-03-23T12:40:03.692447Z","iopub.status.idle":"2024-03-23T12:40:03.733635Z","shell.execute_reply.started":"2024-03-23T12:40:03.692410Z","shell.execute_reply":"2024-03-23T12:40:03.732545Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"assert torch.cuda.is_available() == True\nprint(f'number of cuda devices: {torch.cuda.device_count()}')","metadata":{"execution":{"iopub.status.busy":"2024-03-23T12:40:04.216910Z","iopub.execute_input":"2024-03-23T12:40:04.217654Z","iopub.status.idle":"2024-03-23T12:40:04.222445Z","shell.execute_reply.started":"2024-03-23T12:40:04.217613Z","shell.execute_reply":"2024-03-23T12:40:04.221508Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"number of cuda devices: 1\n","output_type":"stream"}]},{"cell_type":"code","source":"if __name__ == '__main__':\n\n    torch.cuda.empty_cache()\n    \n    config = {'train_dataset': 'mini-imagenet', \n              'train_dataset_args': {\n                  'split': 'train'\n              }, \n              'tval_dataset': 'mini-imagenet', \n              'tval_dataset_args': {\n                  'split': 'test'\n              }, \n              'val_dataset': 'mini-imagenet', \n              'val_dataset_args': {\n                  'split': 'val'\n              }, \n              'student_model': 'convnet4-fs', \n              'student_model_args': {\n                  'encoder': 'convnet4', \n                  'encoder_args': {},\n                  'classifier': 'convnet4-classifier',\n                  'classifier_args': {'n_classes': 5}\n              }, \n              'teacher_model': 'meta-baseline',\n              'teacher_model_args': {\n                  'encoder': 'resnet12',\n                  'encoder_rags': {},\n              }, \n#               'student_load': '/kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-40.pth',\n              'teacher_load': '/kaggle/input/meta-classifier/pytorch/meta-classifier-5way5shot_epoch20/1/epoch-20.pth', \n              'n_way': 5,\n              # CHANGE TO EITHER 1 OR 5 DEPENDING ON YOUR OBJECTIVE\n              'k_shot': 5, \n              'n_query': 15, \n              'train_batches': 200, \n              'ep_per_batch': 4, \n              'max_epoch': 100, \n              'save_epoch': 5,\n              'optimizer': 'sgd', \n              'optimizer_args': {\n                  'lr': 0.001, \n                  'weight_decay': 0.0005\n              }, \n              'visualize_datasets': True,\n              'tag': None, \n              'name': None,\n              'temperature': 1,\n              'alpha': 0.5\n             }\n\n    set_gpu(\"4\")\n    main(config)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"212c3a37","lines_to_next_cell":2,"outputId":"18dad718-8021-48cb-bea5-998b0faab9a6","execution":{"iopub.status.busy":"2024-03-23T13:23:38.899529Z","iopub.execute_input":"2024-03-23T13:23:38.899900Z","iopub.status.idle":"2024-03-23T17:45:46.059834Z","shell.execute_reply.started":"2024-03-23T13:23:38.899864Z","shell.execute_reply":"2024-03-23T17:45:46.058714Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"set gpu: 4\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"/kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4 exists, remove? ([y]/n):  y\n"},{"name":"stderr","text":"Exception ignored in: <function _ConnectionBase.__del__ at 0x79dd1d5cf910>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 132, in __del__\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\nException in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\nException ignored in: <function _ConnectionBase.__del__ at 0x79dd1d5cf910>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 132, in __del__\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\n","output_type":"stream"},{"name":"stdout","text":"train dataset: torch.Size([3, 80, 80]) (x38400), 64\ntval dataset: torch.Size([3, 80, 80]) (x12000), 20\nval dataset: torch.Size([3, 80, 80]) (x9600), 16\nnum params: 113.1K\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 1, train 0.9072|0.4387, tval 0.8530|0.4000, val 0.8510|0.4112, 2.6m 2.6m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 2, train 0.8938|0.4381, tval 0.8478|0.3941, val 0.8427|0.4078, 2.6m 5.2m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 3, train 0.8862|0.4350, tval 0.8441|0.3844, val 0.8376|0.4018, 2.6m 7.8m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 4, train 0.8795|0.4342, tval 0.8422|0.3768, val 0.8348|0.3977, 2.6m 10.5m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 5, train 0.8750|0.4282, tval 0.8412|0.3744, val 0.8315|0.3960, 2.6m 13.1m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 6, train 0.8733|0.4245, tval 0.8397|0.3728, val 0.8310|0.3935, 2.6m 15.7m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 7, train 0.8691|0.4300, tval 0.8397|0.3698, val 0.8295|0.3897, 2.6m 18.3m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 8, train 0.8671|0.4289, tval 0.8395|0.3704, val 0.8284|0.3884, 2.6m 20.9m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 9, train 0.8654|0.4333, tval 0.8398|0.3702, val 0.8272|0.3885, 2.6m 23.6m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 10, train 0.8638|0.4326, tval 0.8389|0.3690, val 0.8278|0.3861, 2.6m 26.2m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 11, train 0.8659|0.4243, tval 0.8381|0.3725, val 0.8266|0.3879, 2.6m 28.8m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 12, train 0.8616|0.4372, tval 0.8367|0.3731, val 0.8258|0.3861, 2.6m 31.4m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 13, train 0.8623|0.4312, tval 0.8363|0.3723, val 0.8265|0.3865, 2.6m 34.0m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 14, train 0.8602|0.4385, tval 0.8344|0.3758, val 0.8259|0.3873, 2.6m 36.6m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 15, train 0.8592|0.4347, tval 0.8329|0.3807, val 0.8243|0.3896, 2.6m 39.3m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 16, train 0.8609|0.4360, tval 0.8321|0.3830, val 0.8241|0.3889, 2.6m 41.9m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 17, train 0.8582|0.4388, tval 0.8304|0.3875, val 0.8229|0.3926, 2.6m 44.5m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 18, train 0.8590|0.4369, tval 0.8295|0.3875, val 0.8238|0.3917, 2.6m 47.1m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 19, train 0.8566|0.4463, tval 0.8275|0.3935, val 0.8229|0.3956, 2.6m 49.7m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 20, train 0.8581|0.4404, tval 0.8275|0.3952, val 0.8218|0.3958, 2.6m 52.3m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 21, train 0.8569|0.4426, tval 0.8271|0.3938, val 0.8223|0.3963, 2.6m 54.9m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 22, train 0.8560|0.4442, tval 0.8263|0.3971, val 0.8213|0.3974, 2.6m 57.6m/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 23, train 0.8528|0.4539, tval 0.8239|0.4024, val 0.8191|0.4007, 2.6m 1.0h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 24, train 0.8563|0.4440, tval 0.8219|0.4074, val 0.8182|0.4035, 2.6m 1.0h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 25, train 0.8528|0.4548, tval 0.8210|0.4067, val 0.8190|0.4021, 2.6m 1.1h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 26, train 0.8519|0.4552, tval 0.8191|0.4102, val 0.8190|0.4001, 2.6m 1.1h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 27, train 0.8514|0.4566, tval 0.8159|0.4185, val 0.8179|0.4058, 2.6m 1.2h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 28, train 0.8519|0.4595, tval 0.8177|0.4113, val 0.8169|0.4089, 2.6m 1.2h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 29, train 0.8498|0.4542, tval 0.8176|0.4105, val 0.8202|0.3987, 2.6m 1.3h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 30, train 0.8500|0.4595, tval 0.8154|0.4188, val 0.8173|0.4081, 2.6m 1.3h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 31, train 0.8487|0.4589, tval 0.8145|0.4163, val 0.8198|0.4009, 2.6m 1.4h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 32, train 0.8482|0.4625, tval 0.8119|0.4243, val 0.8157|0.4098, 2.6m 1.4h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 33, train 0.8501|0.4575, tval 0.8130|0.4250, val 0.8144|0.4127, 2.6m 1.4h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 34, train 0.8494|0.4601, tval 0.8102|0.4268, val 0.8157|0.4088, 2.6m 1.5h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 35, train 0.8482|0.4639, tval 0.8092|0.4291, val 0.8142|0.4151, 2.6m 1.5h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 36, train 0.8461|0.4733, tval 0.8084|0.4321, val 0.8133|0.4161, 2.6m 1.6h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 37, train 0.8457|0.4720, tval 0.8141|0.4232, val 0.8155|0.4140, 2.6m 1.6h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 38, train 0.8478|0.4624, tval 0.8098|0.4272, val 0.8137|0.4147, 2.6m 1.7h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 39, train 0.8462|0.4703, tval 0.8119|0.4236, val 0.8180|0.4052, 2.6m 1.7h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 40, train 0.8472|0.4669, tval 0.8068|0.4356, val 0.8123|0.4193, 2.6m 1.7h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 41, train 0.8445|0.4741, tval 0.8088|0.4307, val 0.8151|0.4155, 2.6m 1.8h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 42, train 0.8429|0.4808, tval 0.8059|0.4344, val 0.8132|0.4148, 2.6m 1.8h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 43, train 0.8429|0.4753, tval 0.8063|0.4360, val 0.8140|0.4142, 2.6m 1.9h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 44, train 0.8446|0.4727, tval 0.8085|0.4296, val 0.8163|0.4084, 2.6m 1.9h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 45, train 0.8435|0.4741, tval 0.8036|0.4380, val 0.8125|0.4196, 2.6m 2.0h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 46, train 0.8440|0.4767, tval 0.8065|0.4345, val 0.8119|0.4206, 2.6m 2.0h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 47, train 0.8416|0.4851, tval 0.8098|0.4307, val 0.8158|0.4144, 2.6m 2.0h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 48, train 0.8409|0.4846, tval 0.8052|0.4386, val 0.8128|0.4206, 2.6m 2.1h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 49, train 0.8410|0.4876, tval 0.8015|0.4434, val 0.8108|0.4192, 2.6m 2.1h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 50, train 0.8439|0.4760, tval 0.8071|0.4370, val 0.8137|0.4142, 2.6m 2.2h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 51, train 0.8417|0.4780, tval 0.8093|0.4303, val 0.8160|0.4112, 2.6m 2.2h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 52, train 0.8406|0.4835, tval 0.8049|0.4387, val 0.8137|0.4191, 2.6m 2.3h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 53, train 0.8423|0.4812, tval 0.8015|0.4458, val 0.8136|0.4202, 2.6m 2.3h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 54, train 0.8400|0.4903, tval 0.8036|0.4425, val 0.8109|0.4227, 2.6m 2.4h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 55, train 0.8397|0.4896, tval 0.8009|0.4495, val 0.8133|0.4207, 2.6m 2.4h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 56, train 0.8418|0.4854, tval 0.8043|0.4397, val 0.8152|0.4149, 2.6m 2.4h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 57, train 0.8390|0.4931, tval 0.7986|0.4524, val 0.8088|0.4261, 2.6m 2.5h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 58, train 0.8372|0.4918, tval 0.8006|0.4475, val 0.8107|0.4241, 2.6m 2.5h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 59, train 0.8376|0.4912, tval 0.7997|0.4468, val 0.8088|0.4283, 2.6m 2.6h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 60, train 0.8373|0.4949, tval 0.8003|0.4486, val 0.8127|0.4190, 2.6m 2.6h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 61, train 0.8376|0.4950, tval 0.8010|0.4529, val 0.8106|0.4235, 2.6m 2.7h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 62, train 0.8373|0.4922, tval 0.8032|0.4429, val 0.8127|0.4184, 2.6m 2.7h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 63, train 0.8360|0.4977, tval 0.8007|0.4513, val 0.8133|0.4192, 2.6m 2.7h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 64, train 0.8372|0.4947, tval 0.7975|0.4530, val 0.8076|0.4297, 2.6m 2.8h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 65, train 0.8356|0.5014, tval 0.8036|0.4476, val 0.8120|0.4212, 2.6m 2.8h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 66, train 0.8353|0.4977, tval 0.7965|0.4601, val 0.8088|0.4310, 2.6m 2.9h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 67, train 0.8366|0.4976, tval 0.7998|0.4514, val 0.8099|0.4236, 2.6m 2.9h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 68, train 0.8354|0.5034, tval 0.8027|0.4504, val 0.8125|0.4220, 2.6m 3.0h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 69, train 0.8362|0.4998, tval 0.7960|0.4548, val 0.8096|0.4276, 2.6m 3.0h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 70, train 0.8347|0.5031, tval 0.7976|0.4577, val 0.8070|0.4330, 2.6m 3.1h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 71, train 0.8360|0.4995, tval 0.8101|0.4348, val 0.8139|0.4186, 2.6m 3.1h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 72, train 0.8359|0.5007, tval 0.7956|0.4552, val 0.8100|0.4263, 2.6m 3.1h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 73, train 0.8342|0.5036, tval 0.7960|0.4580, val 0.8083|0.4329, 2.6m 3.2h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 74, train 0.8349|0.5069, tval 0.7985|0.4611, val 0.8108|0.4235, 2.6m 3.2h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 75, train 0.8325|0.5070, tval 0.7986|0.4533, val 0.8073|0.4296, 2.6m 3.3h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 76, train 0.8338|0.5084, tval 0.7963|0.4561, val 0.8077|0.4316, 2.6m 3.3h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 77, train 0.8335|0.5096, tval 0.8003|0.4510, val 0.8086|0.4211, 2.6m 3.4h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 78, train 0.8326|0.5110, tval 0.7946|0.4612, val 0.8084|0.4298, 2.6m 3.4h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 79, train 0.8325|0.5077, tval 0.7957|0.4588, val 0.8088|0.4278, 2.6m 3.4h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 80, train 0.8319|0.5118, tval 0.7945|0.4600, val 0.8060|0.4313, 2.6m 3.5h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 81, train 0.8333|0.5075, tval 0.7970|0.4603, val 0.8086|0.4323, 2.6m 3.5h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 82, train 0.8311|0.5119, tval 0.7993|0.4521, val 0.8125|0.4269, 2.6m 3.6h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 97, train 0.8279|0.5225, tval 0.7916|0.4696, val 0.8033|0.4407, 2.6m 4.2h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 98, train 0.8282|0.5240, tval 0.7936|0.4626, val 0.8024|0.4363, 2.6m 4.3h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 99, train 0.8294|0.5153, tval 0.7948|0.4537, val 0.8033|0.4377, 2.6m 4.3h/4.4h (@7)\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 100, train 0.8283|0.5193, tval 0.7927|0.4680, val 0.8039|0.4352, 2.6m 4.4h/4.4h (@7)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r file.zip /kaggle/working","metadata":{"id":"ARBRZATYe6TS","execution":{"iopub.status.busy":"2024-03-23T18:08:21.530249Z","iopub.execute_input":"2024-03-23T18:08:21.530900Z","iopub.status.idle":"2024-03-23T18:08:23.716616Z","shell.execute_reply.started":"2024-03-23T18:08:21.530844Z","shell.execute_reply":"2024-03-23T18:08:23.715578Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"updating: kaggle/working/ (stored 0%)\nupdating: kaggle/working/.virtual_documents/ (stored 0%)\nupdating: kaggle/working/output/ (stored 0%)\nupdating: kaggle/working/output/save/ (stored 0%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/ (stored 0%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/log.txt (deflated 77%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-10.pth (deflated 8%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-35.pth (deflated 8%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/config.yaml (deflated 55%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-40.pth (deflated 8%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-5.pth (deflated 8%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/trlog.pth (deflated 38%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-15.pth (deflated 8%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-25.pth (deflated 8%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-30.pth (deflated 8%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/tensorboard/ (stored 0%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/tensorboard/loss/ (stored 0%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/tensorboard/loss/val/ (stored 0%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/tensorboard/loss/tval/ (stored 0%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/tensorboard/loss/train/ (stored 0%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/tensorboard/acc/ (stored 0%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/tensorboard/acc/val/ (stored 0%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/tensorboard/acc/tval/ (stored 0%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/tensorboard/acc/train/ (stored 0%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-20.pth (deflated 8%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-last.pth (deflated 8%)\nupdating: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/max-va.pth (deflated 8%)\nupdating: kaggle/working/state.db (deflated 88%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-95.pth (deflated 8%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-60.pth (deflated 8%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-100.pth (deflated 8%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-50.pth (deflated 8%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-70.pth (deflated 8%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-75.pth (deflated 8%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-55.pth (deflated 8%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-80.pth (deflated 8%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/tensorboard/loss/train/events.out.tfevents.1711200407.0def2f3a30aa (deflated 57%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/tensorboard/loss/val/events.out.tfevents.1711200407.0def2f3a30aa (deflated 57%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/tensorboard/loss/tval/events.out.tfevents.1711200407.0def2f3a30aa (deflated 57%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/tensorboard/acc/train/events.out.tfevents.1711200407.0def2f3a30aa (deflated 56%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/tensorboard/acc/val/events.out.tfevents.1711200407.0def2f3a30aa (deflated 56%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/tensorboard/acc/tval/events.out.tfevents.1711200407.0def2f3a30aa (deflated 56%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/tensorboard/events.out.tfevents.1711200229.0def2f3a30aa (deflated 0%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-65.pth (deflated 8%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-45.pth (deflated 8%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-85.pth (deflated 8%)\n  adding: kaggle/working/output/save/conv4_mini-imagenet-5shot_convnet4-fs-convnet4/epoch-90.pth (deflated 8%)\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'file.zip')","metadata":{"execution":{"iopub.status.busy":"2024-03-23T18:08:27.663742Z","iopub.execute_input":"2024-03-23T18:08:27.664629Z","iopub.status.idle":"2024-03-23T18:08:27.670412Z","shell.execute_reply.started":"2024-03-23T18:08:27.664593Z","shell.execute_reply":"2024-03-23T18:08:27.669467Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/file.zip","text/html":"<a href='file.zip' target='_blank'>file.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}