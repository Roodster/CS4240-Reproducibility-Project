{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-03-19T21:51:39.661951Z","iopub.status.busy":"2024-03-19T21:51:39.661694Z","iopub.status.idle":"2024-03-19T21:52:13.326354Z","shell.execute_reply":"2024-03-19T21:52:13.325204Z","shell.execute_reply.started":"2024-03-19T21:51:39.661929Z"},"executionInfo":{"elapsed":11064,"status":"ok","timestamp":1710833268810,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"rAhYhRtWd-U3","outputId":"237d63b8-9b42-4dd1-c0f6-e52d7e26b45a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorboardX in /opt/conda/lib/python3.10/site-packages (2.6.2.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorboardX) (1.26.4)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorboardX) (21.3)\n","Requirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.10/site-packages (from tensorboardX) (3.20.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorboardX) (3.1.1)\n"]}],"source":["!pip install tensorboardX"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T21:52:13.328657Z","iopub.status.busy":"2024-03-19T21:52:13.328334Z","iopub.status.idle":"2024-03-19T21:52:13.333994Z","shell.execute_reply":"2024-03-19T21:52:13.332984Z","shell.execute_reply.started":"2024-03-19T21:52:13.328627Z"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1710833268811,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"b64c1de4","trusted":true},"outputs":[],"source":["import argparse\n","import os\n","import yaml\n","import json\n","from PIL import Image\n","import pickle\n","import numpy as np\n","import math\n","import shutil\n","import time"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T21:52:13.335835Z","iopub.status.busy":"2024-03-19T21:52:13.335390Z","iopub.status.idle":"2024-03-19T21:52:13.346960Z","shell.execute_reply":"2024-03-19T21:52:13.346019Z","shell.execute_reply.started":"2024-03-19T21:52:13.335804Z"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1710833268811,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"37c4bcdb","trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader\n","from tensorboardX import SummaryWriter\n","from torch.utils.data import Dataset\n","from torchvision import transforms\n","from torch.optim import SGD, Adam\n","from torch.optim.lr_scheduler import MultiStepLR\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T21:52:13.349595Z","iopub.status.busy":"2024-03-19T21:52:13.349298Z","iopub.status.idle":"2024-03-19T21:52:13.409643Z","shell.execute_reply":"2024-03-19T21:52:13.408885Z","shell.execute_reply.started":"2024-03-19T21:52:13.349572Z"},"trusted":true},"outputs":[],"source":["assert torch.cuda.is_available() == True"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-03-19T21:52:13.411193Z","iopub.status.busy":"2024-03-19T21:52:13.410844Z","iopub.status.idle":"2024-03-19T21:52:13.421639Z","shell.execute_reply":"2024-03-19T21:52:13.420862Z","shell.execute_reply.started":"2024-03-19T21:52:13.411163Z"},"executionInfo":{"elapsed":2359,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"13Kkb3Bzcpve","outputId":"fcf48dc5-7f23-4e0f-9c89-37d90a9b6388","trusted":true},"outputs":[],"source":["\n","\n","SOURCE_DIRECTORY = f\"input\""]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T21:52:13.422891Z","iopub.status.busy":"2024-03-19T21:52:13.422626Z","iopub.status.idle":"2024-03-19T21:52:13.448075Z","shell.execute_reply":"2024-03-19T21:52:13.447248Z","shell.execute_reply.started":"2024-03-19T21:52:13.422870Z"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"zquFYmn6dAk7","trusted":true},"outputs":[],"source":["\n","_log_path = None\n","\n","def set_log_path(path):\n","    global _log_path\n","    _log_path = path\n","\n","def log(obj, filename='log.txt'):\n","    print(obj)\n","    if _log_path is not None:\n","        with open(os.path.join(_log_path, filename), 'a') as f:\n","            print(obj, file=f)\n","\n","\n","class Averager():\n","\n","    def __init__(self):\n","        self.n = 0.0\n","        self.v = 0.0\n","\n","    def add(self, v, n=1.0):\n","        self.v = (self.v * self.n + v * n) / (self.n + n)\n","        self.n += n\n","\n","    def item(self):\n","        return self.v\n","\n","\n","class Timer():\n","\n","    def __init__(self):\n","        self.v = time.time()\n","\n","    def s(self):\n","        self.v = time.time()\n","\n","    def t(self):\n","        return time.time() - self.v\n","\n","\n","def set_gpu(gpu):\n","    print('set gpu:', gpu)\n","    os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n","\n","\n","def ensure_path(path, remove=True):\n","    basename = os.path.basename(path.rstrip('/'))\n","    if os.path.exists(path):\n","        if remove and (basename.startswith('_')\n","                or input('{} exists, remove? ([y]/n): '.format(path)) != 'n'):\n","            shutil.rmtree(path)\n","            os.makedirs(path)\n","    else:\n","        os.makedirs(path)\n","\n","\n","def time_str(t):\n","    if t >= 3600:\n","        return '{:.1f}h'.format(t / 3600)\n","    if t >= 60:\n","        return '{:.1f}m'.format(t / 60)\n","    return '{:.1f}s'.format(t)\n","\n","\n","def compute_logits(feat, proto, metric='dot', temp=1.0):\n","    assert feat.dim() == proto.dim()\n","\n","    if feat.dim() == 2:\n","        if metric == 'dot':\n","            logits = torch.mm(feat, proto.t())\n","        elif metric == 'cos':\n","            logits = torch.mm(F.normalize(feat, dim=-1),\n","                              F.normalize(proto, dim=-1).t())\n","        elif metric == 'sqr':\n","            logits = -(feat.unsqueeze(1) -\n","                       proto.unsqueeze(0)).pow(2).sum(dim=-1)\n","\n","    elif feat.dim() == 3:\n","        if metric == 'dot':\n","            logits = torch.bmm(feat, proto.permute(0, 2, 1))\n","        elif metric == 'cos':\n","            logits = torch.bmm(F.normalize(feat, dim=-1),\n","                               F.normalize(proto, dim=-1).permute(0, 2, 1))\n","        elif metric == 'sqr':\n","            logits = -(feat.unsqueeze(2) -\n","                       proto.unsqueeze(1)).pow(2).sum(dim=-1)\n","\n","    return logits * temp\n","\n","\n","def compute_acc(logits, label, reduction='mean'):\n","    ret = (torch.argmax(logits, dim=1) == label).float()\n","    if reduction == 'none':\n","        return ret.detach()\n","    elif reduction == 'mean':\n","        return ret.mean().item()\n","\n","\n","def compute_n_params(model, return_str=True):\n","    tot = 0\n","    for p in model.parameters():\n","        w = 1\n","        for x in p.shape:\n","            w *= x\n","        tot += w\n","    if return_str:\n","        if tot >= 1e6:\n","            return '{:.1f}M'.format(tot / 1e6)\n","        else:\n","            return '{:.1f}K'.format(tot / 1e3)\n","    else:\n","        return tot\n","\n","\n","def make_optimizer(params, name, lr, weight_decay=None, milestones=None):\n","    if weight_decay is None:\n","        weight_decay = 0.\n","    if name == 'sgd':\n","        optimizer = SGD(params, lr, momentum=0.9, weight_decay=weight_decay)\n","    elif name == 'adam':\n","        optimizer = Adam(params, lr, weight_decay=weight_decay)\n","    if milestones:\n","        lr_scheduler = MultiStepLR(optimizer, milestones)\n","    else:\n","        lr_scheduler = None\n","    return optimizer, lr_scheduler\n","\n","\n","def visualize_dataset(dataset, name, writer, n_samples=16):\n","    demo = []\n","    for i in np.random.choice(len(dataset), n_samples):\n","        demo.append(dataset.convert_raw(dataset[i][0]))\n","    writer.add_images('visualize_' + name, torch.stack(demo))\n","    writer.flush()\n","\n","\n","def freeze_bn(model):\n","    for m in model.modules():\n","        if isinstance(m, nn.BatchNorm2d):\n","            m.eval()\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T21:52:13.449311Z","iopub.status.busy":"2024-03-19T21:52:13.449046Z","iopub.status.idle":"2024-03-19T21:52:13.466109Z","shell.execute_reply":"2024-03-19T21:52:13.465258Z","shell.execute_reply.started":"2024-03-19T21:52:13.449291Z"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"zxr_LloTdAVM","trusted":true},"outputs":[],"source":["# DEFAULT_ROOT = \n","DEFAULT_ROOT = \"./../input\"\n","\n","\n","datasets = {}\n","def datasets_register(name):\n","    def decorator(cls):\n","        datasets[name] = cls\n","        return cls\n","    return decorator\n","\n","\n","def datasets_make(name, **kwargs):\n","    if kwargs.get('root_path') is None:\n","        kwargs['root_path'] = os.path.join(DEFAULT_ROOT, name)\n","    dataset = datasets[name](**kwargs)\n","    return dataset\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T21:52:13.467811Z","iopub.status.busy":"2024-03-19T21:52:13.467491Z","iopub.status.idle":"2024-03-19T21:52:13.481127Z","shell.execute_reply":"2024-03-19T21:52:13.480281Z","shell.execute_reply.started":"2024-03-19T21:52:13.467783Z"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"QOFXfUfkdAQG","trusted":true},"outputs":[],"source":["\n","@datasets_register('image-folder')\n","class ImageFolder(Dataset):\n","\n","    def __init__(self, root_path, image_size=224, box_size=256, **kwargs):\n","        if box_size is None:\n","            box_size = image_size\n","\n","        self.filepaths = []\n","        self.label = []\n","        classes = sorted(os.listdir(root_path))\n","\n","        if kwargs.get('split'):\n","            path = kwargs.get('split_file')\n","            if path is None:\n","                path = os.path.join(\n","                        os.path.dirname(root_path.rstrip('/')), 'split.json')\n","            split = json.load(open(path, 'r'))\n","            classes = sorted(split[kwargs['split']])\n","\n","        for i, c in enumerate(classes):\n","            for filename in sorted(os.listdir(os.path.join(root_path, c))):\n","                self.filepaths.append(os.path.join(root_path, c, filename))\n","                self.label.append(i)\n","        self.n_classes = max(self.label) + 1\n","\n","        norm_params = {'mean': [0.485, 0.456, 0.406],\n","                       'std': [0.229, 0.224, 0.225]}\n","        normalize = transforms.Normalize(**norm_params)\n","        if kwargs.get('augment'):\n","            self.transform = transforms.Compose([\n","                transforms.RandomResizedCrop(image_size),\n","                transforms.RandomHorizontalFlip(),\n","                transforms.ToTensor(),\n","                normalize,\n","            ])\n","        else:\n","            self.transform = transforms.Compose([\n","                transforms.Resize(box_size),\n","                transforms.CenterCrop(image_size),\n","                transforms.ToTensor(),\n","                normalize,\n","            ])\n","\n","        def convert_raw(x):\n","            mean = torch.tensor(norm_params['mean']).view(3, 1, 1).type_as(x)\n","            std = torch.tensor(norm_params['std']).view(3, 1, 1).type_as(x)\n","            return x * std + mean\n","        self.convert_raw = convert_raw\n","\n","    def __len__(self):\n","        return len(self.filepaths)\n","\n","    def __getitem__(self, i):\n","        img = Image.open(self.filepaths[i]).convert('RGB')\n","        return self.transform(img), self.label[i]\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T21:52:13.483101Z","iopub.status.busy":"2024-03-19T21:52:13.482292Z","iopub.status.idle":"2024-03-19T21:52:13.497321Z","shell.execute_reply":"2024-03-19T21:52:13.496550Z","shell.execute_reply.started":"2024-03-19T21:52:13.483068Z"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"k0noCslgdASp","trusted":true},"outputs":[],"source":["@datasets_register('mini-imagenet')\n","class MiniImageNet(Dataset):\n","\n","    def __init__(self, root_path, split='train', **kwargs):\n","        split_tag = split\n","        if split == 'train':\n","            split_tag = 'train_phase_train'\n","        split_file = 'miniImageNet_category_split_{}.pickle'.format(split_tag)\n","        with open(os.path.join(root_path, split_file), 'rb') as f:\n","            pack = pickle.load(f, encoding='latin1')\n","        data = pack['data']\n","        label = pack['labels']\n","\n","        image_size = 80\n","        data = [Image.fromarray(x) for x in data]\n","\n","        min_label = min(label)\n","        label = [x - min_label for x in label]\n","\n","        self.data = data\n","        self.label = label\n","        self.n_classes = max(self.label) + 1\n","\n","        norm_params = {'mean': [0.485, 0.456, 0.406],\n","                       'std': [0.229, 0.224, 0.225]}\n","        normalize = transforms.Normalize(**norm_params)\n","        self.default_transform = transforms.Compose([\n","            transforms.Resize(image_size),\n","            transforms.ToTensor(),\n","            normalize,\n","        ])\n","        augment = kwargs.get('augment')\n","        if augment == 'resize':\n","            self.transform = transforms.Compose([\n","                transforms.RandomResizedCrop(image_size),\n","                transforms.RandomHorizontalFlip(),\n","                transforms.ToTensor(),\n","                normalize,\n","            ])\n","        elif augment == 'crop':\n","            self.transform = transforms.Compose([\n","                transforms.Resize(image_size),\n","                transforms.RandomCrop(image_size, padding=8),\n","                transforms.RandomHorizontalFlip(),\n","                transforms.ToTensor(),\n","                normalize,\n","            ])\n","        elif augment is None:\n","            self.transform = self.default_transform\n","\n","        def convert_raw(x):\n","            mean = torch.tensor(norm_params['mean']).view(3, 1, 1).type_as(x)\n","            std = torch.tensor(norm_params['std']).view(3, 1, 1).type_as(x)\n","            return x * std + mean\n","        self.convert_raw = convert_raw\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, i):\n","        return self.transform(self.data[i]), self.label[i]\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T21:52:13.500609Z","iopub.status.busy":"2024-03-19T21:52:13.500283Z","iopub.status.idle":"2024-03-19T21:52:13.512035Z","shell.execute_reply":"2024-03-19T21:52:13.511328Z","shell.execute_reply.started":"2024-03-19T21:52:13.500577Z"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"VuoXX_6adAXy","trusted":true},"outputs":[],"source":["\n","class CategoriesSampler():\n","\n","    def __init__(self, label, n_batch, n_cls, n_per, ep_per_batch=1):\n","        self.n_batch = n_batch\n","        self.n_cls = n_cls\n","        self.n_per = n_per\n","        self.ep_per_batch = ep_per_batch\n","\n","        label = np.array(label)\n","        self.catlocs = []\n","        for c in range(max(label) + 1):\n","            self.catlocs.append(np.argwhere(label == c).reshape(-1))\n","\n","    def __len__(self):\n","        return self.n_batch\n","\n","    def __iter__(self):\n","        for i_batch in range(self.n_batch):\n","            batch = []\n","            for i_ep in range(self.ep_per_batch):\n","                episode = []\n","                classes = np.random.choice(len(self.catlocs), self.n_cls,\n","                                           replace=False)\n","                for c in classes:\n","                    l = np.random.choice(self.catlocs[c], self.n_per,\n","                                         replace=False)\n","                    episode.append(torch.from_numpy(l))\n","                episode = torch.stack(episode)\n","                batch.append(episode)\n","            batch = torch.stack(batch) # bs * n_cls * n_per\n","            yield batch.view(-1)\n","\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T22:02:05.471551Z","iopub.status.busy":"2024-03-19T22:02:05.470884Z","iopub.status.idle":"2024-03-19T22:02:05.479038Z","shell.execute_reply":"2024-03-19T22:02:05.477611Z","shell.execute_reply.started":"2024-03-19T22:02:05.471518Z"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1710833271164,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"TBNv3xjsiorL","trusted":true},"outputs":[],"source":["\n","\n","models = {}\n","def models_register(name):\n","    def decorator(cls):\n","        models[name] = cls\n","        return cls\n","    return decorator\n","\n","\n","def models_make(name, **kwargs):\n","    if name is None:\n","        return None\n","    model = models[name](**kwargs)\n","    if torch.cuda.is_available():\n","        model.cuda()\n","    return model\n","\n","\n","def models_load(model_sv, name=None):\n","    if name is None:\n","        name = 'model'\n","    model = models_make(model_sv[name], **model_sv[name + '_args'])\n","    model.load_state_dict(model_sv[name + '_sd'])\n","    return model\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T22:02:07.078805Z","iopub.status.busy":"2024-03-19T22:02:07.077934Z","iopub.status.idle":"2024-03-19T22:02:07.093221Z","shell.execute_reply":"2024-03-19T22:02:07.092296Z","shell.execute_reply.started":"2024-03-19T22:02:07.078771Z"},"executionInfo":{"elapsed":456,"status":"ok","timestamp":1710833271612,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"qgF5hpSudAdA","trusted":true},"outputs":[],"source":["@models_register('classifier')\n","class Classifier(nn.Module):\n","\n","    def __init__(self, encoder, encoder_args,\n","                 classifier, classifier_args):\n","        super().__init__()\n","        self.encoder = models_make(encoder, **encoder_args)\n","        classifier_args['in_dim'] = self.encoder.out_dim\n","        self.classifier = models_make(classifier, **classifier_args)\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.classifier(x)\n","        return x\n","\n","\n","@models_register('linear-classifier')\n","class LinearClassifier(nn.Module):\n","\n","    def __init__(self, in_dim, n_classes):\n","        super().__init__()\n","        self.linear = nn.Linear(in_dim, n_classes)\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","\n","\n","@models_register('nn-classifier')\n","class NNClassifier(nn.Module):\n","\n","    def __init__(self, in_dim, n_classes, metric='cos', temp=None):\n","        super().__init__()\n","        self.proto = nn.Parameter(torch.empty(n_classes, in_dim))\n","        nn.init.kaiming_uniform_(self.proto, a=math.sqrt(5))\n","        if temp is None:\n","            if metric == 'cos':\n","                temp = nn.Parameter(torch.tensor(10.))\n","            else:\n","                temp = 1.0\n","        self.metric = metric\n","        self.temp = temp\n","\n","    def forward(self, x):\n","        return utils.compute_logits(x, self.proto, self.metric, self.temp)\n","\n","\n","def conv_block(in_channels, out_channels):\n","    return nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2)\n","    )\n","\n","\n","@models_register('convnet4')\n","class ConvNet4(nn.Module):\n","\n","    def __init__(self, x_dim=3, hid_dim=64, z_dim=64):\n","        super().__init__()\n","        self.encoder = nn.Sequential(\n","            conv_block(x_dim, hid_dim),\n","            conv_block(hid_dim, hid_dim),\n","            conv_block(hid_dim, hid_dim),\n","            conv_block(hid_dim, z_dim),\n","        )\n","        self.out_dim = 1600\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        return x.view(x.shape[0], -1)\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T22:02:07.617250Z","iopub.status.busy":"2024-03-19T22:02:07.616876Z","iopub.status.idle":"2024-03-19T22:02:07.628863Z","shell.execute_reply":"2024-03-19T22:02:07.627850Z","shell.execute_reply.started":"2024-03-19T22:02:07.617221Z"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1710833271612,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"ZSZg1spbj8jJ","trusted":true},"outputs":[],"source":["\n","@models_register('meta-baseline')\n","class MetaBaseline(nn.Module):\n","\n","    def __init__(self, encoder, encoder_args={}, method='cos',\n","                 temp=10., temp_learnable=True):\n","        super().__init__()\n","        self.encoder = models_make(encoder, **encoder_args)\n","        self.method = method\n","\n","        if temp_learnable:\n","            self.temp = nn.Parameter(torch.tensor(temp))\n","        else:\n","            self.temp = temp\n","\n","    def forward(self, x_shot, x_query):\n","        shot_shape = x_shot.shape[:-3]\n","        query_shape = x_query.shape[:-3]\n","        img_shape = x_shot.shape[-3:]\n","\n","        x_shot = x_shot.view(-1, *img_shape)\n","        x_query = x_query.view(-1, *img_shape)\n","        x_tot = self.encoder(torch.cat([x_shot, x_query], dim=0))\n","        x_shot, x_query = x_tot[:len(x_shot)], x_tot[-len(x_query):]\n","        x_shot = x_shot.view(*shot_shape, -1)\n","        x_query = x_query.view(*query_shape, -1)\n","\n","        if self.method == 'cos':\n","            x_shot = x_shot.mean(dim=-2)\n","            x_shot = F.normalize(x_shot, dim=-1)\n","            x_query = F.normalize(x_query, dim=-1)\n","            metric = 'dot'\n","        elif self.method == 'sqr':\n","            x_shot = x_shot.mean(dim=-2)\n","            metric = 'sqr'\n","\n","        logits = compute_logits(\n","                x_query, x_shot, metric=metric, temp=self.temp)\n","        return logits\n","\n"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T22:02:08.114908Z","iopub.status.busy":"2024-03-19T22:02:08.114399Z","iopub.status.idle":"2024-03-19T22:02:08.166282Z","shell.execute_reply":"2024-03-19T22:02:08.165198Z","shell.execute_reply.started":"2024-03-19T22:02:08.114880Z"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1710833271613,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"Fiv27JoYdAfm","trusted":true},"outputs":[],"source":["\n","__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n","           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n","           'wide_resnet50_2', 'wide_resnet101_2']\n","\n","\n","def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n","\n","\n","def conv1x1(in_planes, out_planes, stride=1):\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","    __constants__ = ['downsample']\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n","                 base_width=64, dilation=1, norm_layer=None):\n","        super(BasicBlock, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        if groups != 1 or base_width != 64:\n","            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n","        if dilation > 1:\n","            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n","        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = norm_layer(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = norm_layer(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","    __constants__ = ['downsample']\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n","                 base_width=64, dilation=1, norm_layer=None):\n","        super(Bottleneck, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        width = int(planes * (base_width / 64.)) * groups\n","        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv1x1(inplanes, width)\n","        self.bn1 = norm_layer(width)\n","        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n","        self.bn2 = norm_layer(width)\n","        self.conv3 = conv1x1(width, planes * self.expansion)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, zero_init_residual=False,\n","                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n","                 norm_layer=None):\n","        super(ResNet, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        self._norm_layer = norm_layer\n","\n","        self.inplanes = 64\n","        self.dilation = 1\n","        if replace_stride_with_dilation is None:\n","            # each element in the tuple indicates if we should replace\n","            # the 2x2 stride with a dilated convolution instead\n","            replace_stride_with_dilation = [False, False, False]\n","        if len(replace_stride_with_dilation) != 3:\n","            raise ValueError(\"replace_stride_with_dilation should be None \"\n","                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n","        self.groups = groups\n","        self.base_width = width_per_group\n","        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n","                               bias=False)\n","        self.bn1 = norm_layer(self.inplanes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n","                                       dilate=replace_stride_with_dilation[0])\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n","                                       dilate=replace_stride_with_dilation[1])\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n","                                       dilate=replace_stride_with_dilation[2])\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.out_dim = 512 * block.expansion\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        # Zero-initialize the last BN in each residual branch,\n","        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n","        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, Bottleneck):\n","                    nn.init.constant_(m.bn3.weight, 0)\n","                elif isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n","        norm_layer = self._norm_layer\n","        downsample = None\n","        previous_dilation = self.dilation\n","        if dilate:\n","            self.dilation *= stride\n","            stride = 1\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes * block.expansion, stride),\n","                norm_layer(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n","                            self.base_width, previous_dilation, norm_layer))\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, groups=self.groups,\n","                                base_width=self.base_width, dilation=self.dilation,\n","                                norm_layer=norm_layer))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _forward_impl(self, x):\n","        # See note [TorchScript super()]\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","\n","        return x\n","\n","    def forward(self, x):\n","        return self._forward_impl(x)\n","\n","\n","def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n","    model = ResNet(block, layers, **kwargs)\n","    return model\n","\n","\n","@models_register('resnet18')\n","def resnet18(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"ResNet-18 model from\n","    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n","                   **kwargs)\n","\n","\n","def resnet34(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"ResNet-34 model from\n","    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress,\n","                   **kwargs)\n","\n","\n","@models_register('resnet50')\n","def resnet50(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"ResNet-50 model from\n","    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n","                   **kwargs)\n","\n","\n","def resnet101(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"ResNet-101 model from\n","    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, progress,\n","                   **kwargs)\n","\n","\n","def resnet152(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"ResNet-152 model from\n","    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress,\n","                   **kwargs)\n","\n","\n","def resnext50_32x4d(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"ResNeXt-50 32x4d model from\n","    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    kwargs['groups'] = 32\n","    kwargs['width_per_group'] = 4\n","    return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3],\n","                   pretrained, progress, **kwargs)\n","\n","\n","def resnext101_32x8d(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"ResNeXt-101 32x8d model from\n","    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    kwargs['groups'] = 32\n","    kwargs['width_per_group'] = 8\n","    return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\n","                   pretrained, progress, **kwargs)\n","\n","\n","def wide_resnet50_2(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"Wide ResNet-50-2 model from\n","    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n","\n","    The model is the same as ResNet except for the bottleneck number of channels\n","    which is twice larger in every block. The number of channels in outer 1x1\n","    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n","    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    kwargs['width_per_group'] = 64 * 2\n","    return _resnet('wide_resnet50_2', Bottleneck, [3, 4, 6, 3],\n","                   pretrained, progress, **kwargs)\n","\n","\n","def wide_resnet101_2(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"Wide ResNet-101-2 model from\n","    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n","\n","    The model is the same as ResNet except for the bottleneck number of channels\n","    which is twice larger in every block. The number of channels in outer 1x1\n","    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n","    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    kwargs['width_per_group'] = 64 * 2\n","    return _resnet('wide_resnet101_2', Bottleneck, [3, 4, 23, 3],\n","                   pretrained, progress, **kwargs)\n"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T22:02:08.318094Z","iopub.status.busy":"2024-03-19T22:02:08.317784Z","iopub.status.idle":"2024-03-19T22:02:08.334703Z","shell.execute_reply":"2024-03-19T22:02:08.333814Z","shell.execute_reply.started":"2024-03-19T22:02:08.318072Z"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1710833271613,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"Vj0MBInqdAiX","trusted":true},"outputs":[],"source":["\n","def conv3x3(in_planes, out_planes):\n","    return nn.Conv2d(in_planes, out_planes, 3, padding=1, bias=False)\n","\n","\n","def conv1x1(in_planes, out_planes):\n","    return nn.Conv2d(in_planes, out_planes, 1, bias=False)\n","\n","\n","def norm_layer(planes):\n","    return nn.BatchNorm2d(planes)\n","\n","\n","class Block(nn.Module):\n","\n","    def __init__(self, inplanes, planes, downsample):\n","        super().__init__()\n","\n","        self.relu = nn.LeakyReLU(0.1)\n","\n","        self.conv1 = conv3x3(inplanes, planes)\n","        self.bn1 = norm_layer(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = norm_layer(planes)\n","        self.conv3 = conv3x3(planes, planes)\n","        self.bn3 = norm_layer(planes)\n","\n","        self.downsample = downsample\n","\n","        self.maxpool = nn.MaxPool2d(2)\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        out = self.maxpool(out)\n","\n","        return out\n","\n","\n","class ResNet12(nn.Module):\n","\n","    def __init__(self, channels):\n","        super().__init__()\n","\n","        self.inplanes = 3\n","\n","        self.layer1 = self._make_layer(channels[0])\n","        self.layer2 = self._make_layer(channels[1])\n","        self.layer3 = self._make_layer(channels[2])\n","        self.layer4 = self._make_layer(channels[3])\n","\n","        self.out_dim = channels[3]\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out',\n","                                        nonlinearity='leaky_relu')\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def _make_layer(self, planes):\n","        downsample = nn.Sequential(\n","            conv1x1(self.inplanes, planes),\n","            norm_layer(planes),\n","        )\n","        block = Block(self.inplanes, planes, downsample)\n","        self.inplanes = planes\n","        return block\n","\n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = x.view(x.shape[0], x.shape[1], -1).mean(dim=2)\n","        return x\n","\n","\n","@models_register('resnet12')\n","def resnet12():\n","    return ResNet12([64, 128, 256, 512])\n","\n","\n","@models_register('resnet12-wide')\n","def resnet12_wide():\n","    return ResNet12([64, 160, 320, 640])\n","\n"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T22:02:08.515926Z","iopub.status.busy":"2024-03-19T22:02:08.515612Z","iopub.status.idle":"2024-03-19T22:02:08.523370Z","shell.execute_reply":"2024-03-19T22:02:08.522494Z","shell.execute_reply.started":"2024-03-19T22:02:08.515901Z"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1710833271613,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"DATVlOexdAnf","trusted":true},"outputs":[],"source":["\n","\n","def split_shot_query(data, way, shot, query, ep_per_batch=1):\n","    img_shape = data.shape[1:]\n","    data = data.view(ep_per_batch, way, shot + query, *img_shape)\n","    x_shot, x_query = data.split([shot, query], dim=2)\n","    x_shot = x_shot.contiguous()\n","    x_query = x_query.contiguous().view(ep_per_batch, way * query, *img_shape)\n","    return x_shot, x_query\n","\n","\n","def make_nk_label(n, k, ep_per_batch=1):\n","    label = torch.arange(n).unsqueeze(1).expand(n, k).reshape(-1)\n","    label = label.repeat(ep_per_batch)\n","    return label\n","\n"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T22:06:21.399178Z","iopub.status.busy":"2024-03-19T22:06:21.398727Z","iopub.status.idle":"2024-03-19T22:06:21.439389Z","shell.execute_reply":"2024-03-19T22:06:21.438423Z","shell.execute_reply.started":"2024-03-19T22:06:21.399126Z"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1710833271614,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"b23e2e2e","trusted":true},"outputs":[],"source":["\n","def main(config):\n","    svname = config.get('name')\n","    if svname is None:\n","        svname = 'meta_{}-{}shot'.format(\n","                config['train_dataset'], config['n_shot'])\n","        svname += '_' + config['model'] + '-' + config['model_args']['encoder']\n","    if config.get('tag') is not None:\n","        svname += '_' + config.get('tag')\n","    save_path = os.path.join(SOURCE_DIRECTORY + './../output/save', svname)\n","    ensure_path(save_path)\n","    set_log_path(save_path)\n","    writer = SummaryWriter(os.path.join(save_path, 'tensorboard'))\n","\n","    yaml.dump(config, open(os.path.join(save_path, 'config.yaml'), 'w'))\n","\n","    #### Dataset ####\n","\n","    n_way, n_shot = config['n_way'], config['n_shot']\n","    n_query = config['n_query']\n","\n","    if config.get('n_train_way') is not None:\n","        n_train_way = config['n_train_way']\n","    else:\n","        n_train_way = n_way\n","    if config.get('n_train_shot') is not None:\n","        n_train_shot = config['n_train_shot']\n","    else:\n","        n_train_shot = n_shot\n","    if config.get('ep_per_batch') is not None:\n","        ep_per_batch = config['ep_per_batch']\n","    else:\n","        ep_per_batch = 1\n","\n","    # train\n","    train_dataset = datasets_make(config['train_dataset'],\n","                                  **config['train_dataset_args'])\n","    log('train dataset: {} (x{}), {}'.format(\n","            train_dataset[0][0].shape, len(train_dataset),\n","            train_dataset.n_classes))\n","    if config.get('visualize_datasets'):\n","        visualize_dataset(train_dataset, 'train_dataset', writer)\n","    train_sampler = CategoriesSampler(\n","            train_dataset.label, config['train_batches'],\n","            n_train_way, n_train_shot + n_query,\n","            ep_per_batch=ep_per_batch)\n","    train_loader = DataLoader(train_dataset, batch_sampler=train_sampler,\n","                              num_workers=4, pin_memory=True)\n","\n","    # tval\n","    if config.get('tval_dataset'):\n","        tval_dataset = datasets_make(config['tval_dataset'],\n","                                     **config['tval_dataset_args'])\n","        log('tval dataset: {} (x{}), {}'.format(\n","                tval_dataset[0][0].shape, len(tval_dataset),\n","                tval_dataset.n_classes))\n","        if config.get('visualize_datasets'):\n","            visualize_dataset(tval_dataset, 'tval_dataset', writer)\n","        tval_sampler = CategoriesSampler(\n","                tval_dataset.label, 200,\n","                n_way, n_shot + n_query,\n","                ep_per_batch=4)\n","        tval_loader = DataLoader(tval_dataset, batch_sampler=tval_sampler,\n","                                 num_workers=4, pin_memory=True)\n","    else:\n","        tval_loader = None\n","\n","    # val\n","    val_dataset = datasets_make(config['val_dataset'],\n","                                **config['val_dataset_args'])\n","    log('val dataset: {} (x{}), {}'.format(\n","            val_dataset[0][0].shape, len(val_dataset),\n","            val_dataset.n_classes))\n","    if config.get('visualize_datasets'):\n","        visualize_dataset(val_dataset, 'val_dataset', writer)\n","    val_sampler = CategoriesSampler(\n","            val_dataset.label, 200,\n","            n_way, n_shot + n_query,\n","            ep_per_batch=4)\n","    val_loader = DataLoader(val_dataset, batch_sampler=val_sampler,\n","                            num_workers=4, pin_memory=True)\n","\n","    ########\n","\n","    #### Model and optimizer ####\n","\n","    if config.get('load'):\n","        model_sv = torch.load(config['load'], map_location='cuda:0')\n","        model = models_load(model_sv)\n","    else:\n","        model = models_make(config['model'], **config['model_args'])\n","\n","        if config.get('load_encoder'):\n","            encoder = models_load(torch.load(config['load_encoder'], map_location='cuda:0')).encoder\n","            model.encoder.load_state_dict(encoder.state_dict())\n","\n","    if config.get('_parallel'):\n","        model = nn.DataParallel(model)\n","\n","    log('num params: {}'.format(compute_n_params(model)))\n","\n","    optimizer, lr_scheduler = make_optimizer(\n","            model.parameters(),\n","            config['optimizer'], **config['optimizer_args'])\n","\n","    ########\n","    \n","    max_epoch = config['max_epoch']\n","    save_epoch = config.get('save_epoch')\n","    max_va = 0.\n","    timer_used = Timer()\n","    timer_epoch = Timer()\n","\n","    aves_keys = ['tl', 'ta', 'tvl', 'tva', 'vl', 'va']\n","    trlog = dict()\n","    for k in aves_keys:\n","        trlog[k] = []\n","\n","    for epoch in range(1, max_epoch + 1):\n","        timer_epoch.s()\n","        aves = {k: Averager() for k in aves_keys}\n","\n","        # train\n","        model.train()\n","        if config.get('freeze_bn'):\n","            freeze_bn(model) \n","        writer.add_scalar('lr', optimizer.param_groups[0]['lr'], epoch)\n","\n","        np.random.seed(epoch)\n","        for data, _ in tqdm(train_loader, desc='train', leave=False):\n","            x_shot, x_query = split_shot_query(\n","                    data.cuda(), n_train_way, n_train_shot, n_query,\n","                    ep_per_batch=ep_per_batch)\n","            label = make_nk_label(n_train_way, n_query,\n","                    ep_per_batch=ep_per_batch).cuda()\n","\n","            logits = model(x_shot, x_query).view(-1, n_train_way)\n","            loss = F.cross_entropy(logits, label)\n","            acc = compute_acc(logits, label)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            aves['tl'].add(loss.item())\n","            aves['ta'].add(acc)\n","\n","            logits = None; loss = None \n","\n","        # eval\n","        model.eval()\n","\n","        for name, loader, name_l, name_a in [\n","                ('tval', tval_loader, 'tvl', 'tva'),\n","                ('val', val_loader, 'vl', 'va')]:\n","\n","            if (config.get('tval_dataset') is None) and name == 'tval':\n","                continue\n","\n","            np.random.seed(0)\n","            for data, _ in tqdm(loader, desc=name, leave=False):\n","                x_shot, x_query = split_shot_query(\n","                        data.cuda(), n_way, n_shot, n_query,\n","                        ep_per_batch=4)\n","                label = make_nk_label(n_way, n_query,\n","                        ep_per_batch=4).cuda()\n","\n","                with torch.no_grad():\n","                    logits = model(x_shot, x_query).view(-1, n_way)\n","                    loss = F.cross_entropy(logits, label)\n","                    acc = compute_acc(logits, label)\n","                \n","                aves[name_l].add(loss.item())\n","                aves[name_a].add(acc)\n","\n","        _sig = int(_[-1])\n","\n","        # post\n","        if lr_scheduler is not None:\n","            lr_scheduler.step()\n","\n","        for k, v in aves.items():\n","            aves[k] = v.item()\n","            trlog[k].append(aves[k])\n","\n","        t_epoch = time_str(timer_epoch.t())\n","        t_used = time_str(timer_used.t())\n","        t_estimate = time_str(timer_used.t() / epoch * max_epoch)\n","        log('epoch {}, train {:.4f}|{:.4f}, tval {:.4f}|{:.4f}, '\n","                'val {:.4f}|{:.4f}, {} {}/{} (@{})'.format(\n","                epoch, aves['tl'], aves['ta'], aves['tvl'], aves['tva'],\n","                aves['vl'], aves['va'], t_epoch, t_used, t_estimate, _sig))\n","\n","        writer.add_scalars('loss', {\n","            'train': aves['tl'],\n","            'tval': aves['tvl'],\n","            'val': aves['vl'],\n","        }, epoch)\n","        writer.add_scalars('acc', {\n","            'train': aves['ta'],\n","            'tval': aves['tva'],\n","            'val': aves['va'],\n","        }, epoch)\n","\n","        if config.get('_parallel'):\n","            model_ = model.module\n","        else:\n","            model_ = model\n","\n","        training = {\n","            'epoch': epoch,\n","            'optimizer': config['optimizer'],\n","            'optimizer_args': config['optimizer_args'],\n","            'optimizer_sd': optimizer.state_dict(),\n","        }\n","        save_obj = {\n","            'file': './train_meta_kaggle.ipynb',\n","            'config': config,\n","\n","            'model': config['model'],\n","            'model_args': config['model_args'],\n","            'model_sd': model_.state_dict(),\n","\n","            'training': training,\n","        }\n","        torch.save(save_obj, os.path.join(save_path, 'epoch-last.pth'))\n","        torch.save(trlog, os.path.join(save_path, 'trlog.pth'))\n","\n","        if (save_epoch is not None) and epoch % save_epoch == 0:\n","            torch.save(save_obj,\n","                    os.path.join(save_path, 'epoch-{}.pth'.format(epoch)))\n","\n","        if aves['va'] > max_va:\n","            max_va = aves['va']\n","            torch.save(save_obj, os.path.join(save_path, 'max-va.pth'))\n","\n","        writer.flush()\n","\n"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T22:06:21.692219Z","iopub.status.busy":"2024-03-19T22:06:21.691867Z","iopub.status.idle":"2024-03-19T22:06:21.697123Z","shell.execute_reply":"2024-03-19T22:06:21.696097Z","shell.execute_reply.started":"2024-03-19T22:06:21.692193Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["number of cuda devices: 2\n"]}],"source":["assert torch.cuda.is_available() == True\n","print(f'number of cuda devices: {torch.cuda.device_count()}')"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-03-19T22:06:22.474895Z","iopub.status.busy":"2024-03-19T22:06:22.474278Z","iopub.status.idle":"2024-03-19T22:13:31.284830Z","shell.execute_reply":"2024-03-19T22:13:31.283482Z","shell.execute_reply.started":"2024-03-19T22:06:22.474863Z"},"id":"212c3a37","lines_to_next_cell":2,"outputId":"18dad718-8021-48cb-bea5-998b0faab9a6","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["set gpu: 4\n"]},{"name":"stdout","output_type":"stream","text":["input./../output/save/meta_mini-imagenet-1shot_meta-baseline-resnet12 exists, remove? ([y]/n):  y\n"]},{"name":"stdout","output_type":"stream","text":["train dataset: torch.Size([3, 80, 80]) (x38400), 64\n","tval dataset: torch.Size([3, 80, 80]) (x12000), 20\n","val dataset: torch.Size([3, 80, 80]) (x9600), 16\n","num params: 8.0M\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 1, train 0.5599|0.8263, tval 0.9781|0.6136, val 0.9578|0.6276, 4.8m 4.8m/1.6h (@7)\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[37], line 38\u001b[0m\n\u001b[1;32m      3\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmini-imagenet\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      4\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_dataset_args\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m      5\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     35\u001b[0m          }\n\u001b[1;32m     37\u001b[0m set_gpu(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[35], line 144\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    141\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    142\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 144\u001b[0m aves[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtl\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39madd(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    145\u001b[0m aves[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mta\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39madd(acc)\n\u001b[1;32m    147\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m; loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["if __name__ == '__main__':\n","\n","    config = {'train_dataset': 'mini-imagenet', \n","              'train_dataset_args': {\n","                  'split': 'train'\n","              }, \n","              'tval_dataset': 'mini-imagenet', \n","              'tval_dataset_args': {\n","                  'split': 'test'\n","              }, \n","              'val_dataset': 'mini-imagenet', \n","              'val_dataset_args': {\n","                  'split': 'val'\n","              }, \n","              'model': 'meta-baseline', \n","              'model_args': {\n","                  'encoder': 'resnet12', \n","                  'encoder_args': {}\n","              }, \n","              'load_encoder': '/kaggle/input/baseclassifier_resnet12_miniimagenet/pytorch/reproduction/1/epoch-last.pth', \n","              'n_way': 5, \n","              'n_shot': 1, \n","              'n_query': 15, \n","              'train_batches': 200, \n","              'ep_per_batch': 4, \n","              'max_epoch': 20, \n","              'optimizer': 'sgd', \n","              'optimizer_args': {\n","                  'lr': 0.001, \n","                  'weight_decay': 0.0005\n","              }, \n","              'visualize_datasets': True,\n","              'tag': None, \n","              'name': None,\n","             }\n","\n","    set_gpu(\"4\")\n","    main(config)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-19T22:02:28.413822Z","iopub.status.idle":"2024-03-19T22:02:28.414166Z","shell.execute_reply":"2024-03-19T22:02:28.414005Z","shell.execute_reply.started":"2024-03-19T22:02:28.413990Z"},"id":"ARBRZATYe6TS","trusted":true},"outputs":[],"source":["!zip -r file.zip /kaggle/working"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-19T21:53:11.229820Z","iopub.status.idle":"2024-03-19T21:53:11.230165Z","shell.execute_reply":"2024-03-19T21:53:11.229994Z","shell.execute_reply.started":"2024-03-19T21:53:11.229981Z"},"trusted":true},"outputs":[],"source":["from IPython.display import FileLink\n","FileLink(r'file.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4627769,"sourceId":7883994,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelInstanceId":14984,"sourceId":17991,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":5}
