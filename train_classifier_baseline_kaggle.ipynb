{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-03-19T12:23:38.090410Z","iopub.status.busy":"2024-03-19T12:23:38.089811Z","iopub.status.idle":"2024-03-19T12:24:11.431203Z","shell.execute_reply":"2024-03-19T12:24:11.430256Z","shell.execute_reply.started":"2024-03-19T12:23:38.090379Z"},"executionInfo":{"elapsed":11064,"status":"ok","timestamp":1710833268810,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"rAhYhRtWd-U3","outputId":"237d63b8-9b42-4dd1-c0f6-e52d7e26b45a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorboardX in /opt/conda/lib/python3.10/site-packages (2.6.2.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorboardX) (1.26.4)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorboardX) (21.3)\n","Requirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.10/site-packages (from tensorboardX) (3.20.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorboardX) (3.1.1)\n"]}],"source":["!pip install tensorboardX"]},{"cell_type":"code","execution_count":2,"id":"dbaa7229","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:24:13.380749Z","iopub.status.busy":"2024-03-19T12:24:13.380388Z","iopub.status.idle":"2024-03-19T12:24:13.408949Z","shell.execute_reply":"2024-03-19T12:24:13.408099Z","shell.execute_reply.started":"2024-03-19T12:24:13.380719Z"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1710833268811,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"b64c1de4","trusted":true},"outputs":[],"source":["import argparse\n","import os\n","import yaml\n","import json\n","from PIL import Image\n","import pickle\n","import numpy as np\n","import math\n","import shutil\n","import time"]},{"cell_type":"code","execution_count":3,"id":"6be914ed","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:24:13.550346Z","iopub.status.busy":"2024-03-19T12:24:13.549977Z","iopub.status.idle":"2024-03-19T12:24:25.140278Z","shell.execute_reply":"2024-03-19T12:24:25.139456Z","shell.execute_reply.started":"2024-03-19T12:24:13.550301Z"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1710833268811,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"37c4bcdb","trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader\n","from tensorboardX import SummaryWriter\n","from torch.utils.data import Dataset\n","from torchvision import transforms\n","from torch.optim import SGD, Adam\n","from torch.optim.lr_scheduler import MultiStepLR\n"]},{"cell_type":"code","execution_count":4,"id":"e99965f7","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:24:25.143268Z","iopub.status.busy":"2024-03-19T12:24:25.141757Z","iopub.status.idle":"2024-03-19T12:24:25.181511Z","shell.execute_reply":"2024-03-19T12:24:25.180354Z","shell.execute_reply.started":"2024-03-19T12:24:25.143238Z"},"trusted":true},"outputs":[],"source":["assert torch.cuda.is_available() == True"]},{"cell_type":"code","execution_count":5,"id":"b9baee31","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-03-19T12:24:25.183102Z","iopub.status.busy":"2024-03-19T12:24:25.182807Z","iopub.status.idle":"2024-03-19T12:24:25.196945Z","shell.execute_reply":"2024-03-19T12:24:25.196235Z","shell.execute_reply.started":"2024-03-19T12:24:25.183077Z"},"executionInfo":{"elapsed":2359,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"13Kkb3Bzcpve","outputId":"fcf48dc5-7f23-4e0f-9c89-37d90a9b6388","trusted":true},"outputs":[],"source":["\n","\n","SOURCE_DIRECTORY = f\"input\""]},{"cell_type":"code","execution_count":6,"id":"e53fb8ea","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:24:25.199399Z","iopub.status.busy":"2024-03-19T12:24:25.199103Z","iopub.status.idle":"2024-03-19T12:24:25.224782Z","shell.execute_reply":"2024-03-19T12:24:25.223918Z","shell.execute_reply.started":"2024-03-19T12:24:25.199375Z"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"zquFYmn6dAk7","trusted":true},"outputs":[],"source":["\n","_log_path = None\n","\n","def set_log_path(path):\n","    global _log_path\n","    _log_path = path\n","\n","def log(obj, filename='log.txt'):\n","    print(obj)\n","    if _log_path is not None:\n","        with open(os.path.join(_log_path, filename), 'a') as f:\n","            print(obj, file=f)\n","\n","\n","class Averager():\n","\n","    def __init__(self):\n","        self.n = 0.0\n","        self.v = 0.0\n","\n","    def add(self, v, n=1.0):\n","        self.v = (self.v * self.n + v * n) / (self.n + n)\n","        self.n += n\n","\n","    def item(self):\n","        return self.v\n","\n","\n","class Timer():\n","\n","    def __init__(self):\n","        self.v = time.time()\n","\n","    def s(self):\n","        self.v = time.time()\n","\n","    def t(self):\n","        return time.time() - self.v\n","\n","\n","def set_gpu(gpu):\n","    print('set gpu:', gpu)\n","    os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n","\n","\n","def ensure_path(path, remove=True):\n","    basename = os.path.basename(path.rstrip('/'))\n","    if os.path.exists(path):\n","        if remove and (basename.startswith('_')\n","                or input('{} exists, remove? ([y]/n): '.format(path)) != 'n'):\n","            shutil.rmtree(path)\n","            os.makedirs(path)\n","    else:\n","        os.makedirs(path)\n","\n","\n","def time_str(t):\n","    if t >= 3600:\n","        return '{:.1f}h'.format(t / 3600)\n","    if t >= 60:\n","        return '{:.1f}m'.format(t / 60)\n","    return '{:.1f}s'.format(t)\n","\n","\n","def compute_logits(feat, proto, metric='dot', temp=1.0):\n","    assert feat.dim() == proto.dim()\n","\n","    if feat.dim() == 2:\n","        if metric == 'dot':\n","            logits = torch.mm(feat, proto.t())\n","        elif metric == 'cos':\n","            logits = torch.mm(F.normalize(feat, dim=-1),\n","                              F.normalize(proto, dim=-1).t())\n","        elif metric == 'sqr':\n","            logits = -(feat.unsqueeze(1) -\n","                       proto.unsqueeze(0)).pow(2).sum(dim=-1)\n","\n","    elif feat.dim() == 3:\n","        if metric == 'dot':\n","            logits = torch.bmm(feat, proto.permute(0, 2, 1))\n","        elif metric == 'cos':\n","            logits = torch.bmm(F.normalize(feat, dim=-1),\n","                               F.normalize(proto, dim=-1).permute(0, 2, 1))\n","        elif metric == 'sqr':\n","            logits = -(feat.unsqueeze(2) -\n","                       proto.unsqueeze(1)).pow(2).sum(dim=-1)\n","\n","    return logits * temp\n","\n","\n","def compute_acc(logits, label, reduction='mean'):\n","    ret = (torch.argmax(logits, dim=1) == label).float()\n","    if reduction == 'none':\n","        return ret.detach()\n","    elif reduction == 'mean':\n","        return ret.mean().item()\n","\n","\n","def compute_n_params(model, return_str=True):\n","    tot = 0\n","    for p in model.parameters():\n","        w = 1\n","        for x in p.shape:\n","            w *= x\n","        tot += w\n","    if return_str:\n","        if tot >= 1e6:\n","            return '{:.1f}M'.format(tot / 1e6)\n","        else:\n","            return '{:.1f}K'.format(tot / 1e3)\n","    else:\n","        return tot\n","\n","\n","def make_optimizer(params, name, lr, weight_decay=None, milestones=None):\n","    if weight_decay is None:\n","        weight_decay = 0.\n","    if name == 'sgd':\n","        optimizer = SGD(params, lr, momentum=0.9, weight_decay=weight_decay)\n","    elif name == 'adam':\n","        optimizer = Adam(params, lr, weight_decay=weight_decay)\n","    if milestones:\n","        lr_scheduler = MultiStepLR(optimizer, milestones)\n","    else:\n","        lr_scheduler = None\n","    return optimizer, lr_scheduler\n","\n","\n","def visualize_dataset(dataset, name, writer, n_samples=16):\n","    demo = []\n","    for i in np.random.choice(len(dataset), n_samples):\n","        demo.append(dataset.convert_raw(dataset[i][0]))\n","    writer.add_images('visualize_' + name, torch.stack(demo))\n","    writer.flush()\n","\n","\n","def freeze_bn(model):\n","    for m in model.modules():\n","        if isinstance(m, nn.BatchNorm2d):\n","            m.eval()\n","\n"]},{"cell_type":"code","execution_count":7,"id":"d8f7da98","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:24:25.226161Z","iopub.status.busy":"2024-03-19T12:24:25.225843Z","iopub.status.idle":"2024-03-19T12:24:25.239443Z","shell.execute_reply":"2024-03-19T12:24:25.238236Z","shell.execute_reply.started":"2024-03-19T12:24:25.226138Z"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"zxr_LloTdAVM","trusted":true},"outputs":[],"source":["# DEFAULT_ROOT = \n","DEFAULT_ROOT = \"./../input\"\n","\n","\n","datasets = {}\n","def datasets_register(name):\n","    def decorator(cls):\n","        datasets[name] = cls\n","        return cls\n","    return decorator\n","\n","\n","def datasets_make(name, **kwargs):\n","    if kwargs.get('root_path') is None:\n","        kwargs['root_path'] = os.path.join(DEFAULT_ROOT, name)\n","    dataset = datasets[name](**kwargs)\n","    return dataset\n","\n"]},{"cell_type":"code","execution_count":8,"id":"0bd99b28","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:24:25.240860Z","iopub.status.busy":"2024-03-19T12:24:25.240608Z","iopub.status.idle":"2024-03-19T12:24:25.254867Z","shell.execute_reply":"2024-03-19T12:24:25.253860Z","shell.execute_reply.started":"2024-03-19T12:24:25.240839Z"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"QOFXfUfkdAQG","trusted":true},"outputs":[],"source":["\n","@datasets_register('image-folder')\n","class ImageFolder(Dataset):\n","\n","    def __init__(self, root_path, image_size=224, box_size=256, **kwargs):\n","        if box_size is None:\n","            box_size = image_size\n","\n","        self.filepaths = []\n","        self.label = []\n","        classes = sorted(os.listdir(root_path))\n","\n","        if kwargs.get('split'):\n","            path = kwargs.get('split_file')\n","            if path is None:\n","                path = os.path.join(\n","                        os.path.dirname(root_path.rstrip('/')), 'split.json')\n","            split = json.load(open(path, 'r'))\n","            classes = sorted(split[kwargs['split']])\n","\n","        for i, c in enumerate(classes):\n","            for filename in sorted(os.listdir(os.path.join(root_path, c))):\n","                self.filepaths.append(os.path.join(root_path, c, filename))\n","                self.label.append(i)\n","        self.n_classes = max(self.label) + 1\n","\n","        norm_params = {'mean': [0.485, 0.456, 0.406],\n","                       'std': [0.229, 0.224, 0.225]}\n","        normalize = transforms.Normalize(**norm_params)\n","        if kwargs.get('augment'):\n","            self.transform = transforms.Compose([\n","                transforms.RandomResizedCrop(image_size),\n","                transforms.RandomHorizontalFlip(),\n","                transforms.ToTensor(),\n","                normalize,\n","            ])\n","        else:\n","            self.transform = transforms.Compose([\n","                transforms.Resize(box_size),\n","                transforms.CenterCrop(image_size),\n","                transforms.ToTensor(),\n","                normalize,\n","            ])\n","\n","        def convert_raw(x):\n","            mean = torch.tensor(norm_params['mean']).view(3, 1, 1).type_as(x)\n","            std = torch.tensor(norm_params['std']).view(3, 1, 1).type_as(x)\n","            return x * std + mean\n","        self.convert_raw = convert_raw\n","\n","    def __len__(self):\n","        return len(self.filepaths)\n","\n","    def __getitem__(self, i):\n","        img = Image.open(self.filepaths[i]).convert('RGB')\n","        return self.transform(img), self.label[i]\n","\n"]},{"cell_type":"code","execution_count":9,"id":"18737f79","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:24:25.256436Z","iopub.status.busy":"2024-03-19T12:24:25.256133Z","iopub.status.idle":"2024-03-19T12:24:25.270800Z","shell.execute_reply":"2024-03-19T12:24:25.270064Z","shell.execute_reply.started":"2024-03-19T12:24:25.256399Z"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"k0noCslgdASp","trusted":true},"outputs":[],"source":["@datasets_register('mini-imagenet')\n","class MiniImageNet(Dataset):\n","\n","    def __init__(self, root_path, split='train', **kwargs):\n","        split_tag = split\n","        if split == 'train':\n","            split_tag = 'train_phase_train'\n","        split_file = 'miniImageNet_category_split_{}.pickle'.format(split_tag)\n","        with open(os.path.join(root_path, split_file), 'rb') as f:\n","            pack = pickle.load(f, encoding='latin1')\n","        data = pack['data']\n","        label = pack['labels']\n","\n","        image_size = 80\n","        data = [Image.fromarray(x) for x in data]\n","\n","        min_label = min(label)\n","        label = [x - min_label for x in label]\n","\n","        self.data = data\n","        self.label = label\n","        self.n_classes = max(self.label) + 1\n","\n","        norm_params = {'mean': [0.485, 0.456, 0.406],\n","                       'std': [0.229, 0.224, 0.225]}\n","        normalize = transforms.Normalize(**norm_params)\n","        self.default_transform = transforms.Compose([\n","            transforms.Resize(image_size),\n","            transforms.ToTensor(),\n","            normalize,\n","        ])\n","        augment = kwargs.get('augment')\n","        if augment == 'resize':\n","            self.transform = transforms.Compose([\n","                transforms.RandomResizedCrop(image_size),\n","                transforms.RandomHorizontalFlip(),\n","                transforms.ToTensor(),\n","                normalize,\n","            ])\n","        elif augment == 'crop':\n","            self.transform = transforms.Compose([\n","                transforms.Resize(image_size),\n","                transforms.RandomCrop(image_size, padding=8),\n","                transforms.RandomHorizontalFlip(),\n","                transforms.ToTensor(),\n","                normalize,\n","            ])\n","        elif augment is None:\n","            self.transform = self.default_transform\n","\n","        def convert_raw(x):\n","            mean = torch.tensor(norm_params['mean']).view(3, 1, 1).type_as(x)\n","            std = torch.tensor(norm_params['std']).view(3, 1, 1).type_as(x)\n","            return x * std + mean\n","        self.convert_raw = convert_raw\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, i):\n","        return self.transform(self.data[i]), self.label[i]\n","\n"]},{"cell_type":"code","execution_count":10,"id":"f0bfc823","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:24:25.272293Z","iopub.status.busy":"2024-03-19T12:24:25.272032Z","iopub.status.idle":"2024-03-19T12:24:25.285258Z","shell.execute_reply":"2024-03-19T12:24:25.284423Z","shell.execute_reply.started":"2024-03-19T12:24:25.272271Z"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1710833271163,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"VuoXX_6adAXy","trusted":true},"outputs":[],"source":["\n","class CategoriesSampler():\n","\n","    def __init__(self, label, n_batch, n_cls, n_per, ep_per_batch=1):\n","        self.n_batch = n_batch\n","        self.n_cls = n_cls\n","        self.n_per = n_per\n","        self.ep_per_batch = ep_per_batch\n","\n","        label = np.array(label)\n","        self.catlocs = []\n","        for c in range(max(label) + 1):\n","            self.catlocs.append(np.argwhere(label == c).reshape(-1))\n","\n","    def __len__(self):\n","        return self.n_batch\n","\n","    def __iter__(self):\n","        for i_batch in range(self.n_batch):\n","            batch = []\n","            for i_ep in range(self.ep_per_batch):\n","                episode = []\n","                classes = np.random.choice(len(self.catlocs), self.n_cls,\n","                                           replace=False)\n","                for c in classes:\n","                    l = np.random.choice(self.catlocs[c], self.n_per,\n","                                         replace=False)\n","                    episode.append(torch.from_numpy(l))\n","                episode = torch.stack(episode)\n","                batch.append(episode)\n","            batch = torch.stack(batch) # bs * n_cls * n_per\n","            yield batch.view(-1)\n","\n"]},{"cell_type":"code","execution_count":11,"id":"4a34d37c","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:24:29.375281Z","iopub.status.busy":"2024-03-19T12:24:29.374901Z","iopub.status.idle":"2024-03-19T12:24:29.382442Z","shell.execute_reply":"2024-03-19T12:24:29.381462Z","shell.execute_reply.started":"2024-03-19T12:24:29.375248Z"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1710833271164,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"TBNv3xjsiorL","trusted":true},"outputs":[],"source":["\n","\n","models = {}\n","def models_register(name):\n","    def decorator(cls):\n","        models[name] = cls\n","        return cls\n","    return decorator\n","\n","\n","def models_make(name, **kwargs):\n","    if name is None:\n","        return None\n","    model = models[name](**kwargs)\n","    if torch.cuda.is_available():\n","        model.cuda()\n","    return model\n","\n","\n","def load(model_sv, name=None):\n","    if name is None:\n","        name = 'model'\n","    model = make(model_sv[name], **model_sv[name + '_args'])\n","    model.load_state_dict(model_sv[name + '_sd'])\n","    return model\n","\n"]},{"cell_type":"code","execution_count":12,"id":"7fecf46d","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:24:29.559634Z","iopub.status.busy":"2024-03-19T12:24:29.559258Z","iopub.status.idle":"2024-03-19T12:24:29.573696Z","shell.execute_reply":"2024-03-19T12:24:29.572731Z","shell.execute_reply.started":"2024-03-19T12:24:29.559608Z"},"executionInfo":{"elapsed":456,"status":"ok","timestamp":1710833271612,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"qgF5hpSudAdA","trusted":true},"outputs":[],"source":["@models_register('classifier')\n","class Classifier(nn.Module):\n","\n","    def __init__(self, encoder, encoder_args,\n","                 classifier, classifier_args):\n","        super().__init__()\n","        self.encoder = models_make(encoder, **encoder_args)\n","        classifier_args['in_dim'] = self.encoder.out_dim\n","        self.classifier = models_make(classifier, **classifier_args)\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.classifier(x)\n","        return x\n","\n","\n","@models_register('linear-classifier')\n","class LinearClassifier(nn.Module):\n","\n","    def __init__(self, in_dim, n_classes):\n","        super().__init__()\n","        self.linear = nn.Linear(in_dim, n_classes)\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","\n","\n","@models_register('nn-classifier')\n","class NNClassifier(nn.Module):\n","\n","    def __init__(self, in_dim, n_classes, metric='cos', temp=None):\n","        super().__init__()\n","        self.proto = nn.Parameter(torch.empty(n_classes, in_dim))\n","        nn.init.kaiming_uniform_(self.proto, a=math.sqrt(5))\n","        if temp is None:\n","            if metric == 'cos':\n","                temp = nn.Parameter(torch.tensor(10.))\n","            else:\n","                temp = 1.0\n","        self.metric = metric\n","        self.temp = temp\n","\n","    def forward(self, x):\n","        return utils.compute_logits(x, self.proto, self.metric, self.temp)\n","\n","\n","def conv_block(in_channels, out_channels):\n","    return nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2)\n","    )\n","\n","\n","@models_register('convnet4')\n","class ConvNet4(nn.Module):\n","\n","    def __init__(self, x_dim=3, hid_dim=64, z_dim=64):\n","        super().__init__()\n","        self.encoder = nn.Sequential(\n","            conv_block(x_dim, hid_dim),\n","            conv_block(hid_dim, hid_dim),\n","            conv_block(hid_dim, hid_dim),\n","            conv_block(hid_dim, z_dim),\n","        )\n","        self.out_dim = 1600\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        return x.view(x.shape[0], -1)\n"]},{"cell_type":"code","execution_count":13,"id":"63305eb8","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:24:29.725077Z","iopub.status.busy":"2024-03-19T12:24:29.724727Z","iopub.status.idle":"2024-03-19T12:24:29.736649Z","shell.execute_reply":"2024-03-19T12:24:29.735618Z","shell.execute_reply.started":"2024-03-19T12:24:29.725049Z"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1710833271612,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"ZSZg1spbj8jJ","trusted":true},"outputs":[],"source":["\n","@models_register('meta-baseline')\n","class MetaBaseline(nn.Module):\n","\n","    def __init__(self, encoder, encoder_args={}, method='cos',\n","                 temp=10., temp_learnable=True):\n","        super().__init__()\n","        self.encoder = models_make(encoder, **encoder_args)\n","        self.method = method\n","\n","        if temp_learnable:\n","            self.temp = nn.Parameter(torch.tensor(temp))\n","        else:\n","            self.temp = temp\n","\n","    def forward(self, x_shot, x_query):\n","        shot_shape = x_shot.shape[:-3]\n","        query_shape = x_query.shape[:-3]\n","        img_shape = x_shot.shape[-3:]\n","\n","        x_shot = x_shot.view(-1, *img_shape)\n","        x_query = x_query.view(-1, *img_shape)\n","        x_tot = self.encoder(torch.cat([x_shot, x_query], dim=0))\n","        x_shot, x_query = x_tot[:len(x_shot)], x_tot[-len(x_query):]\n","        x_shot = x_shot.view(*shot_shape, -1)\n","        x_query = x_query.view(*query_shape, -1)\n","\n","        if self.method == 'cos':\n","            x_shot = x_shot.mean(dim=-2)\n","            x_shot = F.normalize(x_shot, dim=-1)\n","            x_query = F.normalize(x_query, dim=-1)\n","            metric = 'dot'\n","        elif self.method == 'sqr':\n","            x_shot = x_shot.mean(dim=-2)\n","            metric = 'sqr'\n","\n","        logits = compute_logits(\n","                x_query, x_shot, metric=metric, temp=self.temp)\n","        return logits\n","\n"]},{"cell_type":"code","execution_count":14,"id":"a1d502a5","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:24:29.896824Z","iopub.status.busy":"2024-03-19T12:24:29.896469Z","iopub.status.idle":"2024-03-19T12:24:29.945828Z","shell.execute_reply":"2024-03-19T12:24:29.944799Z","shell.execute_reply.started":"2024-03-19T12:24:29.896796Z"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1710833271613,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"Fiv27JoYdAfm","trusted":true},"outputs":[],"source":["\n","__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n","           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n","           'wide_resnet50_2', 'wide_resnet101_2']\n","\n","\n","def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n","\n","\n","def conv1x1(in_planes, out_planes, stride=1):\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","    __constants__ = ['downsample']\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n","                 base_width=64, dilation=1, norm_layer=None):\n","        super(BasicBlock, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        if groups != 1 or base_width != 64:\n","            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n","        if dilation > 1:\n","            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n","        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = norm_layer(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = norm_layer(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","    __constants__ = ['downsample']\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n","                 base_width=64, dilation=1, norm_layer=None):\n","        super(Bottleneck, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        width = int(planes * (base_width / 64.)) * groups\n","        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv1x1(inplanes, width)\n","        self.bn1 = norm_layer(width)\n","        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n","        self.bn2 = norm_layer(width)\n","        self.conv3 = conv1x1(width, planes * self.expansion)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, zero_init_residual=False,\n","                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n","                 norm_layer=None):\n","        super(ResNet, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        self._norm_layer = norm_layer\n","\n","        self.inplanes = 64\n","        self.dilation = 1\n","        if replace_stride_with_dilation is None:\n","            # each element in the tuple indicates if we should replace\n","            # the 2x2 stride with a dilated convolution instead\n","            replace_stride_with_dilation = [False, False, False]\n","        if len(replace_stride_with_dilation) != 3:\n","            raise ValueError(\"replace_stride_with_dilation should be None \"\n","                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n","        self.groups = groups\n","        self.base_width = width_per_group\n","        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n","                               bias=False)\n","        self.bn1 = norm_layer(self.inplanes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n","                                       dilate=replace_stride_with_dilation[0])\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n","                                       dilate=replace_stride_with_dilation[1])\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n","                                       dilate=replace_stride_with_dilation[2])\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.out_dim = 512 * block.expansion\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        # Zero-initialize the last BN in each residual branch,\n","        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n","        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, Bottleneck):\n","                    nn.init.constant_(m.bn3.weight, 0)\n","                elif isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n","        norm_layer = self._norm_layer\n","        downsample = None\n","        previous_dilation = self.dilation\n","        if dilate:\n","            self.dilation *= stride\n","            stride = 1\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes * block.expansion, stride),\n","                norm_layer(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n","                            self.base_width, previous_dilation, norm_layer))\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, groups=self.groups,\n","                                base_width=self.base_width, dilation=self.dilation,\n","                                norm_layer=norm_layer))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _forward_impl(self, x):\n","        # See note [TorchScript super()]\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","\n","        return x\n","\n","    def forward(self, x):\n","        return self._forward_impl(x)\n","\n","\n","def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n","    model = ResNet(block, layers, **kwargs)\n","    return model\n","\n","\n","@models_register('resnet18')\n","def resnet18(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"ResNet-18 model from\n","    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n","                   **kwargs)\n","\n","\n","def resnet34(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"ResNet-34 model from\n","    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress,\n","                   **kwargs)\n","\n","\n","@models_register('resnet50')\n","def resnet50(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"ResNet-50 model from\n","    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n","                   **kwargs)\n","\n","\n","def resnet101(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"ResNet-101 model from\n","    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, progress,\n","                   **kwargs)\n","\n","\n","def resnet152(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"ResNet-152 model from\n","    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress,\n","                   **kwargs)\n","\n","\n","def resnext50_32x4d(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"ResNeXt-50 32x4d model from\n","    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    kwargs['groups'] = 32\n","    kwargs['width_per_group'] = 4\n","    return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3],\n","                   pretrained, progress, **kwargs)\n","\n","\n","def resnext101_32x8d(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"ResNeXt-101 32x8d model from\n","    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    kwargs['groups'] = 32\n","    kwargs['width_per_group'] = 8\n","    return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\n","                   pretrained, progress, **kwargs)\n","\n","\n","def wide_resnet50_2(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"Wide ResNet-50-2 model from\n","    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n","\n","    The model is the same as ResNet except for the bottleneck number of channels\n","    which is twice larger in every block. The number of channels in outer 1x1\n","    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n","    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    kwargs['width_per_group'] = 64 * 2\n","    return _resnet('wide_resnet50_2', Bottleneck, [3, 4, 6, 3],\n","                   pretrained, progress, **kwargs)\n","\n","\n","def wide_resnet101_2(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"Wide ResNet-101-2 model from\n","    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n","\n","    The model is the same as ResNet except for the bottleneck number of channels\n","    which is twice larger in every block. The number of channels in outer 1x1\n","    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n","    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    kwargs['width_per_group'] = 64 * 2\n","    return _resnet('wide_resnet101_2', Bottleneck, [3, 4, 23, 3],\n","                   pretrained, progress, **kwargs)\n"]},{"cell_type":"code","execution_count":15,"id":"1a3bdb47","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:24:30.047365Z","iopub.status.busy":"2024-03-19T12:24:30.046438Z","iopub.status.idle":"2024-03-19T12:24:30.064589Z","shell.execute_reply":"2024-03-19T12:24:30.063655Z","shell.execute_reply.started":"2024-03-19T12:24:30.047309Z"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1710833271613,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"Vj0MBInqdAiX","trusted":true},"outputs":[],"source":["\n","def conv3x3(in_planes, out_planes):\n","    return nn.Conv2d(in_planes, out_planes, 3, padding=1, bias=False)\n","\n","\n","def conv1x1(in_planes, out_planes):\n","    return nn.Conv2d(in_planes, out_planes, 1, bias=False)\n","\n","\n","def norm_layer(planes):\n","    return nn.BatchNorm2d(planes)\n","\n","\n","class Block(nn.Module):\n","\n","    def __init__(self, inplanes, planes, downsample):\n","        super().__init__()\n","\n","        self.relu = nn.LeakyReLU(0.1)\n","\n","        self.conv1 = conv3x3(inplanes, planes)\n","        self.bn1 = norm_layer(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = norm_layer(planes)\n","        self.conv3 = conv3x3(planes, planes)\n","        self.bn3 = norm_layer(planes)\n","\n","        self.downsample = downsample\n","\n","        self.maxpool = nn.MaxPool2d(2)\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        out = self.maxpool(out)\n","\n","        return out\n","\n","\n","class ResNet12(nn.Module):\n","\n","    def __init__(self, channels):\n","        super().__init__()\n","\n","        self.inplanes = 3\n","\n","        self.layer1 = self._make_layer(channels[0])\n","        self.layer2 = self._make_layer(channels[1])\n","        self.layer3 = self._make_layer(channels[2])\n","        self.layer4 = self._make_layer(channels[3])\n","\n","        self.out_dim = channels[3]\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out',\n","                                        nonlinearity='leaky_relu')\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def _make_layer(self, planes):\n","        downsample = nn.Sequential(\n","            conv1x1(self.inplanes, planes),\n","            norm_layer(planes),\n","        )\n","        block = Block(self.inplanes, planes, downsample)\n","        self.inplanes = planes\n","        return block\n","\n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = x.view(x.shape[0], x.shape[1], -1).mean(dim=2)\n","        return x\n","\n","\n","@models_register('resnet12')\n","def resnet12():\n","    return ResNet12([64, 128, 256, 512])\n","\n","\n","@models_register('resnet12-wide')\n","def resnet12_wide():\n","    return ResNet12([64, 160, 320, 640])\n","\n"]},{"cell_type":"code","execution_count":16,"id":"0be42ba5","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:24:30.216000Z","iopub.status.busy":"2024-03-19T12:24:30.215415Z","iopub.status.idle":"2024-03-19T12:24:30.222506Z","shell.execute_reply":"2024-03-19T12:24:30.221640Z","shell.execute_reply.started":"2024-03-19T12:24:30.215971Z"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1710833271613,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"DATVlOexdAnf","trusted":true},"outputs":[],"source":["\n","\n","def split_shot_query(data, way, shot, query, ep_per_batch=1):\n","    img_shape = data.shape[1:]\n","    data = data.view(ep_per_batch, way, shot + query, *img_shape)\n","    x_shot, x_query = data.split([shot, query], dim=2)\n","    x_shot = x_shot.contiguous()\n","    x_query = x_query.contiguous().view(ep_per_batch, way * query, *img_shape)\n","    return x_shot, x_query\n","\n","\n","def make_nk_label(n, k, ep_per_batch=1):\n","    label = torch.arange(n).unsqueeze(1).expand(n, k).reshape(-1)\n","    label = label.repeat(ep_per_batch)\n","    return label\n","\n"]},{"cell_type":"code","execution_count":21,"id":"a1af3665","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:34:01.746203Z","iopub.status.busy":"2024-03-19T12:34:01.745766Z","iopub.status.idle":"2024-03-19T12:34:01.794243Z","shell.execute_reply":"2024-03-19T12:34:01.793196Z","shell.execute_reply.started":"2024-03-19T12:34:01.746168Z"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1710833271614,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"},"user_tz":-60},"id":"b23e2e2e","trusted":true},"outputs":[],"source":["def main(config):\n","    svname = None\n","    if svname is None:\n","        svname = 'classifier_{}'.format(config['train_dataset'])\n","        svname += '_' + config['model_args']['encoder']\n","        clsfr = config['model_args']['classifier']\n","        if clsfr != 'linear-classifier':\n","            svname += '-' + clsfr\n","    # if args.tag is not None:\n","    #     svname += '_' + args.tag\n","    save_path = os.path.join(SOURCE_DIRECTORY + './../output/save', svname)\n","    ensure_path(save_path)\n","    set_log_path(save_path)\n","    writer = SummaryWriter(os.path.join(save_path, 'tensorboard'))\n","\n","    yaml.dump(config, open(os.path.join(save_path, 'config.yaml'), 'w'))\n","\n","    #### Dataset ####\n","\n","    # train\n","    train_dataset = datasets_make(config['train_dataset'],\n","                                  **config['train_dataset_args'])\n","    train_loader = DataLoader(train_dataset, config['batch_size'], shuffle=True,\n","                              num_workers=8, pin_memory=True)\n","    log('train dataset: {} (x{}), {}'.format(\n","            train_dataset[0][0].shape, len(train_dataset),\n","            train_dataset.n_classes))\n","    if config.get('visualize_datasets'):\n","        visualize_dataset(train_dataset, 'train_dataset', writer)\n","\n","    # val\n","    if config.get('val_dataset'):\n","        eval_val = True\n","        val_dataset = datasets_make(config['val_dataset'],\n","                                    **config['val_dataset_args'])\n","        val_loader = DataLoader(val_dataset, config['batch_size'],\n","                                num_workers=8, pin_memory=True)\n","        log('val dataset: {} (x{}), {}'.format(\n","                val_dataset[0][0].shape, len(val_dataset),\n","                val_dataset.n_classes))\n","        if config.get('visualize_datasets'):\n","            visualize_dataset(val_dataset, 'val_dataset', writer)\n","    else:\n","        eval_val = False\n","\n","    # few-shot eval\n","    if config.get('fs_dataset'):\n","        ef_epoch = config.get('eval_fs_epoch')\n","        if ef_epoch is None:\n","            ef_epoch = 5\n","        eval_fs = True\n","\n","        fs_dataset = datasets_make(config['fs_dataset'],\n","                                   **config['fs_dataset_args'])\n","        log('fs dataset: {} (x{}), {}'.format(\n","                fs_dataset[0][0].shape, len(fs_dataset),\n","                fs_dataset.n_classes))\n","        if config.get('visualize_datasets'):\n","            visualize_dataset(fs_dataset, 'fs_dataset', writer)\n","\n","        n_way = 5\n","        n_query = 15\n","        n_shots = [1, 5]\n","        fs_loaders = []\n","        for n_shot in n_shots:\n","            fs_sampler = CategoriesSampler(\n","                    fs_dataset.label, 200,\n","                    n_way, n_shot + n_query, ep_per_batch=4)\n","            fs_loader = DataLoader(fs_dataset, batch_sampler=fs_sampler,\n","                                   num_workers=8, pin_memory=True)\n","            fs_loaders.append(fs_loader)\n","    else:\n","        eval_fs = False\n","\n","    ########\n","\n","    #### Model and Optimizer ####\n","\n","    if config.get('load'):\n","        model_sv = torch.load(config['load'])\n","        model = models_load(model_sv)\n","    else:\n","        model = models_make(config['model'], **config['model_args'])\n","\n","    if eval_fs:\n","        fs_model = models_make('meta-baseline', encoder=None)\n","        fs_model.encoder = model.encoder\n","\n","    if config.get('_parallel'):\n","        model = nn.DataParallel(model)\n","        if eval_fs:\n","            fs_model = nn.DataParallel(fs_model)\n","\n","    log('num params: {}'.format(compute_n_params(model)))\n","\n","    optimizer, lr_scheduler = make_optimizer(\n","            model.parameters(),\n","            config['optimizer'], **config['optimizer_args'])\n","\n","    ########\n","\n","    max_epoch = config['max_epoch']\n","    save_epoch = config.get('save_epoch')\n","    max_va = 0.\n","    timer_used = Timer()\n","    timer_epoch = Timer()\n","\n","    for epoch in range(1, max_epoch + 1 + 1):\n","        if epoch == max_epoch + 1:\n","            if not config.get('epoch_ex'):\n","                break\n","            train_dataset.transform = train_dataset.default_transform\n","            train_loader = DataLoader(\n","                    train_dataset, config['batch_size'], shuffle=True,\n","                    num_workers=8, pin_memory=True)\n","\n","        timer_epoch.s()\n","        aves_keys = ['tl', 'ta', 'vl', 'va']\n","        if eval_fs:\n","            for n_shot in n_shots:\n","                aves_keys += ['fsa-' + str(n_shot)]\n","        aves = {k: Averager() for k in aves_keys}\n","\n","        # train\n","        model.train()\n","        writer.add_scalar('lr', optimizer.param_groups[0]['lr'], epoch)\n","\n","        for data, label in tqdm(train_loader, desc='train', leave=False):\n","            data, label = data.cuda(), label.cuda()\n","            logits = model(data)\n","            loss = F.cross_entropy(logits, label)\n","            acc = compute_acc(logits, label)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            aves['tl'].add(loss.item())\n","            aves['ta'].add(acc)\n","\n","            logits = None; loss = None\n","\n","        # eval\n","        if eval_val:\n","            model.eval()\n","            for data, label in tqdm(val_loader, desc='val', leave=False):\n","                data, label = data.cuda(), label.cuda()\n","                with torch.no_grad():\n","                    logits = model(data)\n","                    loss = F.cross_entropy(logits, label)\n","                    acc = compute_acc(logits, label)\n","\n","                aves['vl'].add(loss.item())\n","                aves['va'].add(acc)\n","\n","        if eval_fs and (epoch % ef_epoch == 0 or epoch == max_epoch + 1):\n","            fs_model.eval()\n","            for i, n_shot in enumerate(n_shots):\n","                np.random.seed(0)\n","                for data, _ in tqdm(fs_loaders[i],\n","                                    desc='fs-' + str(n_shot), leave=False):\n","                    x_shot, x_query = split_shot_query(\n","                            data.cuda(), n_way, n_shot, n_query, ep_per_batch=4)\n","                    label = make_nk_label(\n","                            n_way, n_query, ep_per_batch=4).cuda()\n","                    with torch.no_grad():\n","                        logits = fs_model(x_shot, x_query).view(-1, n_way)\n","                        acc = compute_acc(logits, label)\n","                    aves['fsa-' + str(n_shot)].add(acc)\n","\n","        # post\n","        if lr_scheduler is not None:\n","            lr_scheduler.step()\n","\n","        for k, v in aves.items():\n","            aves[k] = v.item()\n","\n","        t_epoch = time_str(timer_epoch.t())\n","        t_used = time_str(timer_used.t())\n","        t_estimate = time_str(timer_used.t() / epoch * max_epoch)\n","\n","        if epoch <= max_epoch:\n","            epoch_str = str(epoch)\n","        else:\n","            epoch_str = 'ex'\n","        log_str = 'epoch {}, train {:.4f}|{:.4f}'.format(\n","                epoch_str, aves['tl'], aves['ta'])\n","        writer.add_scalars('loss', {'train': aves['tl']}, epoch)\n","        writer.add_scalars('acc', {'train': aves['ta']}, epoch)\n","\n","        if eval_val:\n","            log_str += ', val {:.4f}|{:.4f}'.format(aves['vl'], aves['va'])\n","            writer.add_scalars('loss', {'val': aves['vl']}, epoch)\n","            writer.add_scalars('acc', {'val': aves['va']}, epoch)\n","\n","        if eval_fs and (epoch % ef_epoch == 0 or epoch == max_epoch + 1):\n","            log_str += ', fs'\n","            for n_shot in n_shots:\n","                key = 'fsa-' + str(n_shot)\n","                log_str += ' {}: {:.4f}'.format(n_shot, aves[key])\n","                writer.add_scalars('acc', {key: aves[key]}, epoch)\n","\n","        if epoch <= max_epoch:\n","            log_str += ', {} {}/{}'.format(t_epoch, t_used, t_estimate)\n","        else:\n","            log_str += ', {}'.format(t_epoch)\n","        log(log_str)\n","\n","        if config.get('_parallel'):\n","            model_ = model.module\n","        else:\n","            model_ = model\n","\n","        training = {\n","            'epoch': epoch,\n","            'optimizer': config['optimizer'],\n","            'optimizer_args': config['optimizer_args'],\n","            'optimizer_sd': optimizer.state_dict(),\n","        }\n","        save_obj = {\n","            'file': './output',\n","            'config': config,\n","\n","            'model': config['model'],\n","            'model_args': config['model_args'],\n","            'model_sd': model_.state_dict(),\n","\n","            'training': training,\n","        }\n","        if epoch <= max_epoch:\n","            torch.save(save_obj, os.path.join(save_path, 'epoch-last.pth'))\n","\n","            if (save_epoch is not None) and epoch % save_epoch == 0:\n","                torch.save(save_obj, os.path.join(\n","                    save_path, 'epoch-{}.pth'.format(epoch)))\n","\n","            if aves['va'] > max_va:\n","                max_va = aves['va']\n","                torch.save(save_obj, os.path.join(save_path, 'max-va.pth'))\n","        else:\n","            torch.save(save_obj, os.path.join(save_path, 'epoch-ex.pth'))\n","\n","        writer.flush()"]},{"cell_type":"code","execution_count":22,"id":"fbf4e8e7","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:34:05.007106Z","iopub.status.busy":"2024-03-19T12:34:05.005944Z","iopub.status.idle":"2024-03-19T12:34:05.022730Z","shell.execute_reply":"2024-03-19T12:34:05.021863Z","shell.execute_reply.started":"2024-03-19T12:34:05.007074Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['miniImageNet_category_split_train_phase_val.pickle',\n"," 'miniImageNet_category_split_train_phase_train.pickle',\n"," 'miniImageNet_category_split_train_phase_test.pickle',\n"," 'miniImageNet_category_split_test.pickle',\n"," 'miniImageNet_category_split_val.pickle']"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["os.listdir('./../input/mini-imagenet')"]},{"cell_type":"code","execution_count":23,"id":"2415b925","metadata":{"execution":{"iopub.execute_input":"2024-03-19T12:34:05.208254Z","iopub.status.busy":"2024-03-19T12:34:05.207174Z","iopub.status.idle":"2024-03-19T12:34:05.212636Z","shell.execute_reply":"2024-03-19T12:34:05.211764Z","shell.execute_reply.started":"2024-03-19T12:34:05.208212Z"},"trusted":true},"outputs":[],"source":["assert torch.cuda.is_available() == True"]},{"cell_type":"code","execution_count":24,"id":"362a2eb1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-03-19T12:34:05.835841Z","iopub.status.busy":"2024-03-19T12:34:05.834976Z","iopub.status.idle":"2024-03-19T14:52:17.755721Z","shell.execute_reply":"2024-03-19T14:52:17.754806Z","shell.execute_reply.started":"2024-03-19T12:34:05.835808Z"},"id":"212c3a37","lines_to_next_cell":2,"outputId":"18dad718-8021-48cb-bea5-998b0faab9a6","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["set gpu: 4\n"]},{"name":"stdout","output_type":"stream","text":["input./../output/save/classifier_mini-imagenet_resnet12 exists, remove? ([y]/n):  y\n"]},{"name":"stdout","output_type":"stream","text":["train dataset: torch.Size([3, 80, 80]) (x38400), 64\n","val dataset: torch.Size([3, 80, 80]) (x18748), 64\n","fs dataset: torch.Size([3, 80, 80]) (x12000), 20\n","num params: 8.0M\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 1, train 3.6984|0.1145, val 3.3639|0.1626, 1.2m 1.2m/1.9h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 2, train 3.2955|0.1734, val 3.1228|0.2134, 1.1m 2.3m/1.9h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 3, train 3.0868|0.2241, val 2.9296|0.2554, 1.1m 3.5m/1.9h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 4, train 2.8423|0.2728, val 2.7713|0.2804, 1.2m 4.6m/1.9h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 5, train 2.6156|0.3230, val 2.5318|0.3353, fs 1: 0.4458 5: 0.5901, 2.3m 6.9m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 6, train 2.4439|0.3612, val 2.3960|0.3808, 1.1m 8.1m/2.2h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 7, train 2.3082|0.3923, val 2.1968|0.4190, 1.1m 9.2m/2.2h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 8, train 2.1960|0.4191, val 2.1480|0.4300, 1.1m 10.4m/2.2h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 9, train 2.0975|0.4412, val 2.1621|0.4191, 1.2m 11.5m/2.1h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 10, train 2.0208|0.4622, val 1.9040|0.4830, fs 1: 0.5006 5: 0.6655, 2.3m 13.8m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 11, train 1.9568|0.4765, val 2.1400|0.4542, 1.1m 15.0m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 12, train 1.9168|0.4881, val 1.9496|0.4844, 1.1m 16.1m/2.2h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 13, train 1.8658|0.5009, val 2.0359|0.4751, 1.1m 17.3m/2.2h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 14, train 1.8249|0.5110, val 1.7129|0.5315, 1.2m 18.4m/2.2h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 15, train 1.7786|0.5250, val 1.9098|0.4905, fs 1: 0.5010 5: 0.6738, 2.3m 20.7m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 16, train 1.7468|0.5323, val 1.7278|0.5364, 1.1m 21.9m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 17, train 1.7037|0.5420, val 1.8267|0.5118, 1.1m 23.0m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 18, train 1.6742|0.5458, val 1.6945|0.5414, 1.2m 24.2m/2.2h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 19, train 1.6635|0.5516, val 1.9721|0.4940, 1.1m 25.3m/2.2h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 20, train 1.6392|0.5580, val 1.8066|0.5243, fs 1: 0.5191 5: 0.6895, 2.3m 27.6m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 21, train 1.6162|0.5633, val 1.6615|0.5516, 1.1m 28.8m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 22, train 1.5961|0.5666, val 1.6023|0.5692, 1.2m 29.9m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 23, train 1.5802|0.5730, val 1.5624|0.5753, 1.1m 31.1m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 24, train 1.5598|0.5789, val 1.5448|0.5804, 1.1m 32.3m/2.2h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 25, train 1.5637|0.5771, val 1.6340|0.5620, fs 1: 0.5139 5: 0.6889, 2.3m 34.5m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 26, train 1.5464|0.5788, val 1.5908|0.5690, 1.2m 35.7m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 27, train 1.5320|0.5850, val 1.6182|0.5662, 1.1m 36.9m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 28, train 1.5116|0.5886, val 1.4829|0.5998, 1.1m 38.0m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 29, train 1.5192|0.5871, val 1.5693|0.5808, 1.1m 39.2m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 30, train 1.4968|0.5951, val 1.6393|0.5712, fs 1: 0.5249 5: 0.6921, 2.3m 41.4m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 31, train 1.4912|0.5933, val 1.5616|0.5847, 1.1m 42.6m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 32, train 1.4922|0.5914, val 1.4971|0.6032, 1.1m 43.7m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 33, train 1.4855|0.5954, val 1.5391|0.5849, 1.1m 44.9m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 34, train 1.4594|0.6044, val 1.5524|0.5949, 1.1m 46.0m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 35, train 1.4718|0.6010, val 1.5424|0.5832, fs 1: 0.5416 5: 0.7122, 2.3m 48.3m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 36, train 1.4702|0.6011, val 1.4489|0.6096, 1.1m 49.5m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 37, train 1.4560|0.6048, val 1.5840|0.5772, 1.1m 50.6m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 38, train 1.4612|0.6031, val 1.5005|0.6027, 1.1m 51.8m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 39, train 1.4470|0.6040, val 1.5266|0.5904, 1.1m 52.9m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 40, train 1.4471|0.6068, val 1.5275|0.5897, fs 1: 0.5179 5: 0.6913, 2.3m 55.2m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 41, train 1.4415|0.6068, val 1.4185|0.6135, 1.1m 56.3m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 42, train 1.4277|0.6105, val 1.5933|0.5799, 1.1m 57.5m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 43, train 1.4349|0.6096, val 1.7131|0.5415, 1.1m 58.6m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 44, train 1.4283|0.6123, val 1.5904|0.5779, 1.1m 59.8m/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 45, train 1.4213|0.6138, val 1.4554|0.6051, fs 1: 0.5317 5: 0.7008, 2.3m 1.0h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 46, train 1.4192|0.6108, val 1.5541|0.5832, 1.1m 1.1h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 47, train 1.4173|0.6175, val 1.5659|0.5876, 1.1m 1.1h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 48, train 1.4186|0.6146, val 1.4097|0.6217, 1.1m 1.1h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 49, train 1.4186|0.6120, val 1.5120|0.5903, 1.1m 1.1h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 50, train 1.4167|0.6121, val 1.4565|0.6009, fs 1: 0.5301 5: 0.7078, 2.3m 1.1h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 51, train 1.4057|0.6167, val 1.4945|0.5980, 1.1m 1.2h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 52, train 1.3998|0.6224, val 1.5538|0.5869, 1.2m 1.2h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 53, train 1.3889|0.6202, val 1.5215|0.5920, 1.1m 1.2h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 54, train 1.4073|0.6159, val 1.4424|0.6151, 1.1m 1.2h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 55, train 1.3902|0.6204, val 1.4748|0.6042, fs 1: 0.5450 5: 0.7177, 2.3m 1.3h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 56, train 1.3892|0.6228, val 1.5571|0.5873, 1.1m 1.3h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 57, train 1.3913|0.6226, val 1.6078|0.5986, 1.1m 1.3h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 58, train 1.3835|0.6223, val 1.4912|0.6058, 1.1m 1.3h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 59, train 1.3759|0.6240, val 1.4449|0.6141, 1.1m 1.3h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 60, train 1.3907|0.6220, val 1.7371|0.5791, fs 1: 0.5315 5: 0.7116, 2.3m 1.4h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 61, train 1.3758|0.6247, val 1.6858|0.5655, 1.1m 1.4h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 62, train 1.3871|0.6248, val 1.6476|0.5852, 1.1m 1.4h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 63, train 1.3728|0.6243, val 1.3989|0.6188, 1.1m 1.4h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 64, train 1.3806|0.6218, val 1.4342|0.6184, 1.1m 1.5h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 65, train 1.3782|0.6258, val 1.3750|0.6249, fs 1: 0.5561 5: 0.7255, 2.3m 1.5h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 66, train 1.3757|0.6259, val 1.4634|0.6118, 1.1m 1.5h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 67, train 1.3693|0.6247, val 1.5528|0.5930, 1.1m 1.5h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 68, train 1.3731|0.6259, val 1.3836|0.6297, 1.1m 1.6h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 69, train 1.3790|0.6265, val 1.3333|0.6341, 1.1m 1.6h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 70, train 1.3741|0.6263, val 1.4144|0.6211, fs 1: 0.5412 5: 0.7133, 2.3m 1.6h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 71, train 1.3821|0.6227, val 1.6143|0.5705, 1.2m 1.6h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 72, train 1.3745|0.6243, val 1.4223|0.6132, 1.1m 1.6h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 73, train 1.3664|0.6278, val 1.5934|0.5781, 1.1m 1.7h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 74, train 1.3609|0.6260, val 1.5010|0.6049, 1.1m 1.7h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 75, train 1.3568|0.6285, val 1.6036|0.5849, fs 1: 0.5249 5: 0.7003, 2.3m 1.7h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 76, train 1.3523|0.6317, val 1.3894|0.6331, 1.1m 1.7h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 77, train 1.3641|0.6264, val 1.5603|0.5893, 1.1m 1.8h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 78, train 1.3503|0.6282, val 1.3827|0.6296, 1.1m 1.8h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 79, train 1.3611|0.6288, val 1.6013|0.5914, 1.1m 1.8h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 80, train 1.3563|0.6297, val 1.4456|0.6089, fs 1: 0.5518 5: 0.7234, 2.3m 1.8h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 81, train 1.3547|0.6274, val 1.5617|0.5793, 1.1m 1.9h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 82, train 1.3419|0.6331, val 1.4394|0.6097, 1.1m 1.9h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 83, train 1.3601|0.6297, val 1.4975|0.5972, 1.1m 1.9h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 84, train 1.3624|0.6263, val 1.3761|0.6264, 1.1m 1.9h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 85, train 1.3500|0.6297, val 1.4449|0.6151, fs 1: 0.5515 5: 0.7223, 2.3m 2.0h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 86, train 1.3571|0.6312, val 1.4712|0.6106, 1.1m 2.0h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 87, train 1.3296|0.6366, val 1.3922|0.6207, 1.1m 2.0h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 88, train 1.3479|0.6324, val 1.5463|0.5897, 1.1m 2.0h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 89, train 1.3528|0.6297, val 1.3865|0.6249, 1.1m 2.0h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 90, train 1.3496|0.6321, val 1.5777|0.5836, fs 1: 0.5351 5: 0.7074, 2.3m 2.1h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 91, train 1.0016|0.7297, val 0.8438|0.7687, 1.1m 2.1h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 92, train 0.8767|0.7604, val 0.7991|0.7808, 1.1m 2.1h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 93, train 0.8258|0.7744, val 0.7921|0.7815, 1.1m 2.1h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 94, train 0.7931|0.7820, val 0.7862|0.7847, 1.1m 2.1h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 95, train 0.7719|0.7891, val 0.7856|0.7839, fs 1: 0.5979 5: 0.7810, 2.3m 2.2h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 96, train 0.7393|0.7968, val 0.7740|0.7875, 1.1m 2.2h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 97, train 0.7150|0.8033, val 0.7724|0.7899, 1.1m 2.2h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 98, train 0.7160|0.8042, val 0.7722|0.7902, 1.1m 2.2h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 99, train 0.6976|0.8060, val 0.7858|0.7876, 1.1m 2.3h/2.3h\n"]},{"name":"stderr","output_type":"stream","text":["                                                        \r"]},{"name":"stdout","output_type":"stream","text":["epoch 100, train 0.6863|0.8089, val 0.7811|0.7898, fs 1: 0.6052 5: 0.7846, 2.3m 2.3h/2.3h\n"]}],"source":["if __name__ == '__main__':\n","    # parser = argparse.ArgumentParser()\n","    # parser.add_argument('--config')\n","    # parser.add_argument('--name', default=None)\n","    # parser.add_argument('--tag', default=None)\n","    # parser.add_argument('--gpu', default='0')\n","    # args = parser.parse_args()\n","\n","    # config = yaml.load(open(args.config, 'r'), Loader=yaml.FullLoader)\n","    # if len(args.gpu.split(',')) > 1:\n","    #     config['_parallel'] = True\n","    #     config['_gpu'] = args.gpu\n","\n","    config = {  'train_dataset': 'mini-imagenet',\n","            'train_dataset_args': {\n","                'split': 'train',\n","                'augment': 'resize'\n","                },\n","                'val_dataset': 'mini-imagenet',\n","                'val_dataset_args': {\n","                    'split': 'train_phase_val'\n","                    },\n","                'fs_dataset': 'mini-imagenet',\n","                'fs_dataset_args': {\n","                    'split': 'test'\n","                    },\n","                'eval_fs_epoch': 5,\n","                'model': 'classifier',\n","                'model_args': {\n","                    'encoder': 'resnet12',\n","                    'encoder_args': {},\n","                    'classifier': 'linear-classifier',\n","                    'classifier_args': {\n","                        'n_classes': 64\n","                        }\n","                    },\n","                'batch_size': 128,\n","                'max_epoch': 100,\n","                'optimizer': 'sgd',\n","                'optimizer_args': {\n","                    'lr': 0.1,\n","                    'weight_decay': 0.0005,\n","                    'milestones': [90]\n","                    },\n","                'save_epoch': 5,\n","                'visualize_datasets': True\n","                }\n","\n","    set_gpu(\"4\")\n","    main(config)"]},{"cell_type":"code","execution_count":25,"id":"256c0421","metadata":{"execution":{"iopub.execute_input":"2024-03-19T15:06:58.714321Z","iopub.status.busy":"2024-03-19T15:06:58.713425Z","iopub.status.idle":"2024-03-19T15:08:12.233078Z","shell.execute_reply":"2024-03-19T15:08:12.231865Z","shell.execute_reply.started":"2024-03-19T15:06:58.714286Z"},"id":"ARBRZATYe6TS","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: kaggle/working/ (stored 0%)\n","  adding: kaggle/working/output/ (stored 0%)\n","  adding: kaggle/working/output/save/ (stored 0%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/ (stored 0%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/max-va.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-25.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/config.yaml (deflated 53%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-20.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/log.txt (deflated 72%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-5.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-75.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/tensorboard/ (stored 0%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/tensorboard/events.out.tfevents.1710851648.19b915bc6133 (deflated 0%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/tensorboard/acc/ (stored 0%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/tensorboard/acc/train/ (stored 0%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/tensorboard/acc/train/events.out.tfevents.1710851740.19b915bc6133 (deflated 57%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/tensorboard/acc/fsa-5/ (stored 0%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/tensorboard/acc/fsa-5/events.out.tfevents.1710852086.19b915bc6133 (deflated 47%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/tensorboard/acc/val/ (stored 0%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/tensorboard/acc/val/events.out.tfevents.1710851740.19b915bc6133 (deflated 56%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/tensorboard/acc/fsa-1/ (stored 0%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/tensorboard/acc/fsa-1/events.out.tfevents.1710852086.19b915bc6133 (deflated 48%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/tensorboard/loss/ (stored 0%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/tensorboard/loss/train/ (stored 0%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/tensorboard/loss/train/events.out.tfevents.1710851740.19b915bc6133 (deflated 57%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/tensorboard/loss/val/ (stored 0%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/tensorboard/loss/val/events.out.tfevents.1710851740.19b915bc6133 (deflated 57%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-last.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-35.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-15.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-50.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-55.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-10.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-90.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-100.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-80.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-60.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-65.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-85.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-70.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-95.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-40.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-30.pth (deflated 7%)\n","  adding: kaggle/working/output/save/classifier_mini-imagenet_resnet12/epoch-45.pth (deflated 7%)\n","  adding: kaggle/working/input./ (stored 0%)\n","  adding: kaggle/working/.virtual_documents/ (stored 0%)\n"]}],"source":["!zip -r file.zip /kaggle/working"]},{"cell_type":"code","execution_count":26,"id":"b080d097","metadata":{"execution":{"iopub.execute_input":"2024-03-19T15:19:47.895479Z","iopub.status.busy":"2024-03-19T15:19:47.894802Z","iopub.status.idle":"2024-03-19T15:19:47.904244Z","shell.execute_reply":"2024-03-19T15:19:47.903400Z","shell.execute_reply.started":"2024-03-19T15:19:47.895448Z"},"trusted":true},"outputs":[{"data":{"text/html":["<a href='file.zip' target='_blank'>file.zip</a><br>"],"text/plain":["/kaggle/working/file.zip"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import FileLink\n","FileLink(r'file.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4627769,"sourceId":7883994,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":5}
