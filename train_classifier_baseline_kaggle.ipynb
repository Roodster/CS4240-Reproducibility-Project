{"metadata":{"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"colab":{"provenance":[],"gpuType":"T4"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7883994,"sourceType":"datasetVersion","datasetId":4627769}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorboardX","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rAhYhRtWd-U3","executionInfo":{"status":"ok","timestamp":1710833268810,"user_tz":-60,"elapsed":11064,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"}},"outputId":"237d63b8-9b42-4dd1-c0f6-e52d7e26b45a","execution":{"iopub.status.busy":"2024-03-19T12:23:38.089811Z","iopub.execute_input":"2024-03-19T12:23:38.090410Z","iopub.status.idle":"2024-03-19T12:24:11.431203Z","shell.execute_reply.started":"2024-03-19T12:23:38.090379Z","shell.execute_reply":"2024-03-19T12:24:11.430256Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorboardX in /opt/conda/lib/python3.10/site-packages (2.6.2.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorboardX) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorboardX) (21.3)\nRequirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.10/site-packages (from tensorboardX) (3.20.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorboardX) (3.1.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import argparse\nimport os\nimport yaml\nimport json\nfrom PIL import Image\nimport pickle\nimport numpy as np\nimport math\nimport shutil\nimport time","metadata":{"id":"b64c1de4","executionInfo":{"status":"ok","timestamp":1710833268811,"user_tz":-60,"elapsed":9,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"}},"execution":{"iopub.status.busy":"2024-03-19T12:24:13.380388Z","iopub.execute_input":"2024-03-19T12:24:13.380749Z","iopub.status.idle":"2024-03-19T12:24:13.408949Z","shell.execute_reply.started":"2024-03-19T12:24:13.380719Z","shell.execute_reply":"2024-03-19T12:24:13.408099Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom tensorboardX import SummaryWriter\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom torch.optim import SGD, Adam\nfrom torch.optim.lr_scheduler import MultiStepLR\n","metadata":{"id":"37c4bcdb","executionInfo":{"status":"ok","timestamp":1710833268811,"user_tz":-60,"elapsed":7,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"}},"execution":{"iopub.status.busy":"2024-03-19T12:24:13.549977Z","iopub.execute_input":"2024-03-19T12:24:13.550346Z","iopub.status.idle":"2024-03-19T12:24:25.140278Z","shell.execute_reply.started":"2024-03-19T12:24:13.550301Z","shell.execute_reply":"2024-03-19T12:24:25.139456Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"assert torch.cuda.is_available() == True","metadata":{"execution":{"iopub.status.busy":"2024-03-19T12:24:25.141757Z","iopub.execute_input":"2024-03-19T12:24:25.143268Z","iopub.status.idle":"2024-03-19T12:24:25.181511Z","shell.execute_reply.started":"2024-03-19T12:24:25.143238Z","shell.execute_reply":"2024-03-19T12:24:25.180354Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\n\nSOURCE_DIRECTORY = f\"input\"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13Kkb3Bzcpve","executionInfo":{"status":"ok","timestamp":1710833271163,"user_tz":-60,"elapsed":2359,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"}},"outputId":"fcf48dc5-7f23-4e0f-9c89-37d90a9b6388","execution":{"iopub.status.busy":"2024-03-19T12:24:25.182807Z","iopub.execute_input":"2024-03-19T12:24:25.183102Z","iopub.status.idle":"2024-03-19T12:24:25.196945Z","shell.execute_reply.started":"2024-03-19T12:24:25.183077Z","shell.execute_reply":"2024-03-19T12:24:25.196235Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\n_log_path = None\n\ndef set_log_path(path):\n    global _log_path\n    _log_path = path\n\ndef log(obj, filename='log.txt'):\n    print(obj)\n    if _log_path is not None:\n        with open(os.path.join(_log_path, filename), 'a') as f:\n            print(obj, file=f)\n\n\nclass Averager():\n\n    def __init__(self):\n        self.n = 0.0\n        self.v = 0.0\n\n    def add(self, v, n=1.0):\n        self.v = (self.v * self.n + v * n) / (self.n + n)\n        self.n += n\n\n    def item(self):\n        return self.v\n\n\nclass Timer():\n\n    def __init__(self):\n        self.v = time.time()\n\n    def s(self):\n        self.v = time.time()\n\n    def t(self):\n        return time.time() - self.v\n\n\ndef set_gpu(gpu):\n    print('set gpu:', gpu)\n    os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n\n\ndef ensure_path(path, remove=True):\n    basename = os.path.basename(path.rstrip('/'))\n    if os.path.exists(path):\n        if remove and (basename.startswith('_')\n                or input('{} exists, remove? ([y]/n): '.format(path)) != 'n'):\n            shutil.rmtree(path)\n            os.makedirs(path)\n    else:\n        os.makedirs(path)\n\n\ndef time_str(t):\n    if t >= 3600:\n        return '{:.1f}h'.format(t / 3600)\n    if t >= 60:\n        return '{:.1f}m'.format(t / 60)\n    return '{:.1f}s'.format(t)\n\n\ndef compute_logits(feat, proto, metric='dot', temp=1.0):\n    assert feat.dim() == proto.dim()\n\n    if feat.dim() == 2:\n        if metric == 'dot':\n            logits = torch.mm(feat, proto.t())\n        elif metric == 'cos':\n            logits = torch.mm(F.normalize(feat, dim=-1),\n                              F.normalize(proto, dim=-1).t())\n        elif metric == 'sqr':\n            logits = -(feat.unsqueeze(1) -\n                       proto.unsqueeze(0)).pow(2).sum(dim=-1)\n\n    elif feat.dim() == 3:\n        if metric == 'dot':\n            logits = torch.bmm(feat, proto.permute(0, 2, 1))\n        elif metric == 'cos':\n            logits = torch.bmm(F.normalize(feat, dim=-1),\n                               F.normalize(proto, dim=-1).permute(0, 2, 1))\n        elif metric == 'sqr':\n            logits = -(feat.unsqueeze(2) -\n                       proto.unsqueeze(1)).pow(2).sum(dim=-1)\n\n    return logits * temp\n\n\ndef compute_acc(logits, label, reduction='mean'):\n    ret = (torch.argmax(logits, dim=1) == label).float()\n    if reduction == 'none':\n        return ret.detach()\n    elif reduction == 'mean':\n        return ret.mean().item()\n\n\ndef compute_n_params(model, return_str=True):\n    tot = 0\n    for p in model.parameters():\n        w = 1\n        for x in p.shape:\n            w *= x\n        tot += w\n    if return_str:\n        if tot >= 1e6:\n            return '{:.1f}M'.format(tot / 1e6)\n        else:\n            return '{:.1f}K'.format(tot / 1e3)\n    else:\n        return tot\n\n\ndef make_optimizer(params, name, lr, weight_decay=None, milestones=None):\n    if weight_decay is None:\n        weight_decay = 0.\n    if name == 'sgd':\n        optimizer = SGD(params, lr, momentum=0.9, weight_decay=weight_decay)\n    elif name == 'adam':\n        optimizer = Adam(params, lr, weight_decay=weight_decay)\n    if milestones:\n        lr_scheduler = MultiStepLR(optimizer, milestones)\n    else:\n        lr_scheduler = None\n    return optimizer, lr_scheduler\n\n\ndef visualize_dataset(dataset, name, writer, n_samples=16):\n    demo = []\n    for i in np.random.choice(len(dataset), n_samples):\n        demo.append(dataset.convert_raw(dataset[i][0]))\n    writer.add_images('visualize_' + name, torch.stack(demo))\n    writer.flush()\n\n\ndef freeze_bn(model):\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d):\n            m.eval()\n\n","metadata":{"id":"zquFYmn6dAk7","executionInfo":{"status":"ok","timestamp":1710833271163,"user_tz":-60,"elapsed":10,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"}},"execution":{"iopub.status.busy":"2024-03-19T12:24:25.199103Z","iopub.execute_input":"2024-03-19T12:24:25.199399Z","iopub.status.idle":"2024-03-19T12:24:25.224782Z","shell.execute_reply.started":"2024-03-19T12:24:25.199375Z","shell.execute_reply":"2024-03-19T12:24:25.223918Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# DEFAULT_ROOT = \nDEFAULT_ROOT = \"./../input\"\n\n\ndatasets = {}\ndef datasets_register(name):\n    def decorator(cls):\n        datasets[name] = cls\n        return cls\n    return decorator\n\n\ndef datasets_make(name, **kwargs):\n    if kwargs.get('root_path') is None:\n        kwargs['root_path'] = os.path.join(DEFAULT_ROOT, name)\n    dataset = datasets[name](**kwargs)\n    return dataset\n\n","metadata":{"id":"zxr_LloTdAVM","executionInfo":{"status":"ok","timestamp":1710833271163,"user_tz":-60,"elapsed":9,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"}},"execution":{"iopub.status.busy":"2024-03-19T12:24:25.225843Z","iopub.execute_input":"2024-03-19T12:24:25.226161Z","iopub.status.idle":"2024-03-19T12:24:25.239443Z","shell.execute_reply.started":"2024-03-19T12:24:25.226138Z","shell.execute_reply":"2024-03-19T12:24:25.238236Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\n@datasets_register('image-folder')\nclass ImageFolder(Dataset):\n\n    def __init__(self, root_path, image_size=224, box_size=256, **kwargs):\n        if box_size is None:\n            box_size = image_size\n\n        self.filepaths = []\n        self.label = []\n        classes = sorted(os.listdir(root_path))\n\n        if kwargs.get('split'):\n            path = kwargs.get('split_file')\n            if path is None:\n                path = os.path.join(\n                        os.path.dirname(root_path.rstrip('/')), 'split.json')\n            split = json.load(open(path, 'r'))\n            classes = sorted(split[kwargs['split']])\n\n        for i, c in enumerate(classes):\n            for filename in sorted(os.listdir(os.path.join(root_path, c))):\n                self.filepaths.append(os.path.join(root_path, c, filename))\n                self.label.append(i)\n        self.n_classes = max(self.label) + 1\n\n        norm_params = {'mean': [0.485, 0.456, 0.406],\n                       'std': [0.229, 0.224, 0.225]}\n        normalize = transforms.Normalize(**norm_params)\n        if kwargs.get('augment'):\n            self.transform = transforms.Compose([\n                transforms.RandomResizedCrop(image_size),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                normalize,\n            ])\n        else:\n            self.transform = transforms.Compose([\n                transforms.Resize(box_size),\n                transforms.CenterCrop(image_size),\n                transforms.ToTensor(),\n                normalize,\n            ])\n\n        def convert_raw(x):\n            mean = torch.tensor(norm_params['mean']).view(3, 1, 1).type_as(x)\n            std = torch.tensor(norm_params['std']).view(3, 1, 1).type_as(x)\n            return x * std + mean\n        self.convert_raw = convert_raw\n\n    def __len__(self):\n        return len(self.filepaths)\n\n    def __getitem__(self, i):\n        img = Image.open(self.filepaths[i]).convert('RGB')\n        return self.transform(img), self.label[i]\n\n","metadata":{"id":"QOFXfUfkdAQG","executionInfo":{"status":"ok","timestamp":1710833271163,"user_tz":-60,"elapsed":9,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"}},"execution":{"iopub.status.busy":"2024-03-19T12:24:25.240608Z","iopub.execute_input":"2024-03-19T12:24:25.240860Z","iopub.status.idle":"2024-03-19T12:24:25.254867Z","shell.execute_reply.started":"2024-03-19T12:24:25.240839Z","shell.execute_reply":"2024-03-19T12:24:25.253860Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"@datasets_register('mini-imagenet')\nclass MiniImageNet(Dataset):\n\n    def __init__(self, root_path, split='train', **kwargs):\n        split_tag = split\n        if split == 'train':\n            split_tag = 'train_phase_train'\n        split_file = 'miniImageNet_category_split_{}.pickle'.format(split_tag)\n        with open(os.path.join(root_path, split_file), 'rb') as f:\n            pack = pickle.load(f, encoding='latin1')\n        data = pack['data']\n        label = pack['labels']\n\n        image_size = 80\n        data = [Image.fromarray(x) for x in data]\n\n        min_label = min(label)\n        label = [x - min_label for x in label]\n\n        self.data = data\n        self.label = label\n        self.n_classes = max(self.label) + 1\n\n        norm_params = {'mean': [0.485, 0.456, 0.406],\n                       'std': [0.229, 0.224, 0.225]}\n        normalize = transforms.Normalize(**norm_params)\n        self.default_transform = transforms.Compose([\n            transforms.Resize(image_size),\n            transforms.ToTensor(),\n            normalize,\n        ])\n        augment = kwargs.get('augment')\n        if augment == 'resize':\n            self.transform = transforms.Compose([\n                transforms.RandomResizedCrop(image_size),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                normalize,\n            ])\n        elif augment == 'crop':\n            self.transform = transforms.Compose([\n                transforms.Resize(image_size),\n                transforms.RandomCrop(image_size, padding=8),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                normalize,\n            ])\n        elif augment is None:\n            self.transform = self.default_transform\n\n        def convert_raw(x):\n            mean = torch.tensor(norm_params['mean']).view(3, 1, 1).type_as(x)\n            std = torch.tensor(norm_params['std']).view(3, 1, 1).type_as(x)\n            return x * std + mean\n        self.convert_raw = convert_raw\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, i):\n        return self.transform(self.data[i]), self.label[i]\n\n","metadata":{"id":"k0noCslgdASp","executionInfo":{"status":"ok","timestamp":1710833271163,"user_tz":-60,"elapsed":8,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"}},"execution":{"iopub.status.busy":"2024-03-19T12:24:25.256133Z","iopub.execute_input":"2024-03-19T12:24:25.256436Z","iopub.status.idle":"2024-03-19T12:24:25.270800Z","shell.execute_reply.started":"2024-03-19T12:24:25.256399Z","shell.execute_reply":"2024-03-19T12:24:25.270064Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\nclass CategoriesSampler():\n\n    def __init__(self, label, n_batch, n_cls, n_per, ep_per_batch=1):\n        self.n_batch = n_batch\n        self.n_cls = n_cls\n        self.n_per = n_per\n        self.ep_per_batch = ep_per_batch\n\n        label = np.array(label)\n        self.catlocs = []\n        for c in range(max(label) + 1):\n            self.catlocs.append(np.argwhere(label == c).reshape(-1))\n\n    def __len__(self):\n        return self.n_batch\n\n    def __iter__(self):\n        for i_batch in range(self.n_batch):\n            batch = []\n            for i_ep in range(self.ep_per_batch):\n                episode = []\n                classes = np.random.choice(len(self.catlocs), self.n_cls,\n                                           replace=False)\n                for c in classes:\n                    l = np.random.choice(self.catlocs[c], self.n_per,\n                                         replace=False)\n                    episode.append(torch.from_numpy(l))\n                episode = torch.stack(episode)\n                batch.append(episode)\n            batch = torch.stack(batch) # bs * n_cls * n_per\n            yield batch.view(-1)\n\n","metadata":{"id":"VuoXX_6adAXy","executionInfo":{"status":"ok","timestamp":1710833271163,"user_tz":-60,"elapsed":8,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"}},"execution":{"iopub.status.busy":"2024-03-19T12:24:25.272032Z","iopub.execute_input":"2024-03-19T12:24:25.272293Z","iopub.status.idle":"2024-03-19T12:24:25.285258Z","shell.execute_reply.started":"2024-03-19T12:24:25.272271Z","shell.execute_reply":"2024-03-19T12:24:25.284423Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\n\nmodels = {}\ndef models_register(name):\n    def decorator(cls):\n        models[name] = cls\n        return cls\n    return decorator\n\n\ndef models_make(name, **kwargs):\n    if name is None:\n        return None\n    model = models[name](**kwargs)\n    if torch.cuda.is_available():\n        model.cuda()\n    return model\n\n\ndef load(model_sv, name=None):\n    if name is None:\n        name = 'model'\n    model = make(model_sv[name], **model_sv[name + '_args'])\n    model.load_state_dict(model_sv[name + '_sd'])\n    return model\n\n","metadata":{"id":"TBNv3xjsiorL","executionInfo":{"status":"ok","timestamp":1710833271164,"user_tz":-60,"elapsed":9,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"}},"execution":{"iopub.status.busy":"2024-03-19T12:24:29.374901Z","iopub.execute_input":"2024-03-19T12:24:29.375281Z","iopub.status.idle":"2024-03-19T12:24:29.382442Z","shell.execute_reply.started":"2024-03-19T12:24:29.375248Z","shell.execute_reply":"2024-03-19T12:24:29.381462Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"@models_register('classifier')\nclass Classifier(nn.Module):\n\n    def __init__(self, encoder, encoder_args,\n                 classifier, classifier_args):\n        super().__init__()\n        self.encoder = models_make(encoder, **encoder_args)\n        classifier_args['in_dim'] = self.encoder.out_dim\n        self.classifier = models_make(classifier, **classifier_args)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.classifier(x)\n        return x\n\n\n@models_register('linear-classifier')\nclass LinearClassifier(nn.Module):\n\n    def __init__(self, in_dim, n_classes):\n        super().__init__()\n        self.linear = nn.Linear(in_dim, n_classes)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\n@models_register('nn-classifier')\nclass NNClassifier(nn.Module):\n\n    def __init__(self, in_dim, n_classes, metric='cos', temp=None):\n        super().__init__()\n        self.proto = nn.Parameter(torch.empty(n_classes, in_dim))\n        nn.init.kaiming_uniform_(self.proto, a=math.sqrt(5))\n        if temp is None:\n            if metric == 'cos':\n                temp = nn.Parameter(torch.tensor(10.))\n            else:\n                temp = 1.0\n        self.metric = metric\n        self.temp = temp\n\n    def forward(self, x):\n        return utils.compute_logits(x, self.proto, self.metric, self.temp)\n\n\ndef conv_block(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n    )\n\n\n@models_register('convnet4')\nclass ConvNet4(nn.Module):\n\n    def __init__(self, x_dim=3, hid_dim=64, z_dim=64):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            conv_block(x_dim, hid_dim),\n            conv_block(hid_dim, hid_dim),\n            conv_block(hid_dim, hid_dim),\n            conv_block(hid_dim, z_dim),\n        )\n        self.out_dim = 1600\n\n    def forward(self, x):\n        x = self.encoder(x)\n        return x.view(x.shape[0], -1)\n","metadata":{"id":"qgF5hpSudAdA","executionInfo":{"status":"ok","timestamp":1710833271612,"user_tz":-60,"elapsed":456,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"}},"execution":{"iopub.status.busy":"2024-03-19T12:24:29.559258Z","iopub.execute_input":"2024-03-19T12:24:29.559634Z","iopub.status.idle":"2024-03-19T12:24:29.573696Z","shell.execute_reply.started":"2024-03-19T12:24:29.559608Z","shell.execute_reply":"2024-03-19T12:24:29.572731Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\n@models_register('meta-baseline')\nclass MetaBaseline(nn.Module):\n\n    def __init__(self, encoder, encoder_args={}, method='cos',\n                 temp=10., temp_learnable=True):\n        super().__init__()\n        self.encoder = models_make(encoder, **encoder_args)\n        self.method = method\n\n        if temp_learnable:\n            self.temp = nn.Parameter(torch.tensor(temp))\n        else:\n            self.temp = temp\n\n    def forward(self, x_shot, x_query):\n        shot_shape = x_shot.shape[:-3]\n        query_shape = x_query.shape[:-3]\n        img_shape = x_shot.shape[-3:]\n\n        x_shot = x_shot.view(-1, *img_shape)\n        x_query = x_query.view(-1, *img_shape)\n        x_tot = self.encoder(torch.cat([x_shot, x_query], dim=0))\n        x_shot, x_query = x_tot[:len(x_shot)], x_tot[-len(x_query):]\n        x_shot = x_shot.view(*shot_shape, -1)\n        x_query = x_query.view(*query_shape, -1)\n\n        if self.method == 'cos':\n            x_shot = x_shot.mean(dim=-2)\n            x_shot = F.normalize(x_shot, dim=-1)\n            x_query = F.normalize(x_query, dim=-1)\n            metric = 'dot'\n        elif self.method == 'sqr':\n            x_shot = x_shot.mean(dim=-2)\n            metric = 'sqr'\n\n        logits = compute_logits(\n                x_query, x_shot, metric=metric, temp=self.temp)\n        return logits\n\n","metadata":{"id":"ZSZg1spbj8jJ","executionInfo":{"status":"ok","timestamp":1710833271612,"user_tz":-60,"elapsed":15,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"}},"execution":{"iopub.status.busy":"2024-03-19T12:24:29.724727Z","iopub.execute_input":"2024-03-19T12:24:29.725077Z","iopub.status.idle":"2024-03-19T12:24:29.736649Z","shell.execute_reply.started":"2024-03-19T12:24:29.725049Z","shell.execute_reply":"2024-03-19T12:24:29.735618Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\n__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n           'wide_resnet50_2', 'wide_resnet101_2']\n\n\ndef conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n\n\ndef conv1x1(in_planes, out_planes, stride=1):\n    \"\"\"1x1 convolution\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n    __constants__ = ['downsample']\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n                 base_width=64, dilation=1, norm_layer=None):\n        super(BasicBlock, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        if groups != 1 or base_width != 64:\n            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n        if dilation > 1:\n            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = norm_layer(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = norm_layer(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n    __constants__ = ['downsample']\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n                 base_width=64, dilation=1, norm_layer=None):\n        super(Bottleneck, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        width = int(planes * (base_width / 64.)) * groups\n        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n        self.conv1 = conv1x1(inplanes, width)\n        self.bn1 = norm_layer(width)\n        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n        self.bn2 = norm_layer(width)\n        self.conv3 = conv1x1(width, planes * self.expansion)\n        self.bn3 = norm_layer(planes * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, zero_init_residual=False,\n                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n                 norm_layer=None):\n        super(ResNet, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        self._norm_layer = norm_layer\n\n        self.inplanes = 64\n        self.dilation = 1\n        if replace_stride_with_dilation is None:\n            # each element in the tuple indicates if we should replace\n            # the 2x2 stride with a dilated convolution instead\n            replace_stride_with_dilation = [False, False, False]\n        if len(replace_stride_with_dilation) != 3:\n            raise ValueError(\"replace_stride_with_dilation should be None \"\n                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n        self.groups = groups\n        self.base_width = width_per_group\n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = norm_layer(self.inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n                                       dilate=replace_stride_with_dilation[0])\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n                                       dilate=replace_stride_with_dilation[1])\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n                                       dilate=replace_stride_with_dilation[2])\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.out_dim = 512 * block.expansion\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n        # Zero-initialize the last BN in each residual branch,\n        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n        if zero_init_residual:\n            for m in self.modules():\n                if isinstance(m, Bottleneck):\n                    nn.init.constant_(m.bn3.weight, 0)\n                elif isinstance(m, BasicBlock):\n                    nn.init.constant_(m.bn2.weight, 0)\n\n    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n        norm_layer = self._norm_layer\n        downsample = None\n        previous_dilation = self.dilation\n        if dilate:\n            self.dilation *= stride\n            stride = 1\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv1x1(self.inplanes, planes * block.expansion, stride),\n                norm_layer(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n                            self.base_width, previous_dilation, norm_layer))\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes, groups=self.groups,\n                                base_width=self.base_width, dilation=self.dilation,\n                                norm_layer=norm_layer))\n\n        return nn.Sequential(*layers)\n\n    def _forward_impl(self, x):\n        # See note [TorchScript super()]\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n\n        return x\n\n    def forward(self, x):\n        return self._forward_impl(x)\n\n\ndef _resnet(arch, block, layers, pretrained, progress, **kwargs):\n    model = ResNet(block, layers, **kwargs)\n    return model\n\n\n@models_register('resnet18')\ndef resnet18(pretrained=False, progress=True, **kwargs):\n    r\"\"\"ResNet-18 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n                   **kwargs)\n\n\ndef resnet34(pretrained=False, progress=True, **kwargs):\n    r\"\"\"ResNet-34 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress,\n                   **kwargs)\n\n\n@models_register('resnet50')\ndef resnet50(pretrained=False, progress=True, **kwargs):\n    r\"\"\"ResNet-50 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n                   **kwargs)\n\n\ndef resnet101(pretrained=False, progress=True, **kwargs):\n    r\"\"\"ResNet-101 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, progress,\n                   **kwargs)\n\n\ndef resnet152(pretrained=False, progress=True, **kwargs):\n    r\"\"\"ResNet-152 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress,\n                   **kwargs)\n\n\ndef resnext50_32x4d(pretrained=False, progress=True, **kwargs):\n    r\"\"\"ResNeXt-50 32x4d model from\n    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    kwargs['groups'] = 32\n    kwargs['width_per_group'] = 4\n    return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3],\n                   pretrained, progress, **kwargs)\n\n\ndef resnext101_32x8d(pretrained=False, progress=True, **kwargs):\n    r\"\"\"ResNeXt-101 32x8d model from\n    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    kwargs['groups'] = 32\n    kwargs['width_per_group'] = 8\n    return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\n                   pretrained, progress, **kwargs)\n\n\ndef wide_resnet50_2(pretrained=False, progress=True, **kwargs):\n    r\"\"\"Wide ResNet-50-2 model from\n    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1\n    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    kwargs['width_per_group'] = 64 * 2\n    return _resnet('wide_resnet50_2', Bottleneck, [3, 4, 6, 3],\n                   pretrained, progress, **kwargs)\n\n\ndef wide_resnet101_2(pretrained=False, progress=True, **kwargs):\n    r\"\"\"Wide ResNet-101-2 model from\n    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1\n    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    kwargs['width_per_group'] = 64 * 2\n    return _resnet('wide_resnet101_2', Bottleneck, [3, 4, 23, 3],\n                   pretrained, progress, **kwargs)\n","metadata":{"id":"Fiv27JoYdAfm","executionInfo":{"status":"ok","timestamp":1710833271613,"user_tz":-60,"elapsed":15,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"}},"execution":{"iopub.status.busy":"2024-03-19T12:24:29.896469Z","iopub.execute_input":"2024-03-19T12:24:29.896824Z","iopub.status.idle":"2024-03-19T12:24:29.945828Z","shell.execute_reply.started":"2024-03-19T12:24:29.896796Z","shell.execute_reply":"2024-03-19T12:24:29.944799Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\ndef conv3x3(in_planes, out_planes):\n    return nn.Conv2d(in_planes, out_planes, 3, padding=1, bias=False)\n\n\ndef conv1x1(in_planes, out_planes):\n    return nn.Conv2d(in_planes, out_planes, 1, bias=False)\n\n\ndef norm_layer(planes):\n    return nn.BatchNorm2d(planes)\n\n\nclass Block(nn.Module):\n\n    def __init__(self, inplanes, planes, downsample):\n        super().__init__()\n\n        self.relu = nn.LeakyReLU(0.1)\n\n        self.conv1 = conv3x3(inplanes, planes)\n        self.bn1 = norm_layer(planes)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = norm_layer(planes)\n        self.conv3 = conv3x3(planes, planes)\n        self.bn3 = norm_layer(planes)\n\n        self.downsample = downsample\n\n        self.maxpool = nn.MaxPool2d(2)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        out = self.maxpool(out)\n\n        return out\n\n\nclass ResNet12(nn.Module):\n\n    def __init__(self, channels):\n        super().__init__()\n\n        self.inplanes = 3\n\n        self.layer1 = self._make_layer(channels[0])\n        self.layer2 = self._make_layer(channels[1])\n        self.layer3 = self._make_layer(channels[2])\n        self.layer4 = self._make_layer(channels[3])\n\n        self.out_dim = channels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out',\n                                        nonlinearity='leaky_relu')\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def _make_layer(self, planes):\n        downsample = nn.Sequential(\n            conv1x1(self.inplanes, planes),\n            norm_layer(planes),\n        )\n        block = Block(self.inplanes, planes, downsample)\n        self.inplanes = planes\n        return block\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = x.view(x.shape[0], x.shape[1], -1).mean(dim=2)\n        return x\n\n\n@models_register('resnet12')\ndef resnet12():\n    return ResNet12([64, 128, 256, 512])\n\n\n@models_register('resnet12-wide')\ndef resnet12_wide():\n    return ResNet12([64, 160, 320, 640])\n\n","metadata":{"id":"Vj0MBInqdAiX","executionInfo":{"status":"ok","timestamp":1710833271613,"user_tz":-60,"elapsed":15,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"}},"execution":{"iopub.status.busy":"2024-03-19T12:24:30.046438Z","iopub.execute_input":"2024-03-19T12:24:30.047365Z","iopub.status.idle":"2024-03-19T12:24:30.064589Z","shell.execute_reply.started":"2024-03-19T12:24:30.047309Z","shell.execute_reply":"2024-03-19T12:24:30.063655Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\n\ndef split_shot_query(data, way, shot, query, ep_per_batch=1):\n    img_shape = data.shape[1:]\n    data = data.view(ep_per_batch, way, shot + query, *img_shape)\n    x_shot, x_query = data.split([shot, query], dim=2)\n    x_shot = x_shot.contiguous()\n    x_query = x_query.contiguous().view(ep_per_batch, way * query, *img_shape)\n    return x_shot, x_query\n\n\ndef make_nk_label(n, k, ep_per_batch=1):\n    label = torch.arange(n).unsqueeze(1).expand(n, k).reshape(-1)\n    label = label.repeat(ep_per_batch)\n    return label\n\n","metadata":{"id":"DATVlOexdAnf","executionInfo":{"status":"ok","timestamp":1710833271613,"user_tz":-60,"elapsed":14,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"}},"execution":{"iopub.status.busy":"2024-03-19T12:24:30.215415Z","iopub.execute_input":"2024-03-19T12:24:30.216000Z","iopub.status.idle":"2024-03-19T12:24:30.222506Z","shell.execute_reply.started":"2024-03-19T12:24:30.215971Z","shell.execute_reply":"2024-03-19T12:24:30.221640Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def main(config):\n    svname = None\n    if svname is None:\n        svname = 'classifier_{}'.format(config['train_dataset'])\n        svname += '_' + config['model_args']['encoder']\n        clsfr = config['model_args']['classifier']\n        if clsfr != 'linear-classifier':\n            svname += '-' + clsfr\n    # if args.tag is not None:\n    #     svname += '_' + args.tag\n    save_path = os.path.join(SOURCE_DIRECTORY + './../output/save', svname)\n    ensure_path(save_path)\n    set_log_path(save_path)\n    writer = SummaryWriter(os.path.join(save_path, 'tensorboard'))\n\n    yaml.dump(config, open(os.path.join(save_path, 'config.yaml'), 'w'))\n\n    #### Dataset ####\n\n    # train\n    train_dataset = datasets_make(config['train_dataset'],\n                                  **config['train_dataset_args'])\n    train_loader = DataLoader(train_dataset, config['batch_size'], shuffle=True,\n                              num_workers=8, pin_memory=True)\n    log('train dataset: {} (x{}), {}'.format(\n            train_dataset[0][0].shape, len(train_dataset),\n            train_dataset.n_classes))\n    if config.get('visualize_datasets'):\n        visualize_dataset(train_dataset, 'train_dataset', writer)\n\n    # val\n    if config.get('val_dataset'):\n        eval_val = True\n        val_dataset = datasets_make(config['val_dataset'],\n                                    **config['val_dataset_args'])\n        val_loader = DataLoader(val_dataset, config['batch_size'],\n                                num_workers=8, pin_memory=True)\n        log('val dataset: {} (x{}), {}'.format(\n                val_dataset[0][0].shape, len(val_dataset),\n                val_dataset.n_classes))\n        if config.get('visualize_datasets'):\n            visualize_dataset(val_dataset, 'val_dataset', writer)\n    else:\n        eval_val = False\n\n    # few-shot eval\n    if config.get('fs_dataset'):\n        ef_epoch = config.get('eval_fs_epoch')\n        if ef_epoch is None:\n            ef_epoch = 5\n        eval_fs = True\n\n        fs_dataset = datasets_make(config['fs_dataset'],\n                                   **config['fs_dataset_args'])\n        log('fs dataset: {} (x{}), {}'.format(\n                fs_dataset[0][0].shape, len(fs_dataset),\n                fs_dataset.n_classes))\n        if config.get('visualize_datasets'):\n            visualize_dataset(fs_dataset, 'fs_dataset', writer)\n\n        n_way = 5\n        n_query = 15\n        n_shots = [1, 5]\n        fs_loaders = []\n        for n_shot in n_shots:\n            fs_sampler = CategoriesSampler(\n                    fs_dataset.label, 200,\n                    n_way, n_shot + n_query, ep_per_batch=4)\n            fs_loader = DataLoader(fs_dataset, batch_sampler=fs_sampler,\n                                   num_workers=8, pin_memory=True)\n            fs_loaders.append(fs_loader)\n    else:\n        eval_fs = False\n\n    ########\n\n    #### Model and Optimizer ####\n\n    if config.get('load'):\n        model_sv = torch.load(config['load'])\n        model = models_load(model_sv)\n    else:\n        model = models_make(config['model'], **config['model_args'])\n\n    if eval_fs:\n        fs_model = models_make('meta-baseline', encoder=None)\n        fs_model.encoder = model.encoder\n\n    if config.get('_parallel'):\n        model = nn.DataParallel(model)\n        if eval_fs:\n            fs_model = nn.DataParallel(fs_model)\n\n    log('num params: {}'.format(compute_n_params(model)))\n\n    optimizer, lr_scheduler = make_optimizer(\n            model.parameters(),\n            config['optimizer'], **config['optimizer_args'])\n\n    ########\n\n    max_epoch = config['max_epoch']\n    save_epoch = config.get('save_epoch')\n    max_va = 0.\n    timer_used = Timer()\n    timer_epoch = Timer()\n\n    for epoch in range(1, max_epoch + 1 + 1):\n        if epoch == max_epoch + 1:\n            if not config.get('epoch_ex'):\n                break\n            train_dataset.transform = train_dataset.default_transform\n            train_loader = DataLoader(\n                    train_dataset, config['batch_size'], shuffle=True,\n                    num_workers=8, pin_memory=True)\n\n        timer_epoch.s()\n        aves_keys = ['tl', 'ta', 'vl', 'va']\n        if eval_fs:\n            for n_shot in n_shots:\n                aves_keys += ['fsa-' + str(n_shot)]\n        aves = {k: Averager() for k in aves_keys}\n\n        # train\n        model.train()\n        writer.add_scalar('lr', optimizer.param_groups[0]['lr'], epoch)\n\n        for data, label in tqdm(train_loader, desc='train', leave=False):\n            data, label = data.cuda(), label.cuda()\n            logits = model(data)\n            loss = F.cross_entropy(logits, label)\n            acc = compute_acc(logits, label)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            aves['tl'].add(loss.item())\n            aves['ta'].add(acc)\n\n            logits = None; loss = None\n\n        # eval\n        if eval_val:\n            model.eval()\n            for data, label in tqdm(val_loader, desc='val', leave=False):\n                data, label = data.cuda(), label.cuda()\n                with torch.no_grad():\n                    logits = model(data)\n                    loss = F.cross_entropy(logits, label)\n                    acc = compute_acc(logits, label)\n\n                aves['vl'].add(loss.item())\n                aves['va'].add(acc)\n\n        if eval_fs and (epoch % ef_epoch == 0 or epoch == max_epoch + 1):\n            fs_model.eval()\n            for i, n_shot in enumerate(n_shots):\n                np.random.seed(0)\n                for data, _ in tqdm(fs_loaders[i],\n                                    desc='fs-' + str(n_shot), leave=False):\n                    x_shot, x_query = split_shot_query(\n                            data.cuda(), n_way, n_shot, n_query, ep_per_batch=4)\n                    label = make_nk_label(\n                            n_way, n_query, ep_per_batch=4).cuda()\n                    with torch.no_grad():\n                        logits = fs_model(x_shot, x_query).view(-1, n_way)\n                        acc = compute_acc(logits, label)\n                    aves['fsa-' + str(n_shot)].add(acc)\n\n        # post\n        if lr_scheduler is not None:\n            lr_scheduler.step()\n\n        for k, v in aves.items():\n            aves[k] = v.item()\n\n        t_epoch = time_str(timer_epoch.t())\n        t_used = time_str(timer_used.t())\n        t_estimate = time_str(timer_used.t() / epoch * max_epoch)\n\n        if epoch <= max_epoch:\n            epoch_str = str(epoch)\n        else:\n            epoch_str = 'ex'\n        log_str = 'epoch {}, train {:.4f}|{:.4f}'.format(\n                epoch_str, aves['tl'], aves['ta'])\n        writer.add_scalars('loss', {'train': aves['tl']}, epoch)\n        writer.add_scalars('acc', {'train': aves['ta']}, epoch)\n\n        if eval_val:\n            log_str += ', val {:.4f}|{:.4f}'.format(aves['vl'], aves['va'])\n            writer.add_scalars('loss', {'val': aves['vl']}, epoch)\n            writer.add_scalars('acc', {'val': aves['va']}, epoch)\n\n        if eval_fs and (epoch % ef_epoch == 0 or epoch == max_epoch + 1):\n            log_str += ', fs'\n            for n_shot in n_shots:\n                key = 'fsa-' + str(n_shot)\n                log_str += ' {}: {:.4f}'.format(n_shot, aves[key])\n                writer.add_scalars('acc', {key: aves[key]}, epoch)\n\n        if epoch <= max_epoch:\n            log_str += ', {} {}/{}'.format(t_epoch, t_used, t_estimate)\n        else:\n            log_str += ', {}'.format(t_epoch)\n        log(log_str)\n\n        if config.get('_parallel'):\n            model_ = model.module\n        else:\n            model_ = model\n\n        training = {\n            'epoch': epoch,\n            'optimizer': config['optimizer'],\n            'optimizer_args': config['optimizer_args'],\n            'optimizer_sd': optimizer.state_dict(),\n        }\n        save_obj = {\n            'file': './output',\n            'config': config,\n\n            'model': config['model'],\n            'model_args': config['model_args'],\n            'model_sd': model_.state_dict(),\n\n            'training': training,\n        }\n        if epoch <= max_epoch:\n            torch.save(save_obj, os.path.join(save_path, 'epoch-last.pth'))\n\n            if (save_epoch is not None) and epoch % save_epoch == 0:\n                torch.save(save_obj, os.path.join(\n                    save_path, 'epoch-{}.pth'.format(epoch)))\n\n            if aves['va'] > max_va:\n                max_va = aves['va']\n                torch.save(save_obj, os.path.join(save_path, 'max-va.pth'))\n        else:\n            torch.save(save_obj, os.path.join(save_path, 'epoch-ex.pth'))\n\n        writer.flush()","metadata":{"id":"b23e2e2e","executionInfo":{"status":"ok","timestamp":1710833271614,"user_tz":-60,"elapsed":14,"user":{"displayName":"Rody Haket","userId":"00949362778939735047"}},"execution":{"iopub.status.busy":"2024-03-19T12:34:01.745766Z","iopub.execute_input":"2024-03-19T12:34:01.746203Z","iopub.status.idle":"2024-03-19T12:34:01.794243Z","shell.execute_reply.started":"2024-03-19T12:34:01.746168Z","shell.execute_reply":"2024-03-19T12:34:01.793196Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"os.listdir('./../input/mini-imagenet')","metadata":{"execution":{"iopub.status.busy":"2024-03-19T12:34:05.005944Z","iopub.execute_input":"2024-03-19T12:34:05.007106Z","iopub.status.idle":"2024-03-19T12:34:05.022730Z","shell.execute_reply.started":"2024-03-19T12:34:05.007074Z","shell.execute_reply":"2024-03-19T12:34:05.021863Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['miniImageNet_category_split_train_phase_val.pickle',\n 'miniImageNet_category_split_train_phase_train.pickle',\n 'miniImageNet_category_split_train_phase_test.pickle',\n 'miniImageNet_category_split_test.pickle',\n 'miniImageNet_category_split_val.pickle']"},"metadata":{}}]},{"cell_type":"code","source":"assert torch.cuda.is_available() == True","metadata":{"execution":{"iopub.status.busy":"2024-03-19T12:34:05.207174Z","iopub.execute_input":"2024-03-19T12:34:05.208254Z","iopub.status.idle":"2024-03-19T12:34:05.212636Z","shell.execute_reply.started":"2024-03-19T12:34:05.208212Z","shell.execute_reply":"2024-03-19T12:34:05.211764Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    # parser = argparse.ArgumentParser()\n    # parser.add_argument('--config')\n    # parser.add_argument('--name', default=None)\n    # parser.add_argument('--tag', default=None)\n    # parser.add_argument('--gpu', default='0')\n    # args = parser.parse_args()\n\n    # config = yaml.load(open(args.config, 'r'), Loader=yaml.FullLoader)\n    # if len(args.gpu.split(',')) > 1:\n    #     config['_parallel'] = True\n    #     config['_gpu'] = args.gpu\n\n    config = {  'train_dataset': 'mini-imagenet',\n            'train_dataset_args': {\n                'split': 'train',\n                'augment': 'resize'\n                },\n                'val_dataset': 'mini-imagenet',\n                'val_dataset_args': {\n                    'split': 'train_phase_val'\n                    },\n                'fs_dataset': 'mini-imagenet',\n                'fs_dataset_args': {\n                    'split': 'test'\n                    },\n                'eval_fs_epoch': 5,\n                'model': 'classifier',\n                'model_args': {\n                    'encoder': 'resnet12',\n                    'encoder_args': {},\n                    'classifier': 'linear-classifier',\n                    'classifier_args': {\n                        'n_classes': 64\n                        }\n                    },\n                'batch_size': 128,\n                'max_epoch': 100,\n                'optimizer': 'sgd',\n                'optimizer_args': {\n                    'lr': 0.1,\n                    'weight_decay': 0.0005,\n                    'milestones': [90]\n                    },\n                'save_epoch': 5,\n                'visualize_datasets': True\n                }\n\n    set_gpu(\"4\")\n    main(config)","metadata":{"lines_to_next_cell":2,"colab":{"base_uri":"https://localhost:8080/"},"id":"212c3a37","outputId":"18dad718-8021-48cb-bea5-998b0faab9a6","execution":{"iopub.status.busy":"2024-03-19T12:34:05.834976Z","iopub.execute_input":"2024-03-19T12:34:05.835841Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"set gpu: 4\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"input./../output/save/classifier_mini-imagenet_resnet12 exists, remove? ([y]/n):  y\n"},{"name":"stdout","text":"train dataset: torch.Size([3, 80, 80]) (x38400), 64\nval dataset: torch.Size([3, 80, 80]) (x18748), 64\nfs dataset: torch.Size([3, 80, 80]) (x12000), 20\nnum params: 8.0M\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 1, train 3.6984|0.1145, val 3.3639|0.1626, 1.2m 1.2m/1.9h\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 2, train 3.2955|0.1734, val 3.1228|0.2134, 1.1m 2.3m/1.9h\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 3, train 3.0868|0.2241, val 2.9296|0.2554, 1.1m 3.5m/1.9h\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 4, train 2.8423|0.2728, val 2.7713|0.2804, 1.2m 4.6m/1.9h\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 5, train 2.6156|0.3230, val 2.5318|0.3353, fs 1: 0.4458 5: 0.5901, 2.3m 6.9m/2.3h\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 6, train 2.4439|0.3612, val 2.3960|0.3808, 1.1m 8.1m/2.2h\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 7, train 2.3082|0.3923, val 2.1968|0.4190, 1.1m 9.2m/2.2h\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 8, train 2.1960|0.4191, val 2.1480|0.4300, 1.1m 10.4m/2.2h\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"epoch 9, train 2.0975|0.4412, val 2.1621|0.4191, 1.2m 11.5m/2.1h\n","output_type":"stream"},{"name":"stderr","text":"train:  40%|      | 121/300 [00:24<00:35,  5.10it/s]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"ARBRZATYe6TS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}