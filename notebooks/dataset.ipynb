{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Mini-ImageNet dataset\n",
    "\n",
    "This file is not applicable for use anymore since we can just use the .pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_miniimagenet_by_class(json_file_path, image_base_path=\"path/to/dataset\", train_classes=64, val_classes=16, test_classes=20,\n",
    "                               data_dir=\"./../materials/mini-imagenet\"):\n",
    "    \"\"\"\n",
    "    Reads a miniImagenet JSON file, splits it based on a fixed number of classes for\n",
    "    training, validation, and testing sets, and moves the corresponding images and creates ground truth files.\n",
    "\n",
    "    Args:\n",
    "    json_file_path (str): Path to the JSON file containing miniImagenet data.\n",
    "    image_base_path (str, optional): Base path where the images are located. Defaults to \"data\".\n",
    "    train_classes (int, optional): Number of classes for the training set. Defaults to 64.\n",
    "    val_classes (int, optional): Number of classes for the validation set. Defaults to 16.\n",
    "    test_classes (int, optional): Number of classes for the test set. Defaults to 20.\n",
    "    data_dir (str, optional): Directory to store the split data. Defaults to \"miniimagenet_split_by_class\".\n",
    "    \"\"\"\n",
    "\n",
    "    # Create directories for train, validation, and test sets\n",
    "    os.makedirs(os.path.join(data_dir, \"train\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(data_dir, \"val\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(data_dir, \"test\"), exist_ok=True)\n",
    "\n",
    "    # Read JSON data\n",
    "    with open(json_file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract image names and labels\n",
    "    image_names, labels = data[\"image_names\"], data[\"image_labels\"]\n",
    "\n",
    "    # Organize data by class\n",
    "    class_data = defaultdict(list)\n",
    "    for image_name, label in zip(image_names, labels):\n",
    "    # Extract actual image name without the \"filelists\" prefix (assuming the format is \"filelists/miniImagenet/n01532829/n01532829_721.JPEG\")\n",
    "        class_name =  image_name.split(\"/\")[-2]\n",
    "        image_name = image_name.split(\"/\")[-1]\n",
    "        class_data[class_name].append((image_name, label))\n",
    "\n",
    "    # Randomly select classes for each set (preserves class separation)\n",
    "    random.seed(42)  # For reproducibility\n",
    "    all_classes = list(class_data.keys())\n",
    "    train_classes = random.sample(all_classes, train_classes)\n",
    "    remaining_classes = set(all_classes) - set(train_classes)\n",
    "    val_classes = random.sample(list(remaining_classes), val_classes)\n",
    "    test_classes = list(remaining_classes - set(val_classes))\n",
    "\n",
    "    # Move images and create ground truth files\n",
    "    def move_data(data_dir_subset, class_subset):\n",
    "        \n",
    "        for class_label in class_subset:\n",
    "            class_dir = os.path.join(data_dir_subset, class_label)\n",
    "            os.makedirs(class_dir, exist_ok=True)\n",
    "            # print(class_dir)\n",
    "            for image_name, label in class_data[class_label]:\n",
    "                class_path = os.path.join(image_base_path, class_label)\n",
    "                image_path = os.path.join(class_path, image_name)  # Use the provided image_base_path\n",
    "                full_target_path = os.path.join(class_dir, image_name)\n",
    "                    # Create ground truth file\n",
    "                with open(os.path.join(class_dir, \"ground_truth.txt\"), \"a+\") as f:\n",
    "                    f.write(str(label) + \"\\n\")\n",
    "                    \n",
    "                # Check if the image file exists (optional)\n",
    "                if os.path.exists(image_path):\n",
    "                    shutil.move(image_path, full_target_path)  # Move the image\n",
    "                else:\n",
    "                    print(f\"Warning: Image {image_path} not found. Skipping...\")\n",
    "\n",
    "\n",
    "\n",
    "    # # Move data to train, validation, and test sets based on selected classes\n",
    "    move_data(os.path.join(data_dir, \"train\"), train_classes)\n",
    "    move_data(os.path.join(data_dir, \"val\"), val_classes)\n",
    "    move_data(os.path.join(data_dir, \"test\"), test_classes)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Image D:/Downloads/archive\\n01981276\\n01981276_908.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n02108915\\n02108915_4176.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n01749939\\n01749939_10792.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n03775546\\n03775546_9946.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n03527444\\n03527444_24604.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n03337140\\n03337140_36568.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n03062245\\n03062245_187.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n02120079\\n02120079_9729.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n02108551\\n02108551_25554.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n02129165\\n02129165_2295.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n02950826\\n02950826_11503.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n02105505\\n02105505_2009.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n03584254\\n03584254_6568.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n04596742\\n04596742_3014.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n01770081\\n01770081_14910.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n04418357\\n04418357_12672.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n02443484\\n02443484_5462.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n03047690\\n03047690_12007.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n03207743\\n03207743_7156.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n01855672\\n01855672_14199.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n03773504\\n03773504_17206.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n02110341\\n02110341_12237.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n02981792\\n02981792_23173.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n02966193\\n02966193_14630.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n02871525\\n02871525_26761.JPEG not found. Skipping...\n",
      "Warning: Image D:/Downloads/archive\\n04515003\\n04515003_36691.JPEG not found. Skipping...\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "split_miniimagenet_by_class(json_file_path=\"./../materials/mini-imagenet_split.json\", image_base_path=\"D:/Downloads/archive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
